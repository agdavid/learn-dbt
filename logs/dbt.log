

============================== 2022-01-08 21:09:20.122417 | 01904cb0-62d6-4b01-8491-59378ad5a7a3 ==============================
21:09:20.122417 [info ] [MainThread]: Running with dbt=1.0.1
21:09:20.123092 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:09:20.123341 [debug] [MainThread]: Tracking: tracking
21:09:20.123716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11106df40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cf3e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cf34f0>]}
21:09:20.138890 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
21:09:20.139238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d6d160>]}
21:09:20.177091 [debug] [MainThread]: Parsing macros/catalog.sql
21:09:20.179241 [debug] [MainThread]: Parsing macros/adapters.sql
21:09:20.217042 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:09:20.220647 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:09:20.225505 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:09:20.226762 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:09:20.229590 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:09:20.237646 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:09:20.238707 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:09:20.242562 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:09:20.244690 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:09:20.246186 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:09:20.261677 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:09:20.271982 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:09:20.282731 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:09:20.287015 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:09:20.288629 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:09:20.290264 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:09:20.294280 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:09:20.304617 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:09:20.305979 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:09:20.315402 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:09:20.329735 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:09:20.336468 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:09:20.339177 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:09:20.345706 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:09:20.346910 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:09:20.349278 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:09:20.351293 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:09:20.356561 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:09:20.371175 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:09:20.372482 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:09:20.374637 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:09:20.376005 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:09:20.376771 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:09:20.377267 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:09:20.377876 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:09:20.379061 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:09:20.383051 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:09:20.390625 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:09:20.392527 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:09:20.394866 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:09:20.403365 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:09:20.405913 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:09:20.409889 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:09:20.416343 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:09:20.425048 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:09:20.606382 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:09:20.616491 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:09:20.618417 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:09:20.620610 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:09:20.622563 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:09:20.629748 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:09:20.630835 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:09:20.633282 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:09:20.635895 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:09:20.639421 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:09:20.784705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c350a0>]}
21:09:20.793342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cf24f0>]}
21:09:20.793677 [info ] [MainThread]: Found 8 models, 19 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:09:20.795619 [info ] [MainThread]: 
21:09:20.796106 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:09:20.797273 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:09:20.811111 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:09:20.811312 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:09:20.811487 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:09:21.742974 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.93 seconds
21:09:21.744802 [debug] [ThreadPool]: On list_analytics: Close
21:09:21.924549 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:09:21.932393 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:09:21.932609 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:09:21.932788 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:09:22.756818 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.82 seconds
21:09:22.758695 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:09:22.894571 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:09:22.895052 [info ] [MainThread]: 
21:09:22.902170 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:09:22.902637 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:09:22.903267 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:09:22.903504 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:09:22.903740 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:09:22.909656 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:09:22.910507 [debug] [Thread-1  ]: finished collecting timing info
21:09:22.910728 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:09:22.958148 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:09:22.958440 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:09:22.958627 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:23.554999 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a17ff5-0000-65ab-0000-00016cc23611
21:09:23.555447 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:09:23.555936 [debug] [Thread-1  ]: finished collecting timing info
21:09:23.556236 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:09:23.701224 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:09:23.701637 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11411e910>]}
21:09:23.702037 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.80s]
21:09:23.702426 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:09:23.702661 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:09:23.703054 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:09:23.703543 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:09:23.703741 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:09:23.703930 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:09:23.707407 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:09:23.708006 [debug] [Thread-1  ]: finished collecting timing info
21:09:23.708210 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:09:23.711720 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:23.711930 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:09:23.712144 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:25.459007 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
21:09:25.470243 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:25.470456 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:09:25.586572 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
21:09:25.591697 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:25.591936 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:09:25.756916 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.16 seconds
21:09:25.767156 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:25.767382 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:09:25.995499 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.23 seconds
21:09:26.022617 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:09:26.024652 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:26.024848 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:09:26.133641 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:09:26.134138 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:26.134410 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:09:27.052556 [debug] [Thread-1  ]: SQL status: SUCCESS 504 in 0.92 seconds
21:09:27.053003 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:27.053274 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:09:27.324459 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
21:09:27.336783 [debug] [Thread-1  ]: finished collecting timing info
21:09:27.337023 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:09:27.492699 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d8400>]}
21:09:27.493272 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.79s]
21:09:27.493706 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:09:27.493970 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:09:27.494282 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:09:27.494977 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:09:27.495217 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:09:27.495447 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:09:27.498250 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:09:27.498783 [debug] [Thread-1  ]: finished collecting timing info
21:09:27.498992 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:09:27.508929 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:09:27.510065 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:09:27.510281 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:09:27.510466 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:29.211416 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.7 seconds
21:09:29.213844 [debug] [Thread-1  ]: finished collecting timing info
21:09:29.214114 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:09:29.350255 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d86a0>]}
21:09:29.350796 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.86s]
21:09:29.351232 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:09:29.351501 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:09:29.351918 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:09:29.352531 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:09:29.352774 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:09:29.353026 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:09:29.354558 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:09:29.355067 [debug] [Thread-1  ]: finished collecting timing info
21:09:29.355272 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:09:29.357595 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:09:29.358378 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:09:29.358577 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:09:29.358755 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:45.835472 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 16.48 seconds
21:09:45.837932 [debug] [Thread-1  ]: finished collecting timing info
21:09:45.838210 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:09:46.001963 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d8940>]}
21:09:46.002523 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 16.65s]
21:09:46.002962 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:09:46.003233 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.003655 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:09:46.004238 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.004470 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.004692 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.006100 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.006621 [debug] [Thread-1  ]: finished collecting timing info
21:09:46.006828 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.009118 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.010107 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.010309 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:09:46.010492 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:47.530880 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
21:09:47.533334 [debug] [Thread-1  ]: finished collecting timing info
21:09:47.533611 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:09:47.712870 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d85e0>]}
21:09:47.713400 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 1.71s]
21:09:47.713835 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:47.714105 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:09:47.714436 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:09:47.715006 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:09:47.715263 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:09:47.715601 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:09:47.717088 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:09:47.717567 [debug] [Thread-1  ]: finished collecting timing info
21:09:47.717778 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:09:47.720116 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:09:47.721259 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:09:47.721469 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:09:47.721653 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:49.550117 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.83 seconds
21:09:49.552575 [debug] [Thread-1  ]: finished collecting timing info
21:09:49.552846 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:09:49.700147 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114257a00>]}
21:09:49.700690 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.99s]
21:09:49.701134 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:09:49.701422 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:09:49.701855 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:09:49.702525 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.702759 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:09:49.702965 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:09:49.704346 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.704910 [debug] [Thread-1  ]: finished collecting timing info
21:09:49.705131 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:09:49.707529 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.708617 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.708818 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:09:49.709003 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:51.190462 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
21:09:51.192963 [debug] [Thread-1  ]: finished collecting timing info
21:09:51.193238 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:09:51.355423 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11426afd0>]}
21:09:51.355964 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.65s]
21:09:51.356402 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:09:51.356672 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:09:51.356986 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:09:51.357671 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:09:51.357908 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:09:51.358130 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:09:51.360804 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:09:51.361320 [debug] [Thread-1  ]: finished collecting timing info
21:09:51.361526 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:09:51.363871 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:09:51.364669 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:09:51.364868 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:09:51.365047 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:52.922928 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
21:09:52.925221 [debug] [Thread-1  ]: finished collecting timing info
21:09:52.925527 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:09:53.061201 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11411dc70>]}
21:09:53.061673 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.70s]
21:09:53.062044 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:09:53.063052 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:09:53.063470 [info ] [MainThread]: 
21:09:53.063777 [info ] [MainThread]: Finished running 2 incremental models, 6 table models in 32.27s.
21:09:53.064061 [debug] [MainThread]: Connection 'master' was properly closed.
21:09:53.064229 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:09:53.070761 [info ] [MainThread]: 
21:09:53.071109 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:09:53.071432 [info ] [MainThread]: 
21:09:53.071704 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:09:53.071972 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:09:53.072259 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:09:53.072634 [info ] [MainThread]: 
21:09:53.072922 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:09:53.073285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111045bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121ccbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114225d90>]}


============================== 2022-01-08 21:27:16.583501 | 1a279529-b91a-4786-840f-80c5834dff09 ==============================
21:27:16.583501 [info ] [MainThread]: Running with dbt=1.0.1
21:27:16.584219 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
21:27:16.584540 [debug] [MainThread]: Tracking: tracking
21:27:16.585015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ad9610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ad9cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ab18e0>]}
21:27:16.639509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
21:27:16.640173 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
21:27:16.651056 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:27:16.696568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1a279529-b91a-4786-840f-80c5834dff09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069700d0>]}
21:27:16.703348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a279529-b91a-4786-840f-80c5834dff09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106818d30>]}
21:27:16.703730 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:27:16.705922 [info ] [MainThread]: 
21:27:16.706408 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:27:16.707556 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:27:16.719996 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:27:16.720245 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:27:16.720405 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:27:19.548119 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2.83 seconds
21:27:19.550710 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:27:19.696602 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:27:19.697105 [info ] [MainThread]: 
21:27:19.701116 [debug] [Thread-1  ]: Began running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.701418 [info ] [Thread-1  ]: 1 of 18 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
21:27:19.701982 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.702198 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.702416 [debug] [Thread-1  ]: Compiling test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.714825 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.715660 [debug] [Thread-1  ]: finished collecting timing info
21:27:19.715912 [debug] [Thread-1  ]: Began executing node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.735541 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.737023 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.737241 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.playing_with_tests
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
21:27:19.737430 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:21.854314 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.12 seconds
21:27:21.857488 [debug] [Thread-1  ]: finished collecting timing info
21:27:21.857778 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
21:27:22.010064 [info ] [Thread-1  ]: 1 of 18 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 2.31s]
21:27:22.010633 [debug] [Thread-1  ]: Finished running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:22.010928 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_100m_acctbal
21:27:22.011314 [info ] [Thread-1  ]: 2 of 18 START test assert_under_100m_acctbal.................................... [RUN]
21:27:22.011926 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.012168 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_100m_acctbal
21:27:22.012415 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_100m_acctbal
21:27:22.014759 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.015410 [debug] [Thread-1  ]: finished collecting timing info
21:27:22.015628 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_100m_acctbal
21:27:22.017798 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.019000 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.019214 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_100m_acctbal: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_100m_acctbal"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select
    c_custkey,
    sum(c_acctbal) as total_acctbal
from analytics.dbt.playing_with_tests
group by
    c_custkey

having sum(c_acctbal) > 100000000
      
    ) dbt_internal_test
21:27:22.019428 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:24.026185 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.01 seconds
21:27:24.028166 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.028453 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_100m_acctbal: Close
21:27:24.195558 [info ] [Thread-1  ]: 2 of 18 PASS assert_under_100m_acctbal.......................................... [[32mPASS[0m in 2.18s]
21:27:24.196109 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_100m_acctbal
21:27:24.196415 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
21:27:24.196690 [info ] [Thread-1  ]: 3 of 18 START test assert_under_10_percent_null................................. [RUN]
21:27:24.197281 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
21:27:24.197660 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
21:27:24.197927 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
21:27:24.200396 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
21:27:24.200950 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.201167 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
21:27:24.203312 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
21:27:24.204438 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
21:27:24.204652 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select 
    sum(case when id is null then 1 else 0 end) / count(*) as total_nulls

from analytics.dbt.first_model

having sum(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
21:27:24.204846 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:24.793533 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.59 seconds
21:27:24.795850 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.796163 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
21:27:24.945645 [info ] [Thread-1  ]: 3 of 18 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 0.75s]
21:27:24.946207 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
21:27:24.946499 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.946881 [info ] [Thread-1  ]: 4 of 18 START test not_null_playing_with_tests_c_custkey........................ [RUN]
21:27:24.947479 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.947723 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.947957 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.958659 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.959755 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.960266 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.964116 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.965931 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.966296 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.playing_with_tests
where c_custkey is null



      
    ) dbt_internal_test
21:27:24.966526 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:25.493541 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.53 seconds
21:27:25.495833 [debug] [Thread-1  ]: finished collecting timing info
21:27:25.496121 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
21:27:25.645089 [info ] [Thread-1  ]: 4 of 18 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 0.70s]
21:27:25.645716 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:25.646075 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.646458 [info ] [Thread-1  ]: 5 of 18 START test not_null_snowflake_cumulative_orders_by_date_o_orderdate..... [RUN]
21:27:25.646984 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.647195 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.647396 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.651714 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.652346 [debug] [Thread-1  ]: finished collecting timing info
21:27:25.652576 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.654904 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.656171 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.656446 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_orders_by_date
where o_orderdate is null



      
    ) dbt_internal_test
21:27:25.656652 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:26.275928 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.62 seconds
21:27:26.278179 [debug] [Thread-1  ]: finished collecting timing info
21:27:26.278463 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14: Close
21:27:26.425711 [info ] [Thread-1  ]: 5 of 18 PASS not_null_snowflake_cumulative_orders_by_date_o_orderdate........... [[32mPASS[0m in 0.78s]
21:27:26.426259 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:26.426547 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.426921 [info ] [Thread-1  ]: 6 of 18 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
21:27:26.427509 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.427771 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.428007 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.432142 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.432764 [debug] [Thread-1  ]: finished collecting timing info
21:27:26.432989 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.435203 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.436220 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.436434 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
21:27:26.436628 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:27.413841 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
21:27:27.416154 [debug] [Thread-1  ]: finished collecting timing info
21:27:27.416441 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
21:27:27.555215 [info ] [Thread-1  ]: 6 of 18 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.13s]
21:27:27.555764 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:27.556052 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.556446 [info ] [Thread-1  ]: 7 of 18 START test not_null_snowflake_customer_purchases_c_name................. [RUN]
21:27:27.557162 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.557405 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.557645 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.561607 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.562160 [debug] [Thread-1  ]: finished collecting timing info
21:27:27.562372 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.564529 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.565523 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.565731 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_name is null



      
    ) dbt_internal_test
21:27:27.565917 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:28.125087 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.56 seconds
21:27:28.126778 [debug] [Thread-1  ]: finished collecting timing info
21:27:28.127032 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972: Close
21:27:28.295835 [info ] [Thread-1  ]: 7 of 18 PASS not_null_snowflake_customer_purchases_c_name....................... [[32mPASS[0m in 0.74s]
21:27:28.296407 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:28.296692 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.297079 [info ] [Thread-1  ]: 8 of 18 START test not_null_snowflake_nation_customer_count_n_name.............. [RUN]
21:27:28.297687 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.297931 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.298166 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.302229 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.302785 [debug] [Thread-1  ]: finished collecting timing info
21:27:28.303007 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.305215 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.306228 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.306444 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_nation_customer_count
where n_name is null



      
    ) dbt_internal_test
21:27:28.306636 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:28.923766 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.62 seconds
21:27:28.926039 [debug] [Thread-1  ]: finished collecting timing info
21:27:28.926329 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81: Close
21:27:29.095814 [info ] [Thread-1  ]: 8 of 18 PASS not_null_snowflake_nation_customer_count_n_name.................... [[32mPASS[0m in 0.80s]
21:27:29.096370 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:29.096659 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.097053 [info ] [Thread-1  ]: 9 of 18 START test not_null_snowflake_nation_customer_count_n_nationkey......... [RUN]
21:27:29.097645 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.097887 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.098123 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.102075 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.102632 [debug] [Thread-1  ]: finished collecting timing info
21:27:29.102841 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.104958 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.105977 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.106197 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_nation_customer_count
where n_nationkey is null



      
    ) dbt_internal_test
21:27:29.106386 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:29.698072 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.59 seconds
21:27:29.700357 [debug] [Thread-1  ]: finished collecting timing info
21:27:29.700642 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae: Close
21:27:30.395620 [info ] [Thread-1  ]: 9 of 18 PASS not_null_snowflake_nation_customer_count_n_nationkey............... [[32mPASS[0m in 1.30s]
21:27:30.396207 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:30.396495 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.396867 [info ] [Thread-1  ]: 10 of 18 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
21:27:30.397470 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.397713 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.397947 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.404177 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.404809 [debug] [Thread-1  ]: finished collecting timing info
21:27:30.405030 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.406910 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.408359 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.408581 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
21:27:30.408777 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:31.275316 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.87 seconds
21:27:31.277474 [debug] [Thread-1  ]: finished collecting timing info
21:27:31.277757 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
21:27:31.666320 [info ] [Thread-1  ]: 10 of 18 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[32mPASS[0m in 1.27s]
21:27:31.666864 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:31.667127 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.667466 [info ] [Thread-1  ]: 11 of 18 START test unique_my_first_dbt_model_id................................ [RUN]
21:27:31.668006 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.668263 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.668479 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.676868 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.677533 [debug] [Thread-1  ]: finished collecting timing info
21:27:31.677765 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.679812 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.680995 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.681231 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
21:27:31.681438 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:33.462934 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.78 seconds
21:27:33.464920 [debug] [Thread-1  ]: finished collecting timing info
21:27:33.465250 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
21:27:33.612539 [info ] [Thread-1  ]: 11 of 18 PASS unique_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.94s]
21:27:33.613082 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:33.613432 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.613936 [info ] [Thread-1  ]: 12 of 18 START test unique_my_second_dbt_model_id............................... [RUN]
21:27:33.614506 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.614731 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.614943 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.619351 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.619960 [debug] [Thread-1  ]: finished collecting timing info
21:27:33.620190 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.622393 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.623510 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.623728 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
21:27:33.623952 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:34.310417 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.69 seconds
21:27:34.312693 [debug] [Thread-1  ]: finished collecting timing info
21:27:34.312981 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
21:27:34.600507 [info ] [Thread-1  ]: 12 of 18 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 0.99s]
21:27:34.601015 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:34.601271 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.601592 [info ] [Thread-1  ]: 13 of 18 START test unique_playing_with_tests_c_custkey......................... [RUN]
21:27:34.602191 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.602411 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.602614 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.607143 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.607788 [debug] [Thread-1  ]: finished collecting timing info
21:27:34.608017 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.610675 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.612088 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.612352 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.playing_with_tests
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
21:27:34.612561 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:36.124335 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
21:27:36.126015 [debug] [Thread-1  ]: finished collecting timing info
21:27:36.126264 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: Close
21:27:36.295682 [info ] [Thread-1  ]: 13 of 18 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.69s]
21:27:36.296255 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:36.296540 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.296902 [info ] [Thread-1  ]: 14 of 18 START test unique_snowflake_cumulative_orders_by_date_o_orderdate...... [RUN]
21:27:36.297498 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.297740 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.297974 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.302036 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.302665 [debug] [Thread-1  ]: finished collecting timing info
21:27:36.302902 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.305090 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.306300 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.306516 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_orders_by_date
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
21:27:36.306712 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:36.948647 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
21:27:36.951174 [debug] [Thread-1  ]: finished collecting timing info
21:27:36.951499 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88: Close
21:27:37.095771 [info ] [Thread-1  ]: 14 of 18 PASS unique_snowflake_cumulative_orders_by_date_o_orderdate............ [[32mPASS[0m in 0.80s]
21:27:37.096335 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:37.096624 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.096994 [info ] [Thread-1  ]: 15 of 18 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
21:27:37.097589 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.097831 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.098065 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.102206 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.102759 [debug] [Thread-1  ]: finished collecting timing info
21:27:37.102975 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.105171 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.106369 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.106585 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
21:27:37.106781 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:37.943365 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
21:27:37.945366 [debug] [Thread-1  ]: finished collecting timing info
21:27:37.945654 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
21:27:38.079906 [info ] [Thread-1  ]: 15 of 18 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 0.98s]
21:27:38.080402 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:38.080654 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.080955 [info ] [Thread-1  ]: 16 of 18 START test unique_snowflake_customer_purchases_c_name.................. [RUN]
21:27:38.081526 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.081754 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.081961 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.085962 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.086567 [debug] [Thread-1  ]: finished collecting timing info
21:27:38.086790 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.089059 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.090274 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.090565 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_name as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_name is not null
group by c_name
having count(*) > 1



      
    ) dbt_internal_test
21:27:38.090845 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:38.819997 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.73 seconds
21:27:38.822060 [debug] [Thread-1  ]: finished collecting timing info
21:27:38.822343 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297: Close
21:27:38.994376 [info ] [Thread-1  ]: 16 of 18 PASS unique_snowflake_customer_purchases_c_name........................ [[32mPASS[0m in 0.91s]
21:27:38.994852 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.995193 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:38.995527 [info ] [Thread-1  ]: 17 of 18 START test unique_snowflake_nation_customer_count_n_name............... [RUN]
21:27:38.996087 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:38.996372 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:38.996607 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:39.000913 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:39.001542 [debug] [Thread-1  ]: finished collecting timing info
21:27:39.001771 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:39.004279 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:39.005818 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:39.006178 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    n_name as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_nation_customer_count
where n_name is not null
group by n_name
having count(*) > 1



      
    ) dbt_internal_test
21:27:39.006429 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:39.610187 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.6 seconds
21:27:39.612196 [debug] [Thread-1  ]: finished collecting timing info
21:27:39.612494 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034: Close
21:27:39.795728 [info ] [Thread-1  ]: 17 of 18 PASS unique_snowflake_nation_customer_count_n_name..................... [[32mPASS[0m in 0.80s]
21:27:39.796508 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:39.796912 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.797277 [info ] [Thread-1  ]: 18 of 18 START test unique_snowflake_nation_customer_count_n_nationkey.......... [RUN]
21:27:39.797937 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.798197 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.798473 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.802595 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.803192 [debug] [Thread-1  ]: finished collecting timing info
21:27:39.803448 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.805923 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.807614 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.807994 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    n_nationkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_nation_customer_count
where n_nationkey is not null
group by n_nationkey
having count(*) > 1



      
    ) dbt_internal_test
21:27:39.808296 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:40.504666 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
21:27:40.506412 [debug] [Thread-1  ]: finished collecting timing info
21:27:40.506675 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5: Close
21:27:40.646857 [info ] [Thread-1  ]: 18 of 18 PASS unique_snowflake_nation_customer_count_n_nationkey................ [[32mPASS[0m in 0.85s]
21:27:40.647736 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:40.649474 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:27:40.650012 [info ] [MainThread]: 
21:27:40.650439 [info ] [MainThread]: Finished running 18 tests in 23.94s.
21:27:40.651133 [debug] [MainThread]: Connection 'master' was properly closed.
21:27:40.651566 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5' was properly closed.
21:27:40.661997 [info ] [MainThread]: 
21:27:40.662646 [info ] [MainThread]: [32mCompleted successfully[0m
21:27:40.663369 [info ] [MainThread]: 
21:27:40.663840 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=0 SKIP=0 TOTAL=18
21:27:40.664342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b11bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106818520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bcfb50>]}


============================== 2022-01-08 21:39:53.629274 | 86818b4c-7252-4e3e-8b8d-539c3aeb2cf0 ==============================
21:39:53.629274 [info ] [MainThread]: Running with dbt=1.0.1
21:39:53.629926 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:39:53.630191 [debug] [MainThread]: Tracking: tracking
21:39:53.630596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e127f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e12d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e124c0>]}
21:39:53.654242 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:39:53.654702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e15a30>]}
21:39:53.693411 [debug] [MainThread]: Parsing macros/catalog.sql
21:39:53.696734 [debug] [MainThread]: Parsing macros/adapters.sql
21:39:53.741125 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:39:53.744737 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:39:53.749563 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:39:53.750839 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:39:53.753747 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:39:53.761769 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:39:53.762671 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:39:53.766231 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:39:53.768385 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:39:53.769908 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:39:53.785568 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:39:53.796034 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:39:53.807038 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:39:53.811282 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:39:53.812895 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:39:53.814529 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:39:53.818590 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:39:53.828830 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:39:53.830213 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:39:53.839625 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:39:53.853913 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:39:53.860653 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:39:53.863256 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:39:53.869751 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:39:53.870945 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:39:53.873411 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:39:53.875517 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:39:53.881021 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:39:53.896141 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:39:53.897487 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:39:53.899716 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:39:53.901275 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:39:53.902089 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:39:53.902611 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:39:53.903265 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:39:53.904511 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:39:53.908530 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:39:53.915931 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:39:53.917853 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:39:53.920186 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:39:53.928591 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:39:53.931105 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:39:53.935042 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:39:53.941507 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:39:53.950225 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:39:54.134354 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:39:54.144405 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:39:54.146412 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:39:54.148633 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:39:54.150757 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:39:54.156845 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:39:54.157756 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:39:54.159734 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:39:54.161838 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:39:54.165093 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:39:54.321804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106719fa0>]}
21:39:54.327926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e2c2b0>]}
21:39:54.328178 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 3 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:39:54.331097 [info ] [MainThread]: 
21:39:54.331955 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:39:54.333632 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:39:54.347129 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:39:54.347433 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:39:54.347628 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:39:55.120646 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.77 seconds
21:39:55.122833 [debug] [ThreadPool]: On list_analytics: Close
21:39:55.288025 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:39:55.295909 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:39:55.296145 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:39:55.296342 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:39:56.019519 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.72 seconds
21:39:56.021747 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:39:56.167067 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:39:56.167586 [info ] [MainThread]: 
21:39:56.171196 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:39:56.171577 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:39:56.172151 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:39:56.172374 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:39:56.172600 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:39:56.179914 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:39:56.181343 [debug] [Thread-1  ]: finished collecting timing info
21:39:56.181606 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:39:56.231504 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:39:56.231815 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:39:56.232016 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:39:56.816675 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a18013-0000-65ab-0000-00016cc23761
21:39:56.817031 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:39:56.817434 [debug] [Thread-1  ]: finished collecting timing info
21:39:56.817673 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:39:56.955955 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:39:56.956391 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10721e100>]}
21:39:56.956798 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.78s]
21:39:56.957205 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:39:56.957451 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:39:56.957873 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:39:56.958404 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:39:56.958611 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:39:56.958815 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:39:56.962491 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:39:56.963142 [debug] [Thread-1  ]: finished collecting timing info
21:39:56.963373 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:39:56.967476 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:56.967738 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:39:56.967944 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:39:58.654900 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.69 seconds
21:39:58.666442 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:58.666684 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:39:58.759834 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:39:58.764734 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:58.764963 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:39:58.854144 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:39:58.864079 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:58.864356 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:39:58.970180 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
21:39:59.004447 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:39:59.006359 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:59.006585 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:39:59.128029 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
21:39:59.128430 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:59.128636 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:39:59.776123 [debug] [Thread-1  ]: SQL status: SUCCESS 544 in 0.65 seconds
21:39:59.776441 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:59.776641 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:40:00.025733 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
21:40:00.038379 [debug] [Thread-1  ]: finished collecting timing info
21:40:00.038700 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:40:00.207930 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275220>]}
21:40:00.208632 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.25s]
21:40:00.209132 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:40:00.209433 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:40:00.209944 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:40:00.210534 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:40:00.210754 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:40:00.210973 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:40:00.214363 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:40:00.215022 [debug] [Thread-1  ]: finished collecting timing info
21:40:00.215261 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:40:00.226587 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:40:00.227842 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:40:00.228080 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:40:00.228277 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:01.575961 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.35 seconds
21:40:01.578161 [debug] [Thread-1  ]: finished collecting timing info
21:40:01.578499 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:40:01.856524 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275b20>]}
21:40:01.857093 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.65s]
21:40:01.857562 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:40:01.857846 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:40:01.858294 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:40:01.858960 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:40:01.859184 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:40:01.859397 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:40:01.860863 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:40:01.861609 [debug] [Thread-1  ]: finished collecting timing info
21:40:01.861848 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:40:01.864507 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:40:01.865462 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:40:01.865721 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:40:01.865927 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:19.124271 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.26 seconds
21:40:19.126771 [debug] [Thread-1  ]: finished collecting timing info
21:40:19.127059 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:40:19.507582 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275970>]}
21:40:19.508143 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 17.65s]
21:40:19.508616 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:40:19.508905 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.509359 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:40:19.509987 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.510239 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.510494 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.511949 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.513333 [debug] [Thread-1  ]: finished collecting timing info
21:40:19.513577 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.516102 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.517525 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.517766 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:40:19.517969 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:20.955187 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
21:40:20.957970 [debug] [Thread-1  ]: finished collecting timing info
21:40:20.958290 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:40:21.089095 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275910>]}
21:40:21.089657 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 1.58s]
21:40:21.090134 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:21.090425 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:40:21.090871 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:40:21.091477 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:40:21.091726 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:40:21.091985 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:40:21.093443 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:40:21.094036 [debug] [Thread-1  ]: finished collecting timing info
21:40:21.094261 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:40:21.096755 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:40:21.097963 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:40:21.098186 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:40:21.098386 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:23.314762 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.22 seconds
21:40:23.317257 [debug] [Thread-1  ]: finished collecting timing info
21:40:23.317548 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:40:23.507432 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275a60>]}
21:40:23.508016 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.42s]
21:40:23.508504 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:40:23.508810 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:40:23.509258 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:40:23.509851 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.510103 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:40:23.510349 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:40:23.511816 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.512394 [debug] [Thread-1  ]: finished collecting timing info
21:40:23.512618 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:40:23.515091 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.516240 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.516462 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:40:23.516666 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:26.210110 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.69 seconds
21:40:26.212643 [debug] [Thread-1  ]: finished collecting timing info
21:40:26.212933 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:40:26.359804 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275670>]}
21:40:26.360369 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 2.85s]
21:40:26.360837 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:40:26.361127 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:40:26.361571 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:40:26.362168 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:40:26.362417 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:40:26.362658 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:40:26.365078 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:40:26.365652 [debug] [Thread-1  ]: finished collecting timing info
21:40:26.365877 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:40:26.368708 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:40:26.369698 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:40:26.369925 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:40:26.370121 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:27.754345 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.38 seconds
21:40:27.756147 [debug] [Thread-1  ]: finished collecting timing info
21:40:27.756394 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:40:27.907140 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107223ac0>]}
21:40:27.907712 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.55s]
21:40:27.908186 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:40:27.909388 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:40:27.909696 [info ] [MainThread]: 
21:40:27.910086 [info ] [MainThread]: Running 3 on-run-end hooks
21:40:27.910789 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
21:40:27.912347 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
21:40:27.914275 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
21:40:27.914866 [debug] [MainThread]: Using snowflake connection "master"
21:40:27.915081 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
21:40:27.915277 [debug] [MainThread]: Opening a new connection, currently in state init
21:40:28.871570 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.96 seconds
21:40:28.873029 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.96s]
21:40:28.873599 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
21:40:28.875100 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
21:40:28.876003 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
21:40:28.876697 [debug] [MainThread]: Using snowflake connection "master"
21:40:28.876953 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
21:40:29.331777 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.45 seconds
21:40:29.332894 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.46s]
21:40:29.333361 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
21:40:29.335223 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
21:40:29.336328 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
21:40:29.337609 [debug] [MainThread]: Using snowflake connection "master"
21:40:29.338094 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
21:40:29.467080 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
21:40:29.468077 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.13s]
21:40:29.468471 [info ] [MainThread]: 
21:40:29.468833 [debug] [MainThread]: On master: Close
21:40:29.723645 [info ] [MainThread]: 
21:40:29.724182 [info ] [MainThread]: Finished running 2 incremental models, 6 table models, 3 hooks in 35.39s.
21:40:29.724573 [debug] [MainThread]: Connection 'master' was properly closed.
21:40:29.724803 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:40:29.732698 [info ] [MainThread]: 
21:40:29.733116 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:40:29.733488 [info ] [MainThread]: 
21:40:29.733805 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:40:29.734122 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:40:29.734421 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:40:29.734773 [info ] [MainThread]: 
21:40:29.735147 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:40:29.735760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928bd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928b9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093f0700>]}


============================== 2022-01-08 21:46:47.705272 | af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7 ==============================
21:46:47.705272 [info ] [MainThread]: Running with dbt=1.0.1
21:46:47.706123 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:46:47.706358 [debug] [MainThread]: Tracking: tracking
21:46:47.706808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db40490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db404c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db406d0>]}
21:46:47.731644 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:46:47.732097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db3c130>]}
21:46:47.768231 [debug] [MainThread]: Parsing macros/catalog.sql
21:46:47.771371 [debug] [MainThread]: Parsing macros/adapters.sql
21:46:47.817062 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:46:47.820738 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:46:47.825697 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:46:47.826980 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:46:47.829888 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:46:47.837980 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:46:47.838976 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:46:47.842563 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:46:47.844787 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:46:47.846339 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:46:47.862316 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:46:47.873079 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:46:47.884206 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:46:47.888407 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:46:47.890118 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:46:47.891841 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:46:47.896030 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:46:47.906781 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:46:47.908231 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:46:47.917759 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:46:47.932042 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:46:47.938619 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:46:47.941163 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:46:47.947570 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:46:47.948793 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:46:47.951156 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:46:47.953188 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:46:47.959504 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:46:47.975053 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:46:47.976448 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:46:47.978657 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:46:47.980560 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:46:47.981411 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:46:47.981927 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:46:47.982567 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:46:47.983806 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:46:47.987764 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:46:47.997229 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:46:47.999369 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:46:48.002862 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:46:48.013275 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:46:48.016304 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:46:48.021484 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:46:48.030683 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:46:48.043228 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:46:48.294386 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:46:48.306405 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:46:48.309997 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:46:48.313545 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:46:48.317469 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:46:48.324263 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:46:48.325349 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:46:48.328786 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:46:48.332127 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:46:48.335158 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:46:48.486504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dbd1a60>]}
21:46:48.492643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc99100>]}
21:46:48.492925 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:46:48.494480 [info ] [MainThread]: 
21:46:48.494879 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:46:48.495938 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:46:48.508221 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:46:48.508474 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:46:48.508625 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:46:49.532805 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.02 seconds
21:46:49.534615 [debug] [ThreadPool]: On list_analytics: Close
21:46:49.676731 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:46:49.684246 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:46:49.684499 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:46:49.684697 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:46:50.465182 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.78 seconds
21:46:50.467312 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:46:50.605055 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:46:50.605591 [info ] [MainThread]: 
21:46:50.610038 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:46:50.610437 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:46:50.611000 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:46:50.611215 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:46:50.611442 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:46:50.617745 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:46:50.618421 [debug] [Thread-1  ]: finished collecting timing info
21:46:50.618663 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:46:50.668572 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:46:50.668878 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:46:50.669077 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:46:51.379268 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a1801a-0000-6584-0000-00016cc24715
21:46:51.379626 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:46:51.380051 [debug] [Thread-1  ]: finished collecting timing info
21:46:51.380291 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:46:51.521423 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:46:51.521920 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff67c40>]}
21:46:51.522392 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.91s]
21:46:51.522890 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:46:51.523194 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:46:51.523617 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:46:51.524159 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:46:51.524376 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:46:51.524586 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:46:51.528258 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:46:51.528924 [debug] [Thread-1  ]: finished collecting timing info
21:46:51.529169 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:46:51.533064 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:51.533312 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:46:51.533548 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:46:53.439469 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.91 seconds
21:46:53.450877 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.451118 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:46:53.553014 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:46:53.559042 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.559270 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:46:53.653039 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:46:53.663557 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.663789 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:46:53.786188 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
21:46:53.811834 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:46:53.813631 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.813843 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:46:53.921649 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:46:53.922204 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.922503 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:46:54.653062 [debug] [Thread-1  ]: SQL status: SUCCESS 415 in 0.73 seconds
21:46:54.653531 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:54.653855 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:46:54.922475 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
21:46:54.924953 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:54.925179 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

        grant select on analytics.dbt.incremental_dates to role analyst
21:46:55.036021 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:46:55.047729 [debug] [Thread-1  ]: finished collecting timing info
21:46:55.048024 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:46:55.204675 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dee9700>]}
21:46:55.205239 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.68s]
21:46:55.205722 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:46:55.206031 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:46:55.206518 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:46:55.207084 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:46:55.207301 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:46:55.207504 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:46:55.210033 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:46:55.210603 [debug] [Thread-1  ]: finished collecting timing info
21:46:55.210821 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:46:55.221347 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:46:55.222585 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:46:55.222802 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:46:55.222991 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:46:56.327096 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.1 seconds
21:46:56.330339 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:46:56.330600 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant select on analytics.dbt.first_model to role analyst
21:46:56.435430 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
21:46:56.437782 [debug] [Thread-1  ]: finished collecting timing info
21:46:56.438073 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:46:56.617387 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11007a880>]}
21:46:56.617951 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.41s]
21:46:56.618438 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:46:56.618725 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:46:56.619308 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:46:56.619917 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:46:56.620167 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:46:56.620423 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:46:56.621937 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:46:56.622530 [debug] [Thread-1  ]: finished collecting timing info
21:46:56.622753 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:46:56.625321 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:46:56.626151 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:46:56.626382 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:46:56.626579 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:14.476524 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.85 seconds
21:47:14.479194 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:47:14.479418 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        grant select on analytics.dbt.playing_with_tests to role analyst
21:47:14.616544 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
21:47:14.618213 [debug] [Thread-1  ]: finished collecting timing info
21:47:14.618468 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:47:14.760332 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff8e1c0>]}
21:47:14.760874 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 18.14s]
21:47:14.761349 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:47:14.761641 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.762116 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:47:14.762761 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.763024 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.763276 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.764728 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.765314 [debug] [Thread-1  ]: finished collecting timing info
21:47:14.765539 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.768818 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.769914 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.770132 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:47:14.770329 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:16.614357 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
21:47:16.617714 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:16.617983 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */

        grant select on analytics.dbt.snowflake_cumulative_orders_by_date to role analyst
21:47:16.716094 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
21:47:16.718449 [debug] [Thread-1  ]: finished collecting timing info
21:47:16.718742 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:47:16.862470 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110074f70>]}
21:47:16.862957 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 2.10s]
21:47:16.863358 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:16.863602 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:47:16.863994 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:47:16.864499 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:47:16.864706 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:47:16.864906 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:47:16.866281 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:47:16.866838 [debug] [Thread-1  ]: finished collecting timing info
21:47:16.867052 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:47:16.869461 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:47:16.870606 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:47:16.870813 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:47:16.871003 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:18.628120 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.76 seconds
21:47:18.631410 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:47:18.631666 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        grant select on analytics.dbt.snowflake_customer_purchases to role analyst
21:47:18.723771 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.09 seconds
21:47:18.725952 [debug] [Thread-1  ]: finished collecting timing info
21:47:18.726325 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:47:18.862278 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100742e0>]}
21:47:18.862776 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.00s]
21:47:18.863187 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:47:18.863440 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:47:18.863841 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:47:18.864396 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.864624 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:47:18.864835 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:47:18.866282 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.866925 [debug] [Thread-1  ]: finished collecting timing info
21:47:18.867145 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:47:18.870285 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.871539 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.871791 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:47:18.871992 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:20.166781 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
21:47:20.170060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:47:20.170312 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */

        grant select on analytics.dbt.snowflake_nation_customer_count to role analyst
21:47:20.285059 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:47:20.287064 [debug] [Thread-1  ]: finished collecting timing info
21:47:20.287361 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:47:20.425242 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e017dc0>]}
21:47:20.425820 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.56s]
21:47:20.426320 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:47:20.426611 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:47:20.427063 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:47:20.427678 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:47:20.427925 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:47:20.428168 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:47:20.431743 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:47:20.432347 [debug] [Thread-1  ]: finished collecting timing info
21:47:20.432588 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:47:20.434902 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:47:20.435790 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:47:20.436014 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:47:20.436225 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:21.510611 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.07 seconds
21:47:21.513886 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:47:21.514144 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        grant select on analytics.dbt.my_second_dbt_model to role analyst
21:47:21.625352 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:47:21.627713 [debug] [Thread-1  ]: finished collecting timing info
21:47:21.628007 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:47:21.907547 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff5f8b0>]}
21:47:21.908058 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.48s]
21:47:21.908467 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:47:21.909778 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:47:21.910476 [info ] [MainThread]: 
21:47:21.910885 [info ] [MainThread]: Finished running 2 incremental models, 6 table models in 33.42s.
21:47:21.911314 [debug] [MainThread]: Connection 'master' was properly closed.
21:47:21.911522 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:47:21.918380 [info ] [MainThread]: 
21:47:21.918906 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:47:21.919304 [info ] [MainThread]: 
21:47:21.919735 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:47:21.920170 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:47:21.920645 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:47:21.921185 [info ] [MainThread]: 
21:47:21.921673 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:47:21.922168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dbd1cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc99430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110095430>]}


============================== 2022-01-08 21:49:27.432203 | 29d36611-2249-49ad-82bd-f8ff34c16dd6 ==============================
21:49:27.432203 [info ] [MainThread]: Running with dbt=1.0.1
21:49:27.432930 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:49:27.433166 [debug] [MainThread]: Tracking: tracking
21:49:27.433569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047d56a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047d51f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047d51c0>]}
21:49:27.457021 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:49:27.457465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047cbd00>]}
21:49:27.491924 [debug] [MainThread]: Parsing macros/catalog.sql
21:49:27.494631 [debug] [MainThread]: Parsing macros/adapters.sql
21:49:27.535837 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:49:27.539505 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:49:27.544377 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:49:27.545650 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:49:27.548544 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:49:27.556583 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:49:27.557490 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:49:27.561073 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:49:27.563244 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:49:27.564782 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:49:27.580506 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:49:27.591049 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:49:27.602051 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:49:27.606217 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:49:27.607859 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:49:27.609553 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:49:27.613671 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:49:27.623752 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:49:27.625065 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:49:27.634049 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:49:27.648014 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:49:27.654513 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:49:27.657190 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:49:27.663680 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:49:27.664827 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:49:27.667303 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:49:27.669357 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:49:27.674729 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:49:27.689949 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:49:27.691368 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:49:27.693511 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:49:27.694880 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:49:27.695654 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:49:27.696152 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:49:27.696773 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:49:27.698030 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:49:27.701845 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:49:27.709257 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:49:27.711238 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:49:27.713588 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:49:27.722520 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:49:27.743940 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:49:27.749907 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:49:27.758971 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:49:27.770372 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:49:27.953184 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
21:49:27.964772 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
21:49:27.965748 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:49:27.967821 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:49:27.970319 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:49:27.972293 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:49:27.978270 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:49:27.979133 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:49:27.981171 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:49:27.983086 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:49:27.986345 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:49:28.132903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048a16d0>]}
21:49:28.138515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048ab760>]}
21:49:28.138841 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:49:28.140582 [info ] [MainThread]: 
21:49:28.141046 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:49:28.142131 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:49:28.154469 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:49:28.154712 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:49:28.154862 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:49:28.992954 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.84 seconds
21:49:28.995098 [debug] [ThreadPool]: On list_analytics: Close
21:49:29.164757 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:49:29.172713 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:49:29.172958 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:49:29.173159 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:49:29.688585 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.52 seconds
21:49:29.690472 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:49:29.841618 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:49:29.842087 [info ] [MainThread]: 
21:49:29.845475 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:49:29.845852 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:49:29.846421 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:49:29.846644 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:49:29.846867 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:49:29.853263 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:49:29.853956 [debug] [Thread-1  ]: finished collecting timing info
21:49:29.854205 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:49:29.903122 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:49:29.903411 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:49:29.903595 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:30.533829 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a1801d-0000-65ab-0000-00016cc238e1
21:49:30.534180 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:49:30.534572 [debug] [Thread-1  ]: finished collecting timing info
21:49:30.534846 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:49:30.672210 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:49:30.672712 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b987f0>]}
21:49:30.673200 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.83s]
21:49:30.673694 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:49:30.673988 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:49:30.674511 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:49:30.675141 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:49:30.675401 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:49:30.675617 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:49:30.679375 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:49:30.680025 [debug] [Thread-1  ]: finished collecting timing info
21:49:30.680261 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:49:30.684029 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:30.684327 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:49:30.684539 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:32.675427 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.99 seconds
21:49:32.686918 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:32.687152 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:49:32.787518 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:49:32.792640 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:32.792895 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:49:32.911529 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
21:49:32.921868 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:32.922105 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:49:33.011520 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:49:33.038905 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:49:33.040682 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:33.040902 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:49:33.171562 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
21:49:33.172120 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:33.172423 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:49:33.813090 [debug] [Thread-1  ]: SQL status: SUCCESS 159 in 0.64 seconds
21:49:33.813556 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:33.813855 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:49:34.111341 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.3 seconds
21:49:34.123884 [debug] [Thread-1  ]: finished collecting timing info
21:49:34.124146 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:49:34.282710 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bda550>]}
21:49:34.283276 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.61s]
21:49:34.283776 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:49:34.284073 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:49:34.284535 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:49:34.285180 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:49:34.285435 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:49:34.285683 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:49:34.288668 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:49:34.289298 [debug] [Thread-1  ]: finished collecting timing info
21:49:34.289532 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:49:34.301095 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:49:34.302454 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:49:34.302731 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:49:34.302985 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:35.782411 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
21:49:35.785201 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:49:35.785435 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant select on analytics.dbt.first_model to role analyst
21:49:35.911434 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
21:49:35.913785 [debug] [Thread-1  ]: finished collecting timing info
21:49:35.914081 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:49:36.073553 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d3aa00>]}
21:49:36.074118 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.79s]
21:49:36.074593 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:49:36.074884 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:49:36.075457 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:49:36.076090 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:49:36.076404 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:49:36.076681 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:49:36.078134 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:49:36.078716 [debug] [Thread-1  ]: finished collecting timing info
21:49:36.078940 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:49:36.081448 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:49:36.082281 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:49:36.082500 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:49:36.082699 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:54.023100 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.94 seconds
21:49:54.025614 [debug] [Thread-1  ]: finished collecting timing info
21:49:54.025907 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:49:54.463888 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b234f0>]}
21:49:54.464445 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 18.39s]
21:49:54.464920 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:49:54.465227 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.465684 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:49:54.466306 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.466556 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.466798 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.468274 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.468851 [debug] [Thread-1  ]: finished collecting timing info
21:49:54.469082 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.471533 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.472560 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.472779 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:49:54.472975 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:56.161549 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.69 seconds
21:49:56.164033 [debug] [Thread-1  ]: finished collecting timing info
21:49:56.164326 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:49:56.329136 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bda640>]}
21:49:56.329702 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 1.86s]
21:49:56.330179 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:56.330475 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:49:56.331129 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:49:56.331756 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:49:56.332012 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:49:56.332246 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:49:56.333675 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:49:56.334238 [debug] [Thread-1  ]: finished collecting timing info
21:49:56.334464 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:49:56.336897 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:49:56.338089 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:49:56.338310 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:49:56.338510 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:58.090516 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
21:49:58.092422 [debug] [Thread-1  ]: finished collecting timing info
21:49:58.092698 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:49:58.263740 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bdaa30>]}
21:49:58.264304 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.93s]
21:49:58.264778 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:49:58.265070 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:49:58.265543 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:49:58.266138 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.266387 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:49:58.266638 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:49:58.268044 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.268606 [debug] [Thread-1  ]: finished collecting timing info
21:49:58.268830 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:49:58.271261 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.272398 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.272615 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:49:58.272813 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:59.614202 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
21:49:59.616710 [debug] [Thread-1  ]: finished collecting timing info
21:49:59.617015 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:49:59.766130 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bf11f0>]}
21:49:59.766693 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.50s]
21:49:59.767177 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:49:59.767447 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:49:59.767839 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:49:59.768371 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:49:59.768585 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:49:59.768792 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:49:59.771117 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:49:59.771683 [debug] [Thread-1  ]: finished collecting timing info
21:49:59.771907 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:49:59.774325 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:49:59.775191 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:49:59.775408 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:49:59.775605 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:50:01.117764 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
21:50:01.119905 [debug] [Thread-1  ]: finished collecting timing info
21:50:01.120204 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:50:01.263345 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bf10a0>]}
21:50:01.263910 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.50s]
21:50:01.264380 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:50:01.265615 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:50:01.266064 [info ] [MainThread]: 
21:50:01.266418 [info ] [MainThread]: Finished running 2 incremental models, 6 table models in 33.13s.
21:50:01.266748 [debug] [MainThread]: Connection 'master' was properly closed.
21:50:01.266941 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:50:01.273754 [info ] [MainThread]: 
21:50:01.274128 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:50:01.274483 [info ] [MainThread]: 
21:50:01.274807 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:50:01.275105 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:50:01.275399 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:50:01.275701 [info ] [MainThread]: 
21:50:01.275994 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:50:01.276372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bea640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048abf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d37d90>]}


============================== 2022-01-08 21:52:28.283257 | 4874a80c-cec7-49f2-a4b2-55f78c0ecd63 ==============================
21:52:28.283257 [info ] [MainThread]: Running with dbt=1.0.1
21:52:28.284096 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:52:28.284549 [debug] [MainThread]: Tracking: tracking
21:52:28.285075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104928d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104928f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103c40850>]}
21:52:28.310642 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:52:28.311076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103c21eb0>]}
21:52:28.349208 [debug] [MainThread]: Parsing macros/catalog.sql
21:52:28.351787 [debug] [MainThread]: Parsing macros/adapters.sql
21:52:28.392703 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:52:28.396470 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:52:28.401326 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:52:28.402601 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:52:28.405483 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:52:28.413546 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:52:28.414458 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:52:28.418025 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:52:28.420199 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:52:28.421738 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:52:28.437799 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:52:28.448508 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:52:28.459506 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:52:28.463710 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:52:28.465377 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:52:28.467060 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:52:28.471170 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:52:28.481908 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:52:28.483482 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:52:28.493734 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:52:28.508554 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:52:28.515505 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:52:28.518176 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:52:28.524724 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:52:28.525918 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:52:28.528368 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:52:28.530475 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:52:28.536986 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:52:28.552680 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:52:28.554104 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:52:28.556433 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:52:28.557867 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:52:28.558681 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:52:28.559201 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:52:28.559848 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:52:28.561090 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:52:28.565151 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:52:28.572795 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:52:28.575050 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:52:28.577518 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:52:28.587157 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:52:28.589918 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:52:28.594030 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:52:28.600835 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:52:28.609752 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:52:28.808336 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:52:28.818866 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:52:28.820957 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:52:28.823158 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:52:28.825287 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:52:28.831693 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:52:28.832624 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:52:28.834705 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:52:28.836905 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:52:28.840443 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:52:29.004802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1038427f0>]}
21:52:29.011023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048f8190>]}
21:52:29.011332 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 3 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:52:29.013073 [info ] [MainThread]: 
21:52:29.013532 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:52:29.014599 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:52:29.027521 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:52:29.027785 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:52:29.027942 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:52:29.879087 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.85 seconds
21:52:29.881267 [debug] [ThreadPool]: On list_analytics: Close
21:52:30.066787 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:52:30.074871 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:52:30.075122 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:52:30.075336 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:52:30.737132 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.66 seconds
21:52:30.739601 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:52:31.366220 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:52:31.366729 [info ] [MainThread]: 
21:52:31.370389 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:52:31.370772 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:52:31.371334 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:52:31.371554 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:52:31.371781 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:52:31.378931 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:52:31.380499 [debug] [Thread-1  ]: finished collecting timing info
21:52:31.380769 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:52:31.431799 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:52:31.432114 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:52:31.432316 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:31.917637 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a18020-0000-65ab-0000-00016cc23915
21:52:31.917980 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:52:31.918374 [debug] [Thread-1  ]: finished collecting timing info
21:52:31.918652 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:52:32.124068 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:52:32.124568 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d2c580>]}
21:52:32.125042 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.75s]
21:52:32.125535 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:52:32.125827 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:52:32.126347 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:52:32.126950 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:52:32.127205 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:52:32.127418 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:52:32.131107 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:52:32.131747 [debug] [Thread-1  ]: finished collecting timing info
21:52:32.131975 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:52:32.135735 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:32.136040 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:52:32.136286 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:34.640678 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.5 seconds
21:52:34.652251 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:34.652504 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:52:34.771987 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
21:52:34.777037 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:34.777299 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:52:34.913553 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
21:52:34.924765 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:34.924998 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:52:35.016763 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:52:35.043620 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:52:35.046511 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:35.046733 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:52:35.176979 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
21:52:35.177439 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:35.177722 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:52:35.824036 [debug] [Thread-1  ]: SQL status: SUCCESS 182 in 0.65 seconds
21:52:35.824372 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:35.824572 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:52:36.113293 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.29 seconds
21:52:36.126160 [debug] [Thread-1  ]: finished collecting timing info
21:52:36.126473 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:52:36.273801 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d5b370>]}
21:52:36.274354 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 4.15s]
21:52:36.274822 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:52:36.275106 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:52:36.275552 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:52:36.276158 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:52:36.276404 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:52:36.276651 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:52:36.279312 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:52:36.279871 [debug] [Thread-1  ]: finished collecting timing info
21:52:36.280085 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:52:36.290632 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:52:36.292338 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:52:36.292802 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:52:36.293037 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:37.313343 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
21:52:37.315803 [debug] [Thread-1  ]: finished collecting timing info
21:52:37.316088 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:52:37.465779 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d5be80>]}
21:52:37.466325 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.19s]
21:52:37.466788 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:52:37.467071 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:52:37.467616 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:52:37.468231 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:52:37.468478 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:52:37.468714 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:52:37.470132 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:52:37.470696 [debug] [Thread-1  ]: finished collecting timing info
21:52:37.470915 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:52:37.473339 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:52:37.474203 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:52:37.474424 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:52:37.474618 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:54.362685 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 16.89 seconds
21:52:54.364345 [debug] [Thread-1  ]: finished collecting timing info
21:52:54.364562 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:52:54.515393 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fa0280>]}
21:52:54.515946 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 17.05s]
21:52:54.516409 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:52:54.516694 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:52:54.517173 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:52:54.517793 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:52:54.518051 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:52:54.518261 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:52:54.519659 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:52:54.520245 [debug] [Thread-1  ]: finished collecting timing info
21:52:54.520471 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:52:54.522900 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:52:54.523971 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:52:54.524195 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:52:54.524398 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:56.674349 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.15 seconds
21:52:56.676322 [debug] [Thread-1  ]: finished collecting timing info
21:52:56.676640 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:52:56.865298 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d58e20>]}
21:52:56.865791 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 2.35s]
21:52:56.866183 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:52:56.866426 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:52:56.866816 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:52:56.867324 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:52:56.867529 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:52:56.867733 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:52:56.869182 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:52:56.869784 [debug] [Thread-1  ]: finished collecting timing info
21:52:56.870013 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:52:56.872946 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:52:56.874364 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:52:56.874650 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:52:56.874852 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:59.529804 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.65 seconds
21:52:59.531944 [debug] [Thread-1  ]: finished collecting timing info
21:52:59.532238 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:53:00.092926 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d58370>]}
21:53:00.093416 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.23s]
21:53:00.093931 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:53:00.094497 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:53:00.095026 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:53:00.095616 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:53:00.095840 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:53:00.096053 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:53:00.097447 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:53:00.098852 [debug] [Thread-1  ]: finished collecting timing info
21:53:00.099083 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:53:00.101450 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:53:00.102839 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:53:00.103052 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:53:00.103245 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:53:01.565395 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.46 seconds
21:53:01.567651 [debug] [Thread-1  ]: finished collecting timing info
21:53:01.567994 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:53:01.716080 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d58610>]}
21:53:01.716645 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.62s]
21:53:01.717132 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:53:01.717426 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:53:01.717839 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:53:01.718366 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:53:01.718578 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:53:01.718786 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:53:01.721129 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:53:01.723023 [debug] [Thread-1  ]: finished collecting timing info
21:53:01.723374 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:53:01.726200 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:53:01.727178 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:53:01.727431 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:53:01.727695 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:53:03.313281 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
21:53:03.315558 [debug] [Thread-1  ]: finished collecting timing info
21:53:03.315863 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:53:03.475550 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d58d00>]}
21:53:03.476109 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.76s]
21:53:03.476577 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:53:03.477763 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:53:03.478032 [info ] [MainThread]: 
21:53:03.478366 [info ] [MainThread]: Running 3 on-run-end hooks
21:53:03.478721 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
21:53:03.480040 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
21:53:03.481757 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
21:53:03.482357 [debug] [MainThread]: Using snowflake connection "master"
21:53:03.482639 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
21:53:03.482861 [debug] [MainThread]: Opening a new connection, currently in state init
21:53:03.980133 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.5 seconds
21:53:03.981325 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.50s]
21:53:03.981918 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
21:53:03.983493 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
21:53:03.985124 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
21:53:03.985764 [debug] [MainThread]: Using snowflake connection "master"
21:53:03.985983 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
21:53:04.165673 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.18 seconds
21:53:04.167106 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.18s]
21:53:04.167686 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
21:53:04.169438 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
21:53:04.171357 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
21:53:04.172047 [debug] [MainThread]: Using snowflake connection "master"
21:53:04.172316 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
21:53:04.264552 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
21:53:04.265870 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
21:53:04.266340 [info ] [MainThread]: 
21:53:04.266754 [debug] [MainThread]: On master: Close
21:53:04.414491 [info ] [MainThread]: 
21:53:04.414925 [info ] [MainThread]: Finished running 2 incremental models, 6 table models, 3 hooks in 35.40s.
21:53:04.415286 [debug] [MainThread]: Connection 'master' was properly closed.
21:53:04.415504 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:53:04.422669 [info ] [MainThread]: 
21:53:04.423078 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:53:04.423490 [info ] [MainThread]: 
21:53:04.424040 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:53:04.424683 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:53:04.425234 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:53:04.425814 [info ] [MainThread]: 
21:53:04.426276 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:53:04.426903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d043970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d5b580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d046f70>]}


============================== 2022-01-08 21:54:31.541137 | f4da1160-83d0-48ec-b141-ea6cdf1e46d8 ==============================
21:54:31.541137 [info ] [MainThread]: Running with dbt=1.0.1
21:54:31.541771 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:54:31.542008 [debug] [MainThread]: Tracking: tracking
21:54:31.542373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca30d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca32b0>]}
21:54:31.568723 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:54:31.569149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc91c10>]}
21:54:31.604543 [debug] [MainThread]: Parsing macros/catalog.sql
21:54:31.607367 [debug] [MainThread]: Parsing macros/adapters.sql
21:54:31.653646 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:54:31.657262 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:54:31.662343 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:54:31.663694 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:54:31.666570 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:54:31.674629 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:54:31.675555 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:54:31.679179 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:54:31.681361 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:54:31.682917 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:54:31.698771 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:54:31.709507 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:54:31.721313 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:54:31.725460 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:54:31.727074 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:54:31.728721 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:54:31.733343 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:54:31.743770 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:54:31.745153 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:54:31.755294 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:54:31.769737 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:54:31.776524 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:54:31.779173 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:54:31.785745 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:54:31.786946 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:54:31.789476 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:54:31.791575 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:54:31.797133 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:54:31.812231 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:54:31.813758 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:54:31.816170 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:54:31.817623 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:54:31.818436 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:54:31.818968 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:54:31.819630 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:54:31.820894 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:54:31.824921 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:54:31.832743 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:54:31.834754 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:54:31.837320 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:54:31.846275 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:54:31.849001 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:54:31.853398 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:54:31.861011 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:54:31.871062 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:54:32.076492 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:54:32.090208 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:54:32.093114 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:54:32.096163 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:54:32.099402 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:54:32.107561 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:54:32.108810 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:54:32.111611 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:54:32.114981 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:54:32.121151 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:54:32.356598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be10af0>]}
21:54:32.366867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd7b3d0>]}
21:54:32.367290 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:54:32.370158 [info ] [MainThread]: 
21:54:32.371116 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:54:32.372597 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:54:32.388746 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:54:32.389071 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:54:32.389273 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:54:33.986821 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.6 seconds
21:54:33.988931 [debug] [ThreadPool]: On list_analytics: Close
21:54:34.146059 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:54:34.154349 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:54:34.154637 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:54:34.154844 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:54:34.943183 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.79 seconds
21:54:34.955886 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:54:35.119592 [info ] [MainThread]: 
21:54:35.134375 [info ] [MainThread]: Running 1 on-run-start hook
21:54:35.135491 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
21:54:35.153565 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
21:54:35.155313 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
21:54:35.155998 [debug] [MainThread]: Using snowflake connection "master"
21:54:35.156364 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
21:54:35.156641 [debug] [MainThread]: Opening a new connection, currently in state init
21:54:35.764385 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.61 seconds
21:54:35.765198 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.61s]
21:54:35.765517 [info ] [MainThread]: 
21:54:35.765776 [debug] [MainThread]: On master: Close
21:54:35.916226 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:54:35.916667 [info ] [MainThread]: 
21:54:35.919709 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:54:35.920088 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:54:35.920938 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:54:35.921156 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:54:35.921369 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:54:35.927896 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:54:35.928598 [debug] [Thread-1  ]: finished collecting timing info
21:54:35.928847 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:54:35.978979 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:54:35.979289 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:54:35.979481 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:54:36.469723 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a18022-0000-65ab-0000-00016cc23955
21:54:36.470094 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:54:36.470487 [debug] [Thread-1  ]: finished collecting timing info
21:54:36.470747 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:54:36.617599 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:54:36.618106 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11411d700>]}
21:54:36.618585 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.70s]
21:54:36.619101 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:54:36.619411 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:54:36.619914 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:54:36.620527 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:54:36.620771 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:54:36.620978 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:54:36.624696 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:54:36.625282 [debug] [Thread-1  ]: finished collecting timing info
21:54:36.625509 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:54:36.629276 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:36.629546 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:54:36.629757 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:54:37.997327 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.37 seconds
21:54:38.008838 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:38.009070 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:54:38.115645 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
21:54:38.120751 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:38.121014 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:54:38.220721 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:54:38.230955 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:38.231185 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:54:38.369915 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
21:54:38.396316 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:54:38.398060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:38.398272 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:54:38.591125 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
21:54:38.591681 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:38.591983 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:54:39.564587 [debug] [Thread-1  ]: SQL status: SUCCESS 124 in 0.97 seconds
21:54:39.564934 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:39.565137 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:54:39.815458 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
21:54:39.827930 [debug] [Thread-1  ]: finished collecting timing info
21:54:39.828197 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:54:39.969632 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11209abe0>]}
21:54:39.970157 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.35s]
21:54:39.970571 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:54:39.970823 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:54:39.971237 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:54:39.971794 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:54:39.972013 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:54:39.972224 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:54:39.975200 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:54:39.975852 [debug] [Thread-1  ]: finished collecting timing info
21:54:39.976102 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:54:39.991581 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:54:39.993996 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:54:39.994528 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:54:39.994950 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:54:41.491164 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
21:54:41.493765 [debug] [Thread-1  ]: finished collecting timing info
21:54:41.494053 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:54:41.717403 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11209a370>]}
21:54:41.717983 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.75s]
21:54:41.718455 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:54:41.718909 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:54:41.719247 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:54:41.719979 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:54:41.720318 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:54:41.720541 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:54:41.721946 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:54:41.722520 [debug] [Thread-1  ]: finished collecting timing info
21:54:41.722744 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:54:41.725240 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:54:41.726068 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:54:41.726291 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:54:41.726504 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:54:58.465665 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 16.74 seconds
21:54:58.468136 [debug] [Thread-1  ]: finished collecting timing info
21:54:58.468427 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:54:58.868016 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120daf40>]}
21:54:58.868573 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 17.15s]
21:54:58.869038 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:54:58.869322 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:54:58.869755 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:54:58.870373 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:54:58.870623 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:54:58.870867 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:54:58.872335 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:54:58.872920 [debug] [Thread-1  ]: finished collecting timing info
21:54:58.873146 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:54:58.875671 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:54:58.876738 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:54:58.876960 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:54:58.877159 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:55:00.716151 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
21:55:00.718419 [debug] [Thread-1  ]: finished collecting timing info
21:55:00.718752 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:55:00.872415 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf9aa60>]}
21:55:00.872980 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 2.00s]
21:55:00.873445 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:55:00.873730 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:55:00.874170 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:55:00.874759 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:55:00.875008 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:55:00.875249 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:55:00.876823 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:55:00.877407 [debug] [Thread-1  ]: finished collecting timing info
21:55:00.877677 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:55:00.880338 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:55:00.881572 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:55:00.881796 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:55:00.881992 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:55:02.594821 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
21:55:02.596682 [debug] [Thread-1  ]: finished collecting timing info
21:55:02.596941 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:55:02.767241 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be9b130>]}
21:55:02.767946 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.89s]
21:55:02.768665 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:55:02.769123 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:55:02.769635 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:55:02.770242 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:55:02.770534 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:55:02.770768 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:55:02.772201 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:55:02.772794 [debug] [Thread-1  ]: finished collecting timing info
21:55:02.773027 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:55:02.775688 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:55:02.776928 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:55:02.777181 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:55:02.777465 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:55:04.226211 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
21:55:04.228749 [debug] [Thread-1  ]: finished collecting timing info
21:55:04.229045 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:55:04.396939 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be9b730>]}
21:55:04.397517 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.63s]
21:55:04.397988 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:55:04.398277 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:55:04.398720 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:55:04.399332 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:55:04.399578 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:55:04.399817 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:55:04.402257 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:55:04.402822 [debug] [Thread-1  ]: finished collecting timing info
21:55:04.403045 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:55:04.405509 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:55:04.406402 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:55:04.406635 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:55:04.406835 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:55:05.816402 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.41 seconds
21:55:05.818815 [debug] [Thread-1  ]: finished collecting timing info
21:55:05.819104 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:55:05.979225 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be9b6d0>]}
21:55:05.979766 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.58s]
21:55:05.980235 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:55:05.981530 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:55:05.981875 [info ] [MainThread]: 
21:55:05.982206 [info ] [MainThread]: Running 3 on-run-end hooks
21:55:05.982650 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
21:55:05.984113 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
21:55:05.984927 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
21:55:05.985680 [debug] [MainThread]: Using snowflake connection "master"
21:55:05.985940 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
21:55:05.986138 [debug] [MainThread]: Opening a new connection, currently in state closed
21:55:06.788429 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.8 seconds
21:55:06.789444 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.80s]
21:55:06.789856 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
21:55:06.791151 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
21:55:06.791886 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
21:55:06.792464 [debug] [MainThread]: Using snowflake connection "master"
21:55:06.792665 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
21:55:06.965851 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.17 seconds
21:55:06.967271 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.17s]
21:55:06.967851 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
21:55:06.969594 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
21:55:06.970480 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
21:55:06.971184 [debug] [MainThread]: Using snowflake connection "master"
21:55:06.971396 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
21:55:07.067823 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
21:55:07.069238 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
21:55:07.069771 [info ] [MainThread]: 
21:55:07.070172 [debug] [MainThread]: On master: Close
21:55:07.218057 [info ] [MainThread]: 
21:55:07.218566 [info ] [MainThread]: Finished running 2 incremental models, 6 table models, 4 hooks in 34.85s.
21:55:07.218958 [debug] [MainThread]: Connection 'master' was properly closed.
21:55:07.219185 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:55:07.226463 [info ] [MainThread]: 
21:55:07.226866 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:55:07.227223 [info ] [MainThread]: 
21:55:07.227563 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:55:07.227868 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:55:07.228159 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:55:07.228480 [info ] [MainThread]: 
21:55:07.228822 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:55:07.229284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142987f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11420ce80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114295970>]}


============================== 2022-01-08 21:58:28.521563 | 28173d38-12d6-4ed8-a33b-a4d4a203618b ==============================
21:58:28.521563 [info ] [MainThread]: Running with dbt=1.0.1
21:58:28.522278 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:58:28.522539 [debug] [MainThread]: Tracking: tracking
21:58:28.522969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb00520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb00250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb002e0>]}
21:58:28.549572 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:58:28.550201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae15d30>]}
21:58:28.587660 [debug] [MainThread]: Parsing macros/catalog.sql
21:58:28.590485 [debug] [MainThread]: Parsing macros/adapters.sql
21:58:28.638174 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:58:28.641854 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:58:28.646919 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:58:28.648230 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:58:28.651142 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:58:28.659520 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:58:28.660436 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:58:28.664457 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:58:28.666707 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:58:28.668261 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:58:28.684592 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:58:28.696153 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:58:28.707715 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:58:28.712071 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:58:28.713728 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:58:28.715417 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:58:28.719642 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:58:28.731081 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:58:28.732657 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:58:28.742288 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:58:28.757295 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:58:28.765290 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:58:28.768206 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:58:28.775590 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:58:28.776861 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:58:28.779652 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:58:28.782007 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:58:28.788048 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:58:28.804131 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:58:28.805575 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:58:28.807945 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:58:28.809430 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:58:28.810248 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:58:28.810873 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:58:28.811536 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:58:28.812843 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:58:28.816976 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:58:28.825175 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:58:28.827320 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:58:28.830250 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:58:28.839719 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:58:28.842499 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:58:28.846722 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:58:28.853708 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:58:28.863464 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:58:29.060809 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:58:29.073850 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:58:29.077579 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:58:29.081205 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:58:29.085223 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:58:29.128976 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:58:29.130935 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:58:29.136205 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:58:29.141039 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:58:29.145286 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:58:29.301187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b669640>]}
21:58:29.309693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10baecc40>]}
21:58:29.310071 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:58:29.312110 [info ] [MainThread]: 
21:58:29.312803 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:58:29.314152 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:58:29.329497 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:58:29.329812 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:58:29.330024 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:58:30.377465 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.05 seconds
21:58:30.379554 [debug] [ThreadPool]: On list_analytics: Close
21:58:30.540740 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:58:30.548383 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:58:30.548637 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:58:30.548824 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:58:31.280427 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.73 seconds
21:58:31.282906 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:58:31.422241 [info ] [MainThread]: 
21:58:31.422676 [info ] [MainThread]: Running 1 on-run-start hook
21:58:31.423044 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
21:58:31.424375 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
21:58:31.426089 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
21:58:31.426736 [debug] [MainThread]: Using snowflake connection "master"
21:58:31.426944 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
21:58:31.427133 [debug] [MainThread]: Opening a new connection, currently in state init
21:58:31.929033 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.5 seconds
21:58:31.930526 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.50s]
21:58:31.931145 [info ] [MainThread]: 
21:58:31.931712 [debug] [MainThread]: On master: Close
21:58:32.074269 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:58:32.074712 [info ] [MainThread]: 
21:58:32.077942 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:58:32.078334 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:58:32.079245 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:58:32.079600 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:58:32.079845 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:58:32.087279 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:58:32.087937 [debug] [Thread-1  ]: finished collecting timing info
21:58:32.088219 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:58:32.138775 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:58:32.139071 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:58:32.139270 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:58:32.628102 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a18026-0000-6584-0000-00016cc2486d
21:58:32.645972 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:58:32.647014 [debug] [Thread-1  ]: finished collecting timing info
21:58:32.647407 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:58:32.810994 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:58:32.811499 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c067850>]}
21:58:32.811963 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.73s]
21:58:32.812447 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:58:32.812750 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:58:32.813283 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:58:32.814060 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:58:32.814305 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:58:32.814672 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:58:32.818758 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:58:32.819404 [debug] [Thread-1  ]: finished collecting timing info
21:58:32.819638 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:58:32.824092 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:32.824369 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

        insert into dbt.audit (model, state, time) values ('incremental_dates', 'starting model deployment', current_timestamp)
21:58:32.824563 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:58:34.274815 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
21:58:34.277551 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:34.277817 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:58:35.368233 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
21:58:35.379439 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:35.379719 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:58:35.480395 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:58:35.484698 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:35.484961 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:58:35.569177 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
21:58:35.578371 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:35.578658 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:58:35.675883 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:58:35.702585 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:58:35.704444 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:35.704664 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:58:35.811441 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:58:35.811994 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:35.812291 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:58:36.519567 [debug] [Thread-1  ]: SQL status: SUCCESS 237 in 0.71 seconds
21:58:36.519901 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:36.520102 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:58:36.766933 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
21:58:36.778916 [debug] [Thread-1  ]: finished collecting timing info
21:58:36.779255 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:58:36.917071 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf6c790>]}
21:58:36.917648 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 4.10s]
21:58:36.918129 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:58:36.918428 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:58:36.918810 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:58:36.919344 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:58:36.919556 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:58:36.919763 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:58:36.922594 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:58:36.923128 [debug] [Thread-1  ]: finished collecting timing info
21:58:36.923353 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:58:36.935577 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:58:36.935854 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
21:58:36.936063 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:58:37.961905 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
21:58:37.964125 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:58:37.965480 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:58:37.965730 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:58:38.841017 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.88 seconds
21:58:38.843155 [debug] [Thread-1  ]: finished collecting timing info
21:58:38.843454 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:58:38.993817 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf6ceb0>]}
21:58:38.994429 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.07s]
21:58:38.994898 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:58:38.995185 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:58:38.995735 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:58:38.996291 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:58:38.996523 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:58:38.996738 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:58:38.998181 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:58:38.998730 [debug] [Thread-1  ]: finished collecting timing info
21:58:38.998952 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:58:39.002448 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:58:39.002680 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
21:58:39.002879 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:58:39.986905 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
21:58:39.989175 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:58:39.990174 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:58:39.990423 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:58:57.184566 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.19 seconds
21:58:57.186417 [debug] [Thread-1  ]: finished collecting timing info
21:58:57.186708 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:58:57.326537 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf72d30>]}
21:58:57.327102 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 18.33s]
21:58:57.327594 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:58:57.327900 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:58:57.328326 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:58:57.328936 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:58:57.329188 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:58:57.329434 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:58:57.330876 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:58:57.331493 [debug] [Thread-1  ]: finished collecting timing info
21:58:57.331767 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:58:57.336354 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:58:57.336623 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_orders_by_date', 'starting model deployment', current_timestamp)
21:58:57.336826 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:58:58.460954 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
21:58:58.463301 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:58:58.464598 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:58:58.464855 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:58:59.360305 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.9 seconds
21:58:59.362202 [debug] [Thread-1  ]: finished collecting timing info
21:58:59.362469 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:58:59.511403 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf6cfa0>]}
21:58:59.511955 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 2.18s]
21:58:59.512420 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:58:59.512708 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:58:59.513155 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:58:59.513767 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:58:59.514017 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:58:59.514265 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:58:59.515845 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:58:59.516481 [debug] [Thread-1  ]: finished collecting timing info
21:58:59.516714 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:58:59.520264 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:58:59.520488 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
21:58:59.520686 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:59:00.376900 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
21:59:00.379203 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:59:00.380660 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:59:00.380926 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:59:01.859017 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
21:59:01.861540 [debug] [Thread-1  ]: finished collecting timing info
21:59:01.861835 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:59:01.994458 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf6c0d0>]}
21:59:01.995041 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.48s]
21:59:01.995519 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:59:01.995811 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:59:01.996313 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:59:01.996937 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:59:01.997212 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:59:01.997427 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:59:01.998871 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:59:01.999449 [debug] [Thread-1  ]: finished collecting timing info
21:59:01.999677 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:59:02.003159 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:59:02.003390 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */

        insert into dbt.audit (model, state, time) values ('snowflake_nation_customer_count', 'starting model deployment', current_timestamp)
21:59:02.003592 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:59:02.845185 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
21:59:02.847405 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:59:02.848752 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:59:02.849007 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:59:03.780689 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
21:59:03.782986 [debug] [Thread-1  ]: finished collecting timing info
21:59:03.783307 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:59:04.161310 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf53b20>]}
21:59:04.161895 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 2.16s]
21:59:04.162370 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:59:04.162663 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:59:04.163140 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:59:04.163756 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:59:04.164007 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:59:04.164267 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:59:04.166723 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:59:04.167304 [debug] [Thread-1  ]: finished collecting timing info
21:59:04.167528 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:59:04.171134 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:59:04.171386 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
21:59:04.171576 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:59:05.176210 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
21:59:05.178076 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:59:05.179080 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:59:05.179298 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:59:06.208911 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
21:59:06.211382 [debug] [Thread-1  ]: finished collecting timing info
21:59:06.211674 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:59:06.574190 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcccdf0>]}
21:59:06.574748 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.41s]
21:59:06.575154 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:59:06.576355 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:59:06.576621 [info ] [MainThread]: 
21:59:06.576954 [info ] [MainThread]: Running 3 on-run-end hooks
21:59:06.577308 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
21:59:06.578628 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
21:59:06.579445 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
21:59:06.580013 [debug] [MainThread]: Using snowflake connection "master"
21:59:06.580218 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
21:59:06.580406 [debug] [MainThread]: Opening a new connection, currently in state closed
21:59:07.066713 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.49 seconds
21:59:07.068149 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.49s]
21:59:07.068750 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
21:59:07.070238 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
21:59:07.071113 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
21:59:07.071837 [debug] [MainThread]: Using snowflake connection "master"
21:59:07.072080 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
21:59:07.222000 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.15 seconds
21:59:07.223407 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.15s]
21:59:07.223969 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
21:59:07.225684 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
21:59:07.226530 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
21:59:07.227218 [debug] [MainThread]: Using snowflake connection "master"
21:59:07.227507 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
21:59:07.383763 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
21:59:07.385184 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.16s]
21:59:07.385718 [info ] [MainThread]: 
21:59:07.386126 [debug] [MainThread]: On master: Close
21:59:07.524008 [info ] [MainThread]: 
21:59:07.524517 [info ] [MainThread]: Finished running 2 incremental models, 6 table models, 4 hooks in 38.21s.
21:59:07.524912 [debug] [MainThread]: Connection 'master' was properly closed.
21:59:07.525146 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:59:07.532704 [info ] [MainThread]: 
21:59:07.533151 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:59:07.533558 [info ] [MainThread]: 
21:59:07.533886 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:59:07.534205 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:59:07.534514 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:59:07.534840 [info ] [MainThread]: 
21:59:07.535159 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:59:07.535604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf72eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df90610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0f2790>]}
