

============================== 2022-01-08 21:09:20.122417 | 01904cb0-62d6-4b01-8491-59378ad5a7a3 ==============================
21:09:20.122417 [info ] [MainThread]: Running with dbt=1.0.1
21:09:20.123092 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:09:20.123341 [debug] [MainThread]: Tracking: tracking
21:09:20.123716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11106df40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cf3e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cf34f0>]}
21:09:20.138890 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
21:09:20.139238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d6d160>]}
21:09:20.177091 [debug] [MainThread]: Parsing macros/catalog.sql
21:09:20.179241 [debug] [MainThread]: Parsing macros/adapters.sql
21:09:20.217042 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:09:20.220647 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:09:20.225505 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:09:20.226762 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:09:20.229590 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:09:20.237646 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:09:20.238707 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:09:20.242562 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:09:20.244690 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:09:20.246186 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:09:20.261677 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:09:20.271982 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:09:20.282731 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:09:20.287015 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:09:20.288629 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:09:20.290264 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:09:20.294280 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:09:20.304617 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:09:20.305979 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:09:20.315402 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:09:20.329735 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:09:20.336468 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:09:20.339177 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:09:20.345706 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:09:20.346910 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:09:20.349278 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:09:20.351293 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:09:20.356561 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:09:20.371175 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:09:20.372482 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:09:20.374637 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:09:20.376005 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:09:20.376771 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:09:20.377267 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:09:20.377876 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:09:20.379061 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:09:20.383051 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:09:20.390625 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:09:20.392527 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:09:20.394866 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:09:20.403365 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:09:20.405913 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:09:20.409889 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:09:20.416343 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:09:20.425048 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:09:20.606382 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:09:20.616491 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:09:20.618417 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:09:20.620610 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:09:20.622563 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:09:20.629748 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:09:20.630835 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:09:20.633282 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:09:20.635895 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:09:20.639421 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:09:20.784705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c350a0>]}
21:09:20.793342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cf24f0>]}
21:09:20.793677 [info ] [MainThread]: Found 8 models, 19 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:09:20.795619 [info ] [MainThread]: 
21:09:20.796106 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:09:20.797273 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:09:20.811111 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:09:20.811312 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:09:20.811487 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:09:21.742974 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.93 seconds
21:09:21.744802 [debug] [ThreadPool]: On list_analytics: Close
21:09:21.924549 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:09:21.932393 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:09:21.932609 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:09:21.932788 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:09:22.756818 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.82 seconds
21:09:22.758695 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:09:22.894571 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:09:22.895052 [info ] [MainThread]: 
21:09:22.902170 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:09:22.902637 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:09:22.903267 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:09:22.903504 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:09:22.903740 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:09:22.909656 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:09:22.910507 [debug] [Thread-1  ]: finished collecting timing info
21:09:22.910728 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:09:22.958148 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:09:22.958440 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:09:22.958627 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:23.554999 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a17ff5-0000-65ab-0000-00016cc23611
21:09:23.555447 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:09:23.555936 [debug] [Thread-1  ]: finished collecting timing info
21:09:23.556236 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:09:23.701224 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:09:23.701637 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11411e910>]}
21:09:23.702037 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.80s]
21:09:23.702426 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:09:23.702661 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:09:23.703054 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:09:23.703543 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:09:23.703741 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:09:23.703930 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:09:23.707407 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:09:23.708006 [debug] [Thread-1  ]: finished collecting timing info
21:09:23.708210 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:09:23.711720 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:23.711930 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:09:23.712144 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:25.459007 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
21:09:25.470243 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:25.470456 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:09:25.586572 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
21:09:25.591697 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:25.591936 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:09:25.756916 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.16 seconds
21:09:25.767156 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:25.767382 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:09:25.995499 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.23 seconds
21:09:26.022617 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:09:26.024652 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:26.024848 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:09:26.133641 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:09:26.134138 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:26.134410 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:09:27.052556 [debug] [Thread-1  ]: SQL status: SUCCESS 504 in 0.92 seconds
21:09:27.053003 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:27.053274 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:09:27.324459 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
21:09:27.336783 [debug] [Thread-1  ]: finished collecting timing info
21:09:27.337023 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:09:27.492699 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d8400>]}
21:09:27.493272 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.79s]
21:09:27.493706 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:09:27.493970 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:09:27.494282 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:09:27.494977 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:09:27.495217 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:09:27.495447 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:09:27.498250 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:09:27.498783 [debug] [Thread-1  ]: finished collecting timing info
21:09:27.498992 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:09:27.508929 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:09:27.510065 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:09:27.510281 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:09:27.510466 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:29.211416 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.7 seconds
21:09:29.213844 [debug] [Thread-1  ]: finished collecting timing info
21:09:29.214114 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:09:29.350255 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d86a0>]}
21:09:29.350796 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.86s]
21:09:29.351232 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:09:29.351501 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:09:29.351918 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:09:29.352531 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:09:29.352774 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:09:29.353026 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:09:29.354558 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:09:29.355067 [debug] [Thread-1  ]: finished collecting timing info
21:09:29.355272 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:09:29.357595 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:09:29.358378 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:09:29.358577 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:09:29.358755 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:45.835472 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 16.48 seconds
21:09:45.837932 [debug] [Thread-1  ]: finished collecting timing info
21:09:45.838210 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:09:46.001963 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d8940>]}
21:09:46.002523 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 16.65s]
21:09:46.002962 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:09:46.003233 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.003655 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:09:46.004238 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.004470 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.004692 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.006100 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.006621 [debug] [Thread-1  ]: finished collecting timing info
21:09:46.006828 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.009118 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.010107 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.010309 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:09:46.010492 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:47.530880 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
21:09:47.533334 [debug] [Thread-1  ]: finished collecting timing info
21:09:47.533611 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:09:47.712870 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d85e0>]}
21:09:47.713400 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 1.71s]
21:09:47.713835 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:47.714105 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:09:47.714436 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:09:47.715006 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:09:47.715263 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:09:47.715601 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:09:47.717088 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:09:47.717567 [debug] [Thread-1  ]: finished collecting timing info
21:09:47.717778 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:09:47.720116 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:09:47.721259 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:09:47.721469 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:09:47.721653 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:49.550117 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.83 seconds
21:09:49.552575 [debug] [Thread-1  ]: finished collecting timing info
21:09:49.552846 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:09:49.700147 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114257a00>]}
21:09:49.700690 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.99s]
21:09:49.701134 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:09:49.701422 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:09:49.701855 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:09:49.702525 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.702759 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:09:49.702965 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:09:49.704346 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.704910 [debug] [Thread-1  ]: finished collecting timing info
21:09:49.705131 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:09:49.707529 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.708617 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.708818 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:09:49.709003 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:51.190462 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
21:09:51.192963 [debug] [Thread-1  ]: finished collecting timing info
21:09:51.193238 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:09:51.355423 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11426afd0>]}
21:09:51.355964 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.65s]
21:09:51.356402 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:09:51.356672 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:09:51.356986 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:09:51.357671 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:09:51.357908 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:09:51.358130 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:09:51.360804 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:09:51.361320 [debug] [Thread-1  ]: finished collecting timing info
21:09:51.361526 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:09:51.363871 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:09:51.364669 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:09:51.364868 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:09:51.365047 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:52.922928 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
21:09:52.925221 [debug] [Thread-1  ]: finished collecting timing info
21:09:52.925527 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:09:53.061201 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11411dc70>]}
21:09:53.061673 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.70s]
21:09:53.062044 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:09:53.063052 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:09:53.063470 [info ] [MainThread]: 
21:09:53.063777 [info ] [MainThread]: Finished running 2 incremental models, 6 table models in 32.27s.
21:09:53.064061 [debug] [MainThread]: Connection 'master' was properly closed.
21:09:53.064229 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:09:53.070761 [info ] [MainThread]: 
21:09:53.071109 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:09:53.071432 [info ] [MainThread]: 
21:09:53.071704 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:09:53.071972 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:09:53.072259 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:09:53.072634 [info ] [MainThread]: 
21:09:53.072922 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:09:53.073285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111045bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121ccbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114225d90>]}


============================== 2022-01-08 21:27:16.583501 | 1a279529-b91a-4786-840f-80c5834dff09 ==============================
21:27:16.583501 [info ] [MainThread]: Running with dbt=1.0.1
21:27:16.584219 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
21:27:16.584540 [debug] [MainThread]: Tracking: tracking
21:27:16.585015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ad9610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ad9cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ab18e0>]}
21:27:16.639509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
21:27:16.640173 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
21:27:16.651056 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:27:16.696568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1a279529-b91a-4786-840f-80c5834dff09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069700d0>]}
21:27:16.703348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a279529-b91a-4786-840f-80c5834dff09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106818d30>]}
21:27:16.703730 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:27:16.705922 [info ] [MainThread]: 
21:27:16.706408 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:27:16.707556 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:27:16.719996 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:27:16.720245 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:27:16.720405 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:27:19.548119 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2.83 seconds
21:27:19.550710 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:27:19.696602 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:27:19.697105 [info ] [MainThread]: 
21:27:19.701116 [debug] [Thread-1  ]: Began running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.701418 [info ] [Thread-1  ]: 1 of 18 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
21:27:19.701982 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.702198 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.702416 [debug] [Thread-1  ]: Compiling test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.714825 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.715660 [debug] [Thread-1  ]: finished collecting timing info
21:27:19.715912 [debug] [Thread-1  ]: Began executing node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.735541 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.737023 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.737241 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.playing_with_tests
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
21:27:19.737430 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:21.854314 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.12 seconds
21:27:21.857488 [debug] [Thread-1  ]: finished collecting timing info
21:27:21.857778 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
21:27:22.010064 [info ] [Thread-1  ]: 1 of 18 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 2.31s]
21:27:22.010633 [debug] [Thread-1  ]: Finished running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:22.010928 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_100m_acctbal
21:27:22.011314 [info ] [Thread-1  ]: 2 of 18 START test assert_under_100m_acctbal.................................... [RUN]
21:27:22.011926 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.012168 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_100m_acctbal
21:27:22.012415 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_100m_acctbal
21:27:22.014759 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.015410 [debug] [Thread-1  ]: finished collecting timing info
21:27:22.015628 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_100m_acctbal
21:27:22.017798 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.019000 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.019214 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_100m_acctbal: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_100m_acctbal"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select
    c_custkey,
    sum(c_acctbal) as total_acctbal
from analytics.dbt.playing_with_tests
group by
    c_custkey

having sum(c_acctbal) > 100000000
      
    ) dbt_internal_test
21:27:22.019428 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:24.026185 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.01 seconds
21:27:24.028166 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.028453 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_100m_acctbal: Close
21:27:24.195558 [info ] [Thread-1  ]: 2 of 18 PASS assert_under_100m_acctbal.......................................... [[32mPASS[0m in 2.18s]
21:27:24.196109 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_100m_acctbal
21:27:24.196415 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
21:27:24.196690 [info ] [Thread-1  ]: 3 of 18 START test assert_under_10_percent_null................................. [RUN]
21:27:24.197281 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
21:27:24.197660 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
21:27:24.197927 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
21:27:24.200396 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
21:27:24.200950 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.201167 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
21:27:24.203312 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
21:27:24.204438 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
21:27:24.204652 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select 
    sum(case when id is null then 1 else 0 end) / count(*) as total_nulls

from analytics.dbt.first_model

having sum(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
21:27:24.204846 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:24.793533 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.59 seconds
21:27:24.795850 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.796163 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
21:27:24.945645 [info ] [Thread-1  ]: 3 of 18 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 0.75s]
21:27:24.946207 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
21:27:24.946499 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.946881 [info ] [Thread-1  ]: 4 of 18 START test not_null_playing_with_tests_c_custkey........................ [RUN]
21:27:24.947479 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.947723 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.947957 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.958659 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.959755 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.960266 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.964116 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.965931 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.966296 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.playing_with_tests
where c_custkey is null



      
    ) dbt_internal_test
21:27:24.966526 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:25.493541 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.53 seconds
21:27:25.495833 [debug] [Thread-1  ]: finished collecting timing info
21:27:25.496121 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
21:27:25.645089 [info ] [Thread-1  ]: 4 of 18 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 0.70s]
21:27:25.645716 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:25.646075 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.646458 [info ] [Thread-1  ]: 5 of 18 START test not_null_snowflake_cumulative_orders_by_date_o_orderdate..... [RUN]
21:27:25.646984 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.647195 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.647396 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.651714 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.652346 [debug] [Thread-1  ]: finished collecting timing info
21:27:25.652576 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.654904 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.656171 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.656446 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_orders_by_date
where o_orderdate is null



      
    ) dbt_internal_test
21:27:25.656652 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:26.275928 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.62 seconds
21:27:26.278179 [debug] [Thread-1  ]: finished collecting timing info
21:27:26.278463 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14: Close
21:27:26.425711 [info ] [Thread-1  ]: 5 of 18 PASS not_null_snowflake_cumulative_orders_by_date_o_orderdate........... [[32mPASS[0m in 0.78s]
21:27:26.426259 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:26.426547 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.426921 [info ] [Thread-1  ]: 6 of 18 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
21:27:26.427509 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.427771 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.428007 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.432142 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.432764 [debug] [Thread-1  ]: finished collecting timing info
21:27:26.432989 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.435203 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.436220 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.436434 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
21:27:26.436628 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:27.413841 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
21:27:27.416154 [debug] [Thread-1  ]: finished collecting timing info
21:27:27.416441 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
21:27:27.555215 [info ] [Thread-1  ]: 6 of 18 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.13s]
21:27:27.555764 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:27.556052 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.556446 [info ] [Thread-1  ]: 7 of 18 START test not_null_snowflake_customer_purchases_c_name................. [RUN]
21:27:27.557162 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.557405 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.557645 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.561607 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.562160 [debug] [Thread-1  ]: finished collecting timing info
21:27:27.562372 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.564529 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.565523 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.565731 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_name is null



      
    ) dbt_internal_test
21:27:27.565917 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:28.125087 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.56 seconds
21:27:28.126778 [debug] [Thread-1  ]: finished collecting timing info
21:27:28.127032 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972: Close
21:27:28.295835 [info ] [Thread-1  ]: 7 of 18 PASS not_null_snowflake_customer_purchases_c_name....................... [[32mPASS[0m in 0.74s]
21:27:28.296407 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:28.296692 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.297079 [info ] [Thread-1  ]: 8 of 18 START test not_null_snowflake_nation_customer_count_n_name.............. [RUN]
21:27:28.297687 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.297931 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.298166 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.302229 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.302785 [debug] [Thread-1  ]: finished collecting timing info
21:27:28.303007 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.305215 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.306228 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.306444 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_nation_customer_count
where n_name is null



      
    ) dbt_internal_test
21:27:28.306636 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:28.923766 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.62 seconds
21:27:28.926039 [debug] [Thread-1  ]: finished collecting timing info
21:27:28.926329 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81: Close
21:27:29.095814 [info ] [Thread-1  ]: 8 of 18 PASS not_null_snowflake_nation_customer_count_n_name.................... [[32mPASS[0m in 0.80s]
21:27:29.096370 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:29.096659 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.097053 [info ] [Thread-1  ]: 9 of 18 START test not_null_snowflake_nation_customer_count_n_nationkey......... [RUN]
21:27:29.097645 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.097887 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.098123 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.102075 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.102632 [debug] [Thread-1  ]: finished collecting timing info
21:27:29.102841 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.104958 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.105977 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.106197 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_nation_customer_count
where n_nationkey is null



      
    ) dbt_internal_test
21:27:29.106386 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:29.698072 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.59 seconds
21:27:29.700357 [debug] [Thread-1  ]: finished collecting timing info
21:27:29.700642 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae: Close
21:27:30.395620 [info ] [Thread-1  ]: 9 of 18 PASS not_null_snowflake_nation_customer_count_n_nationkey............... [[32mPASS[0m in 1.30s]
21:27:30.396207 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:30.396495 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.396867 [info ] [Thread-1  ]: 10 of 18 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
21:27:30.397470 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.397713 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.397947 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.404177 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.404809 [debug] [Thread-1  ]: finished collecting timing info
21:27:30.405030 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.406910 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.408359 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.408581 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
21:27:30.408777 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:31.275316 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.87 seconds
21:27:31.277474 [debug] [Thread-1  ]: finished collecting timing info
21:27:31.277757 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
21:27:31.666320 [info ] [Thread-1  ]: 10 of 18 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[32mPASS[0m in 1.27s]
21:27:31.666864 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:31.667127 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.667466 [info ] [Thread-1  ]: 11 of 18 START test unique_my_first_dbt_model_id................................ [RUN]
21:27:31.668006 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.668263 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.668479 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.676868 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.677533 [debug] [Thread-1  ]: finished collecting timing info
21:27:31.677765 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.679812 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.680995 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.681231 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
21:27:31.681438 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:33.462934 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.78 seconds
21:27:33.464920 [debug] [Thread-1  ]: finished collecting timing info
21:27:33.465250 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
21:27:33.612539 [info ] [Thread-1  ]: 11 of 18 PASS unique_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.94s]
21:27:33.613082 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:33.613432 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.613936 [info ] [Thread-1  ]: 12 of 18 START test unique_my_second_dbt_model_id............................... [RUN]
21:27:33.614506 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.614731 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.614943 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.619351 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.619960 [debug] [Thread-1  ]: finished collecting timing info
21:27:33.620190 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.622393 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.623510 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.623728 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
21:27:33.623952 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:34.310417 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.69 seconds
21:27:34.312693 [debug] [Thread-1  ]: finished collecting timing info
21:27:34.312981 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
21:27:34.600507 [info ] [Thread-1  ]: 12 of 18 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 0.99s]
21:27:34.601015 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:34.601271 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.601592 [info ] [Thread-1  ]: 13 of 18 START test unique_playing_with_tests_c_custkey......................... [RUN]
21:27:34.602191 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.602411 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.602614 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.607143 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.607788 [debug] [Thread-1  ]: finished collecting timing info
21:27:34.608017 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.610675 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.612088 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.612352 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.playing_with_tests
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
21:27:34.612561 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:36.124335 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
21:27:36.126015 [debug] [Thread-1  ]: finished collecting timing info
21:27:36.126264 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: Close
21:27:36.295682 [info ] [Thread-1  ]: 13 of 18 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.69s]
21:27:36.296255 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:36.296540 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.296902 [info ] [Thread-1  ]: 14 of 18 START test unique_snowflake_cumulative_orders_by_date_o_orderdate...... [RUN]
21:27:36.297498 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.297740 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.297974 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.302036 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.302665 [debug] [Thread-1  ]: finished collecting timing info
21:27:36.302902 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.305090 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.306300 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.306516 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_orders_by_date
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
21:27:36.306712 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:36.948647 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
21:27:36.951174 [debug] [Thread-1  ]: finished collecting timing info
21:27:36.951499 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88: Close
21:27:37.095771 [info ] [Thread-1  ]: 14 of 18 PASS unique_snowflake_cumulative_orders_by_date_o_orderdate............ [[32mPASS[0m in 0.80s]
21:27:37.096335 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:37.096624 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.096994 [info ] [Thread-1  ]: 15 of 18 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
21:27:37.097589 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.097831 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.098065 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.102206 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.102759 [debug] [Thread-1  ]: finished collecting timing info
21:27:37.102975 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.105171 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.106369 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.106585 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
21:27:37.106781 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:37.943365 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
21:27:37.945366 [debug] [Thread-1  ]: finished collecting timing info
21:27:37.945654 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
21:27:38.079906 [info ] [Thread-1  ]: 15 of 18 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 0.98s]
21:27:38.080402 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:38.080654 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.080955 [info ] [Thread-1  ]: 16 of 18 START test unique_snowflake_customer_purchases_c_name.................. [RUN]
21:27:38.081526 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.081754 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.081961 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.085962 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.086567 [debug] [Thread-1  ]: finished collecting timing info
21:27:38.086790 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.089059 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.090274 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.090565 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_name as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_name is not null
group by c_name
having count(*) > 1



      
    ) dbt_internal_test
21:27:38.090845 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:38.819997 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.73 seconds
21:27:38.822060 [debug] [Thread-1  ]: finished collecting timing info
21:27:38.822343 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297: Close
21:27:38.994376 [info ] [Thread-1  ]: 16 of 18 PASS unique_snowflake_customer_purchases_c_name........................ [[32mPASS[0m in 0.91s]
21:27:38.994852 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.995193 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:38.995527 [info ] [Thread-1  ]: 17 of 18 START test unique_snowflake_nation_customer_count_n_name............... [RUN]
21:27:38.996087 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:38.996372 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:38.996607 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:39.000913 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:39.001542 [debug] [Thread-1  ]: finished collecting timing info
21:27:39.001771 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:39.004279 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:39.005818 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:39.006178 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    n_name as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_nation_customer_count
where n_name is not null
group by n_name
having count(*) > 1



      
    ) dbt_internal_test
21:27:39.006429 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:39.610187 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.6 seconds
21:27:39.612196 [debug] [Thread-1  ]: finished collecting timing info
21:27:39.612494 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034: Close
21:27:39.795728 [info ] [Thread-1  ]: 17 of 18 PASS unique_snowflake_nation_customer_count_n_name..................... [[32mPASS[0m in 0.80s]
21:27:39.796508 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:39.796912 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.797277 [info ] [Thread-1  ]: 18 of 18 START test unique_snowflake_nation_customer_count_n_nationkey.......... [RUN]
21:27:39.797937 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.798197 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.798473 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.802595 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.803192 [debug] [Thread-1  ]: finished collecting timing info
21:27:39.803448 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.805923 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.807614 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.807994 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    n_nationkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_nation_customer_count
where n_nationkey is not null
group by n_nationkey
having count(*) > 1



      
    ) dbt_internal_test
21:27:39.808296 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:40.504666 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
21:27:40.506412 [debug] [Thread-1  ]: finished collecting timing info
21:27:40.506675 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5: Close
21:27:40.646857 [info ] [Thread-1  ]: 18 of 18 PASS unique_snowflake_nation_customer_count_n_nationkey................ [[32mPASS[0m in 0.85s]
21:27:40.647736 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:40.649474 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:27:40.650012 [info ] [MainThread]: 
21:27:40.650439 [info ] [MainThread]: Finished running 18 tests in 23.94s.
21:27:40.651133 [debug] [MainThread]: Connection 'master' was properly closed.
21:27:40.651566 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5' was properly closed.
21:27:40.661997 [info ] [MainThread]: 
21:27:40.662646 [info ] [MainThread]: [32mCompleted successfully[0m
21:27:40.663369 [info ] [MainThread]: 
21:27:40.663840 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=0 SKIP=0 TOTAL=18
21:27:40.664342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b11bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106818520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bcfb50>]}


============================== 2022-01-08 21:39:53.629274 | 86818b4c-7252-4e3e-8b8d-539c3aeb2cf0 ==============================
21:39:53.629274 [info ] [MainThread]: Running with dbt=1.0.1
21:39:53.629926 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:39:53.630191 [debug] [MainThread]: Tracking: tracking
21:39:53.630596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e127f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e12d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e124c0>]}
21:39:53.654242 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:39:53.654702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e15a30>]}
21:39:53.693411 [debug] [MainThread]: Parsing macros/catalog.sql
21:39:53.696734 [debug] [MainThread]: Parsing macros/adapters.sql
21:39:53.741125 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:39:53.744737 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:39:53.749563 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:39:53.750839 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:39:53.753747 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:39:53.761769 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:39:53.762671 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:39:53.766231 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:39:53.768385 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:39:53.769908 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:39:53.785568 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:39:53.796034 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:39:53.807038 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:39:53.811282 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:39:53.812895 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:39:53.814529 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:39:53.818590 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:39:53.828830 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:39:53.830213 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:39:53.839625 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:39:53.853913 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:39:53.860653 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:39:53.863256 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:39:53.869751 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:39:53.870945 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:39:53.873411 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:39:53.875517 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:39:53.881021 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:39:53.896141 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:39:53.897487 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:39:53.899716 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:39:53.901275 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:39:53.902089 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:39:53.902611 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:39:53.903265 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:39:53.904511 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:39:53.908530 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:39:53.915931 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:39:53.917853 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:39:53.920186 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:39:53.928591 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:39:53.931105 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:39:53.935042 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:39:53.941507 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:39:53.950225 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:39:54.134354 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:39:54.144405 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:39:54.146412 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:39:54.148633 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:39:54.150757 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:39:54.156845 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:39:54.157756 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:39:54.159734 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:39:54.161838 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:39:54.165093 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:39:54.321804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106719fa0>]}
21:39:54.327926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e2c2b0>]}
21:39:54.328178 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 3 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:39:54.331097 [info ] [MainThread]: 
21:39:54.331955 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:39:54.333632 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:39:54.347129 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:39:54.347433 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:39:54.347628 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:39:55.120646 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.77 seconds
21:39:55.122833 [debug] [ThreadPool]: On list_analytics: Close
21:39:55.288025 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:39:55.295909 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:39:55.296145 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:39:55.296342 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:39:56.019519 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.72 seconds
21:39:56.021747 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:39:56.167067 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:39:56.167586 [info ] [MainThread]: 
21:39:56.171196 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:39:56.171577 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:39:56.172151 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:39:56.172374 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:39:56.172600 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:39:56.179914 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:39:56.181343 [debug] [Thread-1  ]: finished collecting timing info
21:39:56.181606 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:39:56.231504 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:39:56.231815 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:39:56.232016 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:39:56.816675 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a18013-0000-65ab-0000-00016cc23761
21:39:56.817031 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:39:56.817434 [debug] [Thread-1  ]: finished collecting timing info
21:39:56.817673 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:39:56.955955 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:39:56.956391 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10721e100>]}
21:39:56.956798 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.78s]
21:39:56.957205 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:39:56.957451 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:39:56.957873 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:39:56.958404 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:39:56.958611 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:39:56.958815 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:39:56.962491 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:39:56.963142 [debug] [Thread-1  ]: finished collecting timing info
21:39:56.963373 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:39:56.967476 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:56.967738 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:39:56.967944 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:39:58.654900 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.69 seconds
21:39:58.666442 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:58.666684 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:39:58.759834 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:39:58.764734 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:58.764963 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:39:58.854144 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:39:58.864079 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:58.864356 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:39:58.970180 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
21:39:59.004447 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:39:59.006359 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:59.006585 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:39:59.128029 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
21:39:59.128430 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:59.128636 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:39:59.776123 [debug] [Thread-1  ]: SQL status: SUCCESS 544 in 0.65 seconds
21:39:59.776441 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:59.776641 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:40:00.025733 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
21:40:00.038379 [debug] [Thread-1  ]: finished collecting timing info
21:40:00.038700 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:40:00.207930 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275220>]}
21:40:00.208632 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.25s]
21:40:00.209132 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:40:00.209433 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:40:00.209944 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:40:00.210534 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:40:00.210754 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:40:00.210973 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:40:00.214363 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:40:00.215022 [debug] [Thread-1  ]: finished collecting timing info
21:40:00.215261 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:40:00.226587 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:40:00.227842 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:40:00.228080 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:40:00.228277 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:01.575961 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.35 seconds
21:40:01.578161 [debug] [Thread-1  ]: finished collecting timing info
21:40:01.578499 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:40:01.856524 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275b20>]}
21:40:01.857093 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.65s]
21:40:01.857562 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:40:01.857846 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:40:01.858294 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:40:01.858960 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:40:01.859184 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:40:01.859397 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:40:01.860863 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:40:01.861609 [debug] [Thread-1  ]: finished collecting timing info
21:40:01.861848 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:40:01.864507 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:40:01.865462 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:40:01.865721 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:40:01.865927 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:19.124271 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.26 seconds
21:40:19.126771 [debug] [Thread-1  ]: finished collecting timing info
21:40:19.127059 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:40:19.507582 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275970>]}
21:40:19.508143 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 17.65s]
21:40:19.508616 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:40:19.508905 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.509359 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:40:19.509987 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.510239 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.510494 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.511949 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.513333 [debug] [Thread-1  ]: finished collecting timing info
21:40:19.513577 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.516102 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.517525 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.517766 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:40:19.517969 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:20.955187 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
21:40:20.957970 [debug] [Thread-1  ]: finished collecting timing info
21:40:20.958290 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:40:21.089095 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275910>]}
21:40:21.089657 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 1.58s]
21:40:21.090134 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:21.090425 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:40:21.090871 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:40:21.091477 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:40:21.091726 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:40:21.091985 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:40:21.093443 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:40:21.094036 [debug] [Thread-1  ]: finished collecting timing info
21:40:21.094261 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:40:21.096755 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:40:21.097963 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:40:21.098186 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:40:21.098386 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:23.314762 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.22 seconds
21:40:23.317257 [debug] [Thread-1  ]: finished collecting timing info
21:40:23.317548 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:40:23.507432 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275a60>]}
21:40:23.508016 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.42s]
21:40:23.508504 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:40:23.508810 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:40:23.509258 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:40:23.509851 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.510103 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:40:23.510349 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:40:23.511816 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.512394 [debug] [Thread-1  ]: finished collecting timing info
21:40:23.512618 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:40:23.515091 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.516240 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.516462 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:40:23.516666 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:26.210110 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.69 seconds
21:40:26.212643 [debug] [Thread-1  ]: finished collecting timing info
21:40:26.212933 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:40:26.359804 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275670>]}
21:40:26.360369 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 2.85s]
21:40:26.360837 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:40:26.361127 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:40:26.361571 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:40:26.362168 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:40:26.362417 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:40:26.362658 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:40:26.365078 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:40:26.365652 [debug] [Thread-1  ]: finished collecting timing info
21:40:26.365877 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:40:26.368708 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:40:26.369698 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:40:26.369925 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:40:26.370121 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:27.754345 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.38 seconds
21:40:27.756147 [debug] [Thread-1  ]: finished collecting timing info
21:40:27.756394 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:40:27.907140 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107223ac0>]}
21:40:27.907712 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.55s]
21:40:27.908186 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:40:27.909388 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:40:27.909696 [info ] [MainThread]: 
21:40:27.910086 [info ] [MainThread]: Running 3 on-run-end hooks
21:40:27.910789 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
21:40:27.912347 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
21:40:27.914275 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
21:40:27.914866 [debug] [MainThread]: Using snowflake connection "master"
21:40:27.915081 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
21:40:27.915277 [debug] [MainThread]: Opening a new connection, currently in state init
21:40:28.871570 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.96 seconds
21:40:28.873029 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.96s]
21:40:28.873599 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
21:40:28.875100 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
21:40:28.876003 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
21:40:28.876697 [debug] [MainThread]: Using snowflake connection "master"
21:40:28.876953 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
21:40:29.331777 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.45 seconds
21:40:29.332894 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.46s]
21:40:29.333361 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
21:40:29.335223 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
21:40:29.336328 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
21:40:29.337609 [debug] [MainThread]: Using snowflake connection "master"
21:40:29.338094 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
21:40:29.467080 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
21:40:29.468077 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.13s]
21:40:29.468471 [info ] [MainThread]: 
21:40:29.468833 [debug] [MainThread]: On master: Close
21:40:29.723645 [info ] [MainThread]: 
21:40:29.724182 [info ] [MainThread]: Finished running 2 incremental models, 6 table models, 3 hooks in 35.39s.
21:40:29.724573 [debug] [MainThread]: Connection 'master' was properly closed.
21:40:29.724803 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:40:29.732698 [info ] [MainThread]: 
21:40:29.733116 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:40:29.733488 [info ] [MainThread]: 
21:40:29.733805 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:40:29.734122 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:40:29.734421 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:40:29.734773 [info ] [MainThread]: 
21:40:29.735147 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:40:29.735760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928bd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928b9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093f0700>]}


============================== 2022-01-08 21:46:47.705272 | af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7 ==============================
21:46:47.705272 [info ] [MainThread]: Running with dbt=1.0.1
21:46:47.706123 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:46:47.706358 [debug] [MainThread]: Tracking: tracking
21:46:47.706808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db40490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db404c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db406d0>]}
21:46:47.731644 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:46:47.732097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db3c130>]}
21:46:47.768231 [debug] [MainThread]: Parsing macros/catalog.sql
21:46:47.771371 [debug] [MainThread]: Parsing macros/adapters.sql
21:46:47.817062 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:46:47.820738 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:46:47.825697 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:46:47.826980 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:46:47.829888 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:46:47.837980 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:46:47.838976 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:46:47.842563 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:46:47.844787 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:46:47.846339 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:46:47.862316 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:46:47.873079 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:46:47.884206 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:46:47.888407 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:46:47.890118 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:46:47.891841 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:46:47.896030 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:46:47.906781 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:46:47.908231 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:46:47.917759 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:46:47.932042 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:46:47.938619 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:46:47.941163 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:46:47.947570 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:46:47.948793 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:46:47.951156 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:46:47.953188 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:46:47.959504 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:46:47.975053 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:46:47.976448 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:46:47.978657 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:46:47.980560 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:46:47.981411 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:46:47.981927 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:46:47.982567 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:46:47.983806 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:46:47.987764 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:46:47.997229 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:46:47.999369 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:46:48.002862 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:46:48.013275 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:46:48.016304 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:46:48.021484 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:46:48.030683 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:46:48.043228 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:46:48.294386 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:46:48.306405 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:46:48.309997 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:46:48.313545 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:46:48.317469 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:46:48.324263 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:46:48.325349 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:46:48.328786 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:46:48.332127 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:46:48.335158 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:46:48.486504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dbd1a60>]}
21:46:48.492643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc99100>]}
21:46:48.492925 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:46:48.494480 [info ] [MainThread]: 
21:46:48.494879 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:46:48.495938 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:46:48.508221 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:46:48.508474 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:46:48.508625 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:46:49.532805 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.02 seconds
21:46:49.534615 [debug] [ThreadPool]: On list_analytics: Close
21:46:49.676731 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:46:49.684246 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:46:49.684499 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:46:49.684697 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:46:50.465182 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.78 seconds
21:46:50.467312 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:46:50.605055 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:46:50.605591 [info ] [MainThread]: 
21:46:50.610038 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:46:50.610437 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:46:50.611000 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:46:50.611215 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:46:50.611442 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:46:50.617745 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:46:50.618421 [debug] [Thread-1  ]: finished collecting timing info
21:46:50.618663 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:46:50.668572 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:46:50.668878 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:46:50.669077 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:46:51.379268 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a1801a-0000-6584-0000-00016cc24715
21:46:51.379626 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:46:51.380051 [debug] [Thread-1  ]: finished collecting timing info
21:46:51.380291 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:46:51.521423 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:46:51.521920 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff67c40>]}
21:46:51.522392 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.91s]
21:46:51.522890 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:46:51.523194 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:46:51.523617 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:46:51.524159 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:46:51.524376 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:46:51.524586 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:46:51.528258 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:46:51.528924 [debug] [Thread-1  ]: finished collecting timing info
21:46:51.529169 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:46:51.533064 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:51.533312 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:46:51.533548 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:46:53.439469 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.91 seconds
21:46:53.450877 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.451118 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:46:53.553014 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:46:53.559042 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.559270 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:46:53.653039 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:46:53.663557 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.663789 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:46:53.786188 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
21:46:53.811834 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:46:53.813631 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.813843 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:46:53.921649 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:46:53.922204 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.922503 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:46:54.653062 [debug] [Thread-1  ]: SQL status: SUCCESS 415 in 0.73 seconds
21:46:54.653531 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:54.653855 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:46:54.922475 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
21:46:54.924953 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:54.925179 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

        grant select on analytics.dbt.incremental_dates to role analyst
21:46:55.036021 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:46:55.047729 [debug] [Thread-1  ]: finished collecting timing info
21:46:55.048024 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:46:55.204675 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dee9700>]}
21:46:55.205239 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.68s]
21:46:55.205722 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:46:55.206031 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:46:55.206518 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:46:55.207084 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:46:55.207301 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:46:55.207504 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:46:55.210033 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:46:55.210603 [debug] [Thread-1  ]: finished collecting timing info
21:46:55.210821 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:46:55.221347 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:46:55.222585 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:46:55.222802 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:46:55.222991 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:46:56.327096 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.1 seconds
21:46:56.330339 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:46:56.330600 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant select on analytics.dbt.first_model to role analyst
21:46:56.435430 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
21:46:56.437782 [debug] [Thread-1  ]: finished collecting timing info
21:46:56.438073 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:46:56.617387 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11007a880>]}
21:46:56.617951 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.41s]
21:46:56.618438 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:46:56.618725 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:46:56.619308 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:46:56.619917 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:46:56.620167 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:46:56.620423 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:46:56.621937 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:46:56.622530 [debug] [Thread-1  ]: finished collecting timing info
21:46:56.622753 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:46:56.625321 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:46:56.626151 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:46:56.626382 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:46:56.626579 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:14.476524 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.85 seconds
21:47:14.479194 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:47:14.479418 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        grant select on analytics.dbt.playing_with_tests to role analyst
21:47:14.616544 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
21:47:14.618213 [debug] [Thread-1  ]: finished collecting timing info
21:47:14.618468 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:47:14.760332 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff8e1c0>]}
21:47:14.760874 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 18.14s]
21:47:14.761349 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:47:14.761641 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.762116 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:47:14.762761 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.763024 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.763276 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.764728 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.765314 [debug] [Thread-1  ]: finished collecting timing info
21:47:14.765539 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.768818 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.769914 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.770132 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:47:14.770329 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:16.614357 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
21:47:16.617714 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:16.617983 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */

        grant select on analytics.dbt.snowflake_cumulative_orders_by_date to role analyst
21:47:16.716094 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
21:47:16.718449 [debug] [Thread-1  ]: finished collecting timing info
21:47:16.718742 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:47:16.862470 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110074f70>]}
21:47:16.862957 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 2.10s]
21:47:16.863358 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:16.863602 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:47:16.863994 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:47:16.864499 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:47:16.864706 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:47:16.864906 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:47:16.866281 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:47:16.866838 [debug] [Thread-1  ]: finished collecting timing info
21:47:16.867052 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:47:16.869461 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:47:16.870606 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:47:16.870813 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:47:16.871003 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:18.628120 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.76 seconds
21:47:18.631410 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:47:18.631666 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        grant select on analytics.dbt.snowflake_customer_purchases to role analyst
21:47:18.723771 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.09 seconds
21:47:18.725952 [debug] [Thread-1  ]: finished collecting timing info
21:47:18.726325 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:47:18.862278 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100742e0>]}
21:47:18.862776 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.00s]
21:47:18.863187 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:47:18.863440 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:47:18.863841 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:47:18.864396 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.864624 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:47:18.864835 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:47:18.866282 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.866925 [debug] [Thread-1  ]: finished collecting timing info
21:47:18.867145 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:47:18.870285 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.871539 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.871791 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:47:18.871992 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:20.166781 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
21:47:20.170060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:47:20.170312 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */

        grant select on analytics.dbt.snowflake_nation_customer_count to role analyst
21:47:20.285059 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:47:20.287064 [debug] [Thread-1  ]: finished collecting timing info
21:47:20.287361 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:47:20.425242 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e017dc0>]}
21:47:20.425820 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.56s]
21:47:20.426320 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:47:20.426611 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:47:20.427063 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:47:20.427678 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:47:20.427925 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:47:20.428168 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:47:20.431743 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:47:20.432347 [debug] [Thread-1  ]: finished collecting timing info
21:47:20.432588 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:47:20.434902 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:47:20.435790 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:47:20.436014 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:47:20.436225 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:21.510611 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.07 seconds
21:47:21.513886 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:47:21.514144 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        grant select on analytics.dbt.my_second_dbt_model to role analyst
21:47:21.625352 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:47:21.627713 [debug] [Thread-1  ]: finished collecting timing info
21:47:21.628007 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:47:21.907547 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff5f8b0>]}
21:47:21.908058 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.48s]
21:47:21.908467 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:47:21.909778 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:47:21.910476 [info ] [MainThread]: 
21:47:21.910885 [info ] [MainThread]: Finished running 2 incremental models, 6 table models in 33.42s.
21:47:21.911314 [debug] [MainThread]: Connection 'master' was properly closed.
21:47:21.911522 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:47:21.918380 [info ] [MainThread]: 
21:47:21.918906 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:47:21.919304 [info ] [MainThread]: 
21:47:21.919735 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:47:21.920170 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:47:21.920645 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:47:21.921185 [info ] [MainThread]: 
21:47:21.921673 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:47:21.922168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dbd1cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc99430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110095430>]}


============================== 2022-01-08 21:49:27.432203 | 29d36611-2249-49ad-82bd-f8ff34c16dd6 ==============================
21:49:27.432203 [info ] [MainThread]: Running with dbt=1.0.1
21:49:27.432930 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:49:27.433166 [debug] [MainThread]: Tracking: tracking
21:49:27.433569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047d56a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047d51f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047d51c0>]}
21:49:27.457021 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:49:27.457465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047cbd00>]}
21:49:27.491924 [debug] [MainThread]: Parsing macros/catalog.sql
21:49:27.494631 [debug] [MainThread]: Parsing macros/adapters.sql
21:49:27.535837 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:49:27.539505 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:49:27.544377 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:49:27.545650 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:49:27.548544 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:49:27.556583 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:49:27.557490 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:49:27.561073 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:49:27.563244 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:49:27.564782 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:49:27.580506 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:49:27.591049 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:49:27.602051 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:49:27.606217 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:49:27.607859 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:49:27.609553 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:49:27.613671 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:49:27.623752 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:49:27.625065 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:49:27.634049 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:49:27.648014 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:49:27.654513 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:49:27.657190 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:49:27.663680 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:49:27.664827 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:49:27.667303 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:49:27.669357 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:49:27.674729 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:49:27.689949 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:49:27.691368 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:49:27.693511 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:49:27.694880 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:49:27.695654 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:49:27.696152 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:49:27.696773 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:49:27.698030 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:49:27.701845 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:49:27.709257 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:49:27.711238 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:49:27.713588 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:49:27.722520 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:49:27.743940 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:49:27.749907 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:49:27.758971 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:49:27.770372 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:49:27.953184 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
21:49:27.964772 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
21:49:27.965748 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:49:27.967821 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:49:27.970319 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:49:27.972293 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:49:27.978270 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:49:27.979133 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:49:27.981171 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:49:27.983086 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:49:27.986345 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:49:28.132903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048a16d0>]}
21:49:28.138515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048ab760>]}
21:49:28.138841 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:49:28.140582 [info ] [MainThread]: 
21:49:28.141046 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:49:28.142131 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:49:28.154469 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:49:28.154712 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:49:28.154862 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:49:28.992954 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.84 seconds
21:49:28.995098 [debug] [ThreadPool]: On list_analytics: Close
21:49:29.164757 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:49:29.172713 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:49:29.172958 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:49:29.173159 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:49:29.688585 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.52 seconds
21:49:29.690472 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:49:29.841618 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:49:29.842087 [info ] [MainThread]: 
21:49:29.845475 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:49:29.845852 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:49:29.846421 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:49:29.846644 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:49:29.846867 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:49:29.853263 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:49:29.853956 [debug] [Thread-1  ]: finished collecting timing info
21:49:29.854205 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:49:29.903122 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:49:29.903411 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:49:29.903595 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:30.533829 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a1801d-0000-65ab-0000-00016cc238e1
21:49:30.534180 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:49:30.534572 [debug] [Thread-1  ]: finished collecting timing info
21:49:30.534846 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:49:30.672210 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:49:30.672712 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b987f0>]}
21:49:30.673200 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.83s]
21:49:30.673694 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:49:30.673988 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:49:30.674511 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:49:30.675141 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:49:30.675401 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:49:30.675617 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:49:30.679375 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:49:30.680025 [debug] [Thread-1  ]: finished collecting timing info
21:49:30.680261 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:49:30.684029 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:30.684327 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:49:30.684539 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:32.675427 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.99 seconds
21:49:32.686918 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:32.687152 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:49:32.787518 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:49:32.792640 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:32.792895 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:49:32.911529 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
21:49:32.921868 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:32.922105 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:49:33.011520 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:49:33.038905 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:49:33.040682 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:33.040902 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:49:33.171562 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
21:49:33.172120 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:33.172423 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:49:33.813090 [debug] [Thread-1  ]: SQL status: SUCCESS 159 in 0.64 seconds
21:49:33.813556 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:33.813855 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:49:34.111341 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.3 seconds
21:49:34.123884 [debug] [Thread-1  ]: finished collecting timing info
21:49:34.124146 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:49:34.282710 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bda550>]}
21:49:34.283276 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.61s]
21:49:34.283776 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:49:34.284073 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:49:34.284535 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:49:34.285180 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:49:34.285435 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:49:34.285683 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:49:34.288668 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:49:34.289298 [debug] [Thread-1  ]: finished collecting timing info
21:49:34.289532 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:49:34.301095 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:49:34.302454 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:49:34.302731 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:49:34.302985 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:35.782411 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
21:49:35.785201 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:49:35.785435 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant select on analytics.dbt.first_model to role analyst
21:49:35.911434 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
21:49:35.913785 [debug] [Thread-1  ]: finished collecting timing info
21:49:35.914081 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:49:36.073553 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d3aa00>]}
21:49:36.074118 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.79s]
21:49:36.074593 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:49:36.074884 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:49:36.075457 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:49:36.076090 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:49:36.076404 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:49:36.076681 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:49:36.078134 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:49:36.078716 [debug] [Thread-1  ]: finished collecting timing info
21:49:36.078940 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:49:36.081448 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:49:36.082281 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:49:36.082500 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:49:36.082699 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:54.023100 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.94 seconds
21:49:54.025614 [debug] [Thread-1  ]: finished collecting timing info
21:49:54.025907 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:49:54.463888 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b234f0>]}
21:49:54.464445 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 18.39s]
21:49:54.464920 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:49:54.465227 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.465684 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:49:54.466306 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.466556 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.466798 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.468274 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.468851 [debug] [Thread-1  ]: finished collecting timing info
21:49:54.469082 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.471533 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.472560 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.472779 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:49:54.472975 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:56.161549 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.69 seconds
21:49:56.164033 [debug] [Thread-1  ]: finished collecting timing info
21:49:56.164326 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:49:56.329136 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bda640>]}
21:49:56.329702 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 1.86s]
21:49:56.330179 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:56.330475 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:49:56.331129 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:49:56.331756 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:49:56.332012 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:49:56.332246 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:49:56.333675 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:49:56.334238 [debug] [Thread-1  ]: finished collecting timing info
21:49:56.334464 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:49:56.336897 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:49:56.338089 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:49:56.338310 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:49:56.338510 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:58.090516 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
21:49:58.092422 [debug] [Thread-1  ]: finished collecting timing info
21:49:58.092698 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:49:58.263740 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bdaa30>]}
21:49:58.264304 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.93s]
21:49:58.264778 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:49:58.265070 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:49:58.265543 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:49:58.266138 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.266387 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:49:58.266638 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:49:58.268044 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.268606 [debug] [Thread-1  ]: finished collecting timing info
21:49:58.268830 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:49:58.271261 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.272398 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.272615 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:49:58.272813 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:59.614202 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
21:49:59.616710 [debug] [Thread-1  ]: finished collecting timing info
21:49:59.617015 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:49:59.766130 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bf11f0>]}
21:49:59.766693 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.50s]
21:49:59.767177 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:49:59.767447 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:49:59.767839 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:49:59.768371 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:49:59.768585 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:49:59.768792 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:49:59.771117 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:49:59.771683 [debug] [Thread-1  ]: finished collecting timing info
21:49:59.771907 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:49:59.774325 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:49:59.775191 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:49:59.775408 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:49:59.775605 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:50:01.117764 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
21:50:01.119905 [debug] [Thread-1  ]: finished collecting timing info
21:50:01.120204 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:50:01.263345 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bf10a0>]}
21:50:01.263910 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.50s]
21:50:01.264380 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:50:01.265615 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:50:01.266064 [info ] [MainThread]: 
21:50:01.266418 [info ] [MainThread]: Finished running 2 incremental models, 6 table models in 33.13s.
21:50:01.266748 [debug] [MainThread]: Connection 'master' was properly closed.
21:50:01.266941 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:50:01.273754 [info ] [MainThread]: 
21:50:01.274128 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:50:01.274483 [info ] [MainThread]: 
21:50:01.274807 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:50:01.275105 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:50:01.275399 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:50:01.275701 [info ] [MainThread]: 
21:50:01.275994 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:50:01.276372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bea640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048abf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d37d90>]}
