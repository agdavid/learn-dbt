

============================== 2022-01-08 21:09:20.122417 | 01904cb0-62d6-4b01-8491-59378ad5a7a3 ==============================
21:09:20.122417 [info ] [MainThread]: Running with dbt=1.0.1
21:09:20.123092 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:09:20.123341 [debug] [MainThread]: Tracking: tracking
21:09:20.123716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11106df40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cf3e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cf34f0>]}
21:09:20.138890 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
21:09:20.139238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d6d160>]}
21:09:20.177091 [debug] [MainThread]: Parsing macros/catalog.sql
21:09:20.179241 [debug] [MainThread]: Parsing macros/adapters.sql
21:09:20.217042 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:09:20.220647 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:09:20.225505 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:09:20.226762 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:09:20.229590 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:09:20.237646 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:09:20.238707 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:09:20.242562 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:09:20.244690 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:09:20.246186 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:09:20.261677 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:09:20.271982 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:09:20.282731 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:09:20.287015 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:09:20.288629 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:09:20.290264 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:09:20.294280 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:09:20.304617 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:09:20.305979 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:09:20.315402 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:09:20.329735 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:09:20.336468 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:09:20.339177 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:09:20.345706 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:09:20.346910 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:09:20.349278 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:09:20.351293 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:09:20.356561 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:09:20.371175 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:09:20.372482 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:09:20.374637 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:09:20.376005 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:09:20.376771 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:09:20.377267 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:09:20.377876 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:09:20.379061 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:09:20.383051 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:09:20.390625 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:09:20.392527 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:09:20.394866 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:09:20.403365 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:09:20.405913 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:09:20.409889 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:09:20.416343 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:09:20.425048 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:09:20.606382 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:09:20.616491 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:09:20.618417 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:09:20.620610 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:09:20.622563 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:09:20.629748 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:09:20.630835 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:09:20.633282 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:09:20.635895 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:09:20.639421 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:09:20.784705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c350a0>]}
21:09:20.793342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cf24f0>]}
21:09:20.793677 [info ] [MainThread]: Found 8 models, 19 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:09:20.795619 [info ] [MainThread]: 
21:09:20.796106 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:09:20.797273 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:09:20.811111 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:09:20.811312 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:09:20.811487 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:09:21.742974 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.93 seconds
21:09:21.744802 [debug] [ThreadPool]: On list_analytics: Close
21:09:21.924549 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:09:21.932393 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:09:21.932609 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:09:21.932788 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:09:22.756818 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.82 seconds
21:09:22.758695 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:09:22.894571 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:09:22.895052 [info ] [MainThread]: 
21:09:22.902170 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:09:22.902637 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:09:22.903267 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:09:22.903504 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:09:22.903740 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:09:22.909656 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:09:22.910507 [debug] [Thread-1  ]: finished collecting timing info
21:09:22.910728 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:09:22.958148 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:09:22.958440 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:09:22.958627 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:23.554999 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a17ff5-0000-65ab-0000-00016cc23611
21:09:23.555447 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:09:23.555936 [debug] [Thread-1  ]: finished collecting timing info
21:09:23.556236 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:09:23.701224 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:09:23.701637 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11411e910>]}
21:09:23.702037 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.80s]
21:09:23.702426 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:09:23.702661 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:09:23.703054 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:09:23.703543 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:09:23.703741 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:09:23.703930 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:09:23.707407 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:09:23.708006 [debug] [Thread-1  ]: finished collecting timing info
21:09:23.708210 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:09:23.711720 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:23.711930 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:09:23.712144 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:25.459007 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
21:09:25.470243 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:25.470456 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:09:25.586572 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
21:09:25.591697 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:25.591936 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:09:25.756916 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.16 seconds
21:09:25.767156 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:25.767382 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:09:25.995499 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.23 seconds
21:09:26.022617 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:09:26.024652 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:26.024848 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:09:26.133641 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:09:26.134138 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:26.134410 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:09:27.052556 [debug] [Thread-1  ]: SQL status: SUCCESS 504 in 0.92 seconds
21:09:27.053003 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:09:27.053274 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:09:27.324459 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
21:09:27.336783 [debug] [Thread-1  ]: finished collecting timing info
21:09:27.337023 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:09:27.492699 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d8400>]}
21:09:27.493272 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.79s]
21:09:27.493706 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:09:27.493970 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:09:27.494282 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:09:27.494977 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:09:27.495217 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:09:27.495447 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:09:27.498250 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:09:27.498783 [debug] [Thread-1  ]: finished collecting timing info
21:09:27.498992 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:09:27.508929 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:09:27.510065 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:09:27.510281 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:09:27.510466 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:29.211416 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.7 seconds
21:09:29.213844 [debug] [Thread-1  ]: finished collecting timing info
21:09:29.214114 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:09:29.350255 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d86a0>]}
21:09:29.350796 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.86s]
21:09:29.351232 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:09:29.351501 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:09:29.351918 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:09:29.352531 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:09:29.352774 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:09:29.353026 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:09:29.354558 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:09:29.355067 [debug] [Thread-1  ]: finished collecting timing info
21:09:29.355272 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:09:29.357595 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:09:29.358378 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:09:29.358577 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:09:29.358755 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:45.835472 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 16.48 seconds
21:09:45.837932 [debug] [Thread-1  ]: finished collecting timing info
21:09:45.838210 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:09:46.001963 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d8940>]}
21:09:46.002523 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 16.65s]
21:09:46.002962 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:09:46.003233 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.003655 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:09:46.004238 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.004470 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.004692 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.006100 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.006621 [debug] [Thread-1  ]: finished collecting timing info
21:09:46.006828 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:46.009118 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.010107 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:09:46.010309 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:09:46.010492 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:47.530880 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
21:09:47.533334 [debug] [Thread-1  ]: finished collecting timing info
21:09:47.533611 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:09:47.712870 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d85e0>]}
21:09:47.713400 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 1.71s]
21:09:47.713835 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:09:47.714105 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:09:47.714436 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:09:47.715006 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:09:47.715263 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:09:47.715601 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:09:47.717088 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:09:47.717567 [debug] [Thread-1  ]: finished collecting timing info
21:09:47.717778 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:09:47.720116 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:09:47.721259 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:09:47.721469 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:09:47.721653 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:49.550117 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.83 seconds
21:09:49.552575 [debug] [Thread-1  ]: finished collecting timing info
21:09:49.552846 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:09:49.700147 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114257a00>]}
21:09:49.700690 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.99s]
21:09:49.701134 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:09:49.701422 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:09:49.701855 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:09:49.702525 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.702759 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:09:49.702965 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:09:49.704346 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.704910 [debug] [Thread-1  ]: finished collecting timing info
21:09:49.705131 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:09:49.707529 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.708617 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:09:49.708818 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:09:49.709003 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:51.190462 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
21:09:51.192963 [debug] [Thread-1  ]: finished collecting timing info
21:09:51.193238 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:09:51.355423 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11426afd0>]}
21:09:51.355964 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.65s]
21:09:51.356402 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:09:51.356672 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:09:51.356986 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:09:51.357671 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:09:51.357908 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:09:51.358130 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:09:51.360804 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:09:51.361320 [debug] [Thread-1  ]: finished collecting timing info
21:09:51.361526 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:09:51.363871 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:09:51.364669 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:09:51.364868 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:09:51.365047 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:09:52.922928 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
21:09:52.925221 [debug] [Thread-1  ]: finished collecting timing info
21:09:52.925527 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:09:53.061201 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01904cb0-62d6-4b01-8491-59378ad5a7a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11411dc70>]}
21:09:53.061673 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.70s]
21:09:53.062044 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:09:53.063052 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:09:53.063470 [info ] [MainThread]: 
21:09:53.063777 [info ] [MainThread]: Finished running 2 incremental models, 6 table models in 32.27s.
21:09:53.064061 [debug] [MainThread]: Connection 'master' was properly closed.
21:09:53.064229 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:09:53.070761 [info ] [MainThread]: 
21:09:53.071109 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:09:53.071432 [info ] [MainThread]: 
21:09:53.071704 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:09:53.071972 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:09:53.072259 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:09:53.072634 [info ] [MainThread]: 
21:09:53.072922 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:09:53.073285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111045bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121ccbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114225d90>]}


============================== 2022-01-08 21:27:16.583501 | 1a279529-b91a-4786-840f-80c5834dff09 ==============================
21:27:16.583501 [info ] [MainThread]: Running with dbt=1.0.1
21:27:16.584219 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
21:27:16.584540 [debug] [MainThread]: Tracking: tracking
21:27:16.585015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ad9610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ad9cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ab18e0>]}
21:27:16.639509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
21:27:16.640173 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
21:27:16.651056 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:27:16.696568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1a279529-b91a-4786-840f-80c5834dff09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069700d0>]}
21:27:16.703348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a279529-b91a-4786-840f-80c5834dff09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106818d30>]}
21:27:16.703730 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:27:16.705922 [info ] [MainThread]: 
21:27:16.706408 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:27:16.707556 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:27:16.719996 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:27:16.720245 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:27:16.720405 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:27:19.548119 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2.83 seconds
21:27:19.550710 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:27:19.696602 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:27:19.697105 [info ] [MainThread]: 
21:27:19.701116 [debug] [Thread-1  ]: Began running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.701418 [info ] [Thread-1  ]: 1 of 18 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
21:27:19.701982 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.702198 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.702416 [debug] [Thread-1  ]: Compiling test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.714825 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.715660 [debug] [Thread-1  ]: finished collecting timing info
21:27:19.715912 [debug] [Thread-1  ]: Began executing node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:19.735541 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.737023 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
21:27:19.737241 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.playing_with_tests
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
21:27:19.737430 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:21.854314 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.12 seconds
21:27:21.857488 [debug] [Thread-1  ]: finished collecting timing info
21:27:21.857778 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
21:27:22.010064 [info ] [Thread-1  ]: 1 of 18 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 2.31s]
21:27:22.010633 [debug] [Thread-1  ]: Finished running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
21:27:22.010928 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_100m_acctbal
21:27:22.011314 [info ] [Thread-1  ]: 2 of 18 START test assert_under_100m_acctbal.................................... [RUN]
21:27:22.011926 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.012168 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_100m_acctbal
21:27:22.012415 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_100m_acctbal
21:27:22.014759 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.015410 [debug] [Thread-1  ]: finished collecting timing info
21:27:22.015628 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_100m_acctbal
21:27:22.017798 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.019000 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_100m_acctbal"
21:27:22.019214 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_100m_acctbal: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_100m_acctbal"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select
    c_custkey,
    sum(c_acctbal) as total_acctbal
from analytics.dbt.playing_with_tests
group by
    c_custkey

having sum(c_acctbal) > 100000000
      
    ) dbt_internal_test
21:27:22.019428 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:24.026185 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.01 seconds
21:27:24.028166 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.028453 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_100m_acctbal: Close
21:27:24.195558 [info ] [Thread-1  ]: 2 of 18 PASS assert_under_100m_acctbal.......................................... [[32mPASS[0m in 2.18s]
21:27:24.196109 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_100m_acctbal
21:27:24.196415 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
21:27:24.196690 [info ] [Thread-1  ]: 3 of 18 START test assert_under_10_percent_null................................. [RUN]
21:27:24.197281 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
21:27:24.197660 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
21:27:24.197927 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
21:27:24.200396 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
21:27:24.200950 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.201167 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
21:27:24.203312 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
21:27:24.204438 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
21:27:24.204652 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select 
    sum(case when id is null then 1 else 0 end) / count(*) as total_nulls

from analytics.dbt.first_model

having sum(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
21:27:24.204846 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:24.793533 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.59 seconds
21:27:24.795850 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.796163 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
21:27:24.945645 [info ] [Thread-1  ]: 3 of 18 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 0.75s]
21:27:24.946207 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
21:27:24.946499 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.946881 [info ] [Thread-1  ]: 4 of 18 START test not_null_playing_with_tests_c_custkey........................ [RUN]
21:27:24.947479 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.947723 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.947957 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.958659 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.959755 [debug] [Thread-1  ]: finished collecting timing info
21:27:24.960266 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:24.964116 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.965931 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
21:27:24.966296 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.playing_with_tests
where c_custkey is null



      
    ) dbt_internal_test
21:27:24.966526 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:25.493541 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.53 seconds
21:27:25.495833 [debug] [Thread-1  ]: finished collecting timing info
21:27:25.496121 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
21:27:25.645089 [info ] [Thread-1  ]: 4 of 18 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 0.70s]
21:27:25.645716 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
21:27:25.646075 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.646458 [info ] [Thread-1  ]: 5 of 18 START test not_null_snowflake_cumulative_orders_by_date_o_orderdate..... [RUN]
21:27:25.646984 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.647195 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.647396 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.651714 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.652346 [debug] [Thread-1  ]: finished collecting timing info
21:27:25.652576 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:25.654904 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.656171 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
21:27:25.656446 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_orders_by_date
where o_orderdate is null



      
    ) dbt_internal_test
21:27:25.656652 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:26.275928 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.62 seconds
21:27:26.278179 [debug] [Thread-1  ]: finished collecting timing info
21:27:26.278463 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14: Close
21:27:26.425711 [info ] [Thread-1  ]: 5 of 18 PASS not_null_snowflake_cumulative_orders_by_date_o_orderdate........... [[32mPASS[0m in 0.78s]
21:27:26.426259 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
21:27:26.426547 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.426921 [info ] [Thread-1  ]: 6 of 18 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
21:27:26.427509 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.427771 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.428007 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.432142 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.432764 [debug] [Thread-1  ]: finished collecting timing info
21:27:26.432989 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:26.435203 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.436220 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
21:27:26.436434 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
21:27:26.436628 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:27.413841 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
21:27:27.416154 [debug] [Thread-1  ]: finished collecting timing info
21:27:27.416441 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
21:27:27.555215 [info ] [Thread-1  ]: 6 of 18 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.13s]
21:27:27.555764 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
21:27:27.556052 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.556446 [info ] [Thread-1  ]: 7 of 18 START test not_null_snowflake_customer_purchases_c_name................. [RUN]
21:27:27.557162 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.557405 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.557645 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.561607 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.562160 [debug] [Thread-1  ]: finished collecting timing info
21:27:27.562372 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:27.564529 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.565523 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
21:27:27.565731 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_name is null



      
    ) dbt_internal_test
21:27:27.565917 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:28.125087 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.56 seconds
21:27:28.126778 [debug] [Thread-1  ]: finished collecting timing info
21:27:28.127032 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972: Close
21:27:28.295835 [info ] [Thread-1  ]: 7 of 18 PASS not_null_snowflake_customer_purchases_c_name....................... [[32mPASS[0m in 0.74s]
21:27:28.296407 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
21:27:28.296692 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.297079 [info ] [Thread-1  ]: 8 of 18 START test not_null_snowflake_nation_customer_count_n_name.............. [RUN]
21:27:28.297687 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.297931 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.298166 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.302229 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.302785 [debug] [Thread-1  ]: finished collecting timing info
21:27:28.303007 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:28.305215 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.306228 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
21:27:28.306444 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_nation_customer_count
where n_name is null



      
    ) dbt_internal_test
21:27:28.306636 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:28.923766 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.62 seconds
21:27:28.926039 [debug] [Thread-1  ]: finished collecting timing info
21:27:28.926329 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81: Close
21:27:29.095814 [info ] [Thread-1  ]: 8 of 18 PASS not_null_snowflake_nation_customer_count_n_name.................... [[32mPASS[0m in 0.80s]
21:27:29.096370 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
21:27:29.096659 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.097053 [info ] [Thread-1  ]: 9 of 18 START test not_null_snowflake_nation_customer_count_n_nationkey......... [RUN]
21:27:29.097645 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.097887 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.098123 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.102075 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.102632 [debug] [Thread-1  ]: finished collecting timing info
21:27:29.102841 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:29.104958 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.105977 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
21:27:29.106197 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_nation_customer_count
where n_nationkey is null



      
    ) dbt_internal_test
21:27:29.106386 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:29.698072 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.59 seconds
21:27:29.700357 [debug] [Thread-1  ]: finished collecting timing info
21:27:29.700642 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae: Close
21:27:30.395620 [info ] [Thread-1  ]: 9 of 18 PASS not_null_snowflake_nation_customer_count_n_nationkey............... [[32mPASS[0m in 1.30s]
21:27:30.396207 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
21:27:30.396495 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.396867 [info ] [Thread-1  ]: 10 of 18 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
21:27:30.397470 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.397713 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.397947 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.404177 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.404809 [debug] [Thread-1  ]: finished collecting timing info
21:27:30.405030 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:30.406910 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.408359 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
21:27:30.408581 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
21:27:30.408777 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:31.275316 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.87 seconds
21:27:31.277474 [debug] [Thread-1  ]: finished collecting timing info
21:27:31.277757 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
21:27:31.666320 [info ] [Thread-1  ]: 10 of 18 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[32mPASS[0m in 1.27s]
21:27:31.666864 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
21:27:31.667127 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.667466 [info ] [Thread-1  ]: 11 of 18 START test unique_my_first_dbt_model_id................................ [RUN]
21:27:31.668006 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.668263 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.668479 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.676868 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.677533 [debug] [Thread-1  ]: finished collecting timing info
21:27:31.677765 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:31.679812 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.680995 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
21:27:31.681231 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
21:27:31.681438 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:33.462934 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.78 seconds
21:27:33.464920 [debug] [Thread-1  ]: finished collecting timing info
21:27:33.465250 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
21:27:33.612539 [info ] [Thread-1  ]: 11 of 18 PASS unique_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.94s]
21:27:33.613082 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
21:27:33.613432 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.613936 [info ] [Thread-1  ]: 12 of 18 START test unique_my_second_dbt_model_id............................... [RUN]
21:27:33.614506 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.614731 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.614943 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.619351 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.619960 [debug] [Thread-1  ]: finished collecting timing info
21:27:33.620190 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:33.622393 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.623510 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
21:27:33.623728 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
21:27:33.623952 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:34.310417 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.69 seconds
21:27:34.312693 [debug] [Thread-1  ]: finished collecting timing info
21:27:34.312981 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
21:27:34.600507 [info ] [Thread-1  ]: 12 of 18 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 0.99s]
21:27:34.601015 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
21:27:34.601271 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.601592 [info ] [Thread-1  ]: 13 of 18 START test unique_playing_with_tests_c_custkey......................... [RUN]
21:27:34.602191 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.602411 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.602614 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.607143 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.607788 [debug] [Thread-1  ]: finished collecting timing info
21:27:34.608017 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:34.610675 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.612088 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
21:27:34.612352 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.playing_with_tests
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
21:27:34.612561 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:36.124335 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
21:27:36.126015 [debug] [Thread-1  ]: finished collecting timing info
21:27:36.126264 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: Close
21:27:36.295682 [info ] [Thread-1  ]: 13 of 18 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.69s]
21:27:36.296255 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
21:27:36.296540 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.296902 [info ] [Thread-1  ]: 14 of 18 START test unique_snowflake_cumulative_orders_by_date_o_orderdate...... [RUN]
21:27:36.297498 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.297740 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.297974 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.302036 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.302665 [debug] [Thread-1  ]: finished collecting timing info
21:27:36.302902 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:36.305090 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.306300 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
21:27:36.306516 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_orders_by_date
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
21:27:36.306712 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:36.948647 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
21:27:36.951174 [debug] [Thread-1  ]: finished collecting timing info
21:27:36.951499 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88: Close
21:27:37.095771 [info ] [Thread-1  ]: 14 of 18 PASS unique_snowflake_cumulative_orders_by_date_o_orderdate............ [[32mPASS[0m in 0.80s]
21:27:37.096335 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
21:27:37.096624 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.096994 [info ] [Thread-1  ]: 15 of 18 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
21:27:37.097589 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.097831 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.098065 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.102206 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.102759 [debug] [Thread-1  ]: finished collecting timing info
21:27:37.102975 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:37.105171 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.106369 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
21:27:37.106585 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
21:27:37.106781 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:37.943365 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
21:27:37.945366 [debug] [Thread-1  ]: finished collecting timing info
21:27:37.945654 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
21:27:38.079906 [info ] [Thread-1  ]: 15 of 18 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 0.98s]
21:27:38.080402 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
21:27:38.080654 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.080955 [info ] [Thread-1  ]: 16 of 18 START test unique_snowflake_customer_purchases_c_name.................. [RUN]
21:27:38.081526 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.081754 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.081961 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.085962 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.086567 [debug] [Thread-1  ]: finished collecting timing info
21:27:38.086790 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.089059 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.090274 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
21:27:38.090565 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_name as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_name is not null
group by c_name
having count(*) > 1



      
    ) dbt_internal_test
21:27:38.090845 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:38.819997 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.73 seconds
21:27:38.822060 [debug] [Thread-1  ]: finished collecting timing info
21:27:38.822343 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297: Close
21:27:38.994376 [info ] [Thread-1  ]: 16 of 18 PASS unique_snowflake_customer_purchases_c_name........................ [[32mPASS[0m in 0.91s]
21:27:38.994852 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
21:27:38.995193 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:38.995527 [info ] [Thread-1  ]: 17 of 18 START test unique_snowflake_nation_customer_count_n_name............... [RUN]
21:27:38.996087 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:38.996372 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:38.996607 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:39.000913 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:39.001542 [debug] [Thread-1  ]: finished collecting timing info
21:27:39.001771 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:39.004279 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:39.005818 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
21:27:39.006178 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    n_name as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_nation_customer_count
where n_name is not null
group by n_name
having count(*) > 1



      
    ) dbt_internal_test
21:27:39.006429 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:39.610187 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.6 seconds
21:27:39.612196 [debug] [Thread-1  ]: finished collecting timing info
21:27:39.612494 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034: Close
21:27:39.795728 [info ] [Thread-1  ]: 17 of 18 PASS unique_snowflake_nation_customer_count_n_name..................... [[32mPASS[0m in 0.80s]
21:27:39.796508 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
21:27:39.796912 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.797277 [info ] [Thread-1  ]: 18 of 18 START test unique_snowflake_nation_customer_count_n_nationkey.......... [RUN]
21:27:39.797937 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.798197 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.798473 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.802595 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.803192 [debug] [Thread-1  ]: finished collecting timing info
21:27:39.803448 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:39.805923 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.807614 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
21:27:39.807994 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    n_nationkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_nation_customer_count
where n_nationkey is not null
group by n_nationkey
having count(*) > 1



      
    ) dbt_internal_test
21:27:39.808296 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:27:40.504666 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
21:27:40.506412 [debug] [Thread-1  ]: finished collecting timing info
21:27:40.506675 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5: Close
21:27:40.646857 [info ] [Thread-1  ]: 18 of 18 PASS unique_snowflake_nation_customer_count_n_nationkey................ [[32mPASS[0m in 0.85s]
21:27:40.647736 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
21:27:40.649474 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:27:40.650012 [info ] [MainThread]: 
21:27:40.650439 [info ] [MainThread]: Finished running 18 tests in 23.94s.
21:27:40.651133 [debug] [MainThread]: Connection 'master' was properly closed.
21:27:40.651566 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5' was properly closed.
21:27:40.661997 [info ] [MainThread]: 
21:27:40.662646 [info ] [MainThread]: [32mCompleted successfully[0m
21:27:40.663369 [info ] [MainThread]: 
21:27:40.663840 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=0 SKIP=0 TOTAL=18
21:27:40.664342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b11bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106818520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bcfb50>]}


============================== 2022-01-08 21:39:53.629274 | 86818b4c-7252-4e3e-8b8d-539c3aeb2cf0 ==============================
21:39:53.629274 [info ] [MainThread]: Running with dbt=1.0.1
21:39:53.629926 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:39:53.630191 [debug] [MainThread]: Tracking: tracking
21:39:53.630596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e127f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e12d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e124c0>]}
21:39:53.654242 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:39:53.654702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e15a30>]}
21:39:53.693411 [debug] [MainThread]: Parsing macros/catalog.sql
21:39:53.696734 [debug] [MainThread]: Parsing macros/adapters.sql
21:39:53.741125 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:39:53.744737 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:39:53.749563 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:39:53.750839 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:39:53.753747 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:39:53.761769 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:39:53.762671 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:39:53.766231 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:39:53.768385 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:39:53.769908 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:39:53.785568 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:39:53.796034 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:39:53.807038 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:39:53.811282 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:39:53.812895 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:39:53.814529 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:39:53.818590 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:39:53.828830 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:39:53.830213 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:39:53.839625 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:39:53.853913 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:39:53.860653 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:39:53.863256 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:39:53.869751 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:39:53.870945 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:39:53.873411 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:39:53.875517 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:39:53.881021 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:39:53.896141 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:39:53.897487 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:39:53.899716 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:39:53.901275 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:39:53.902089 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:39:53.902611 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:39:53.903265 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:39:53.904511 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:39:53.908530 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:39:53.915931 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:39:53.917853 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:39:53.920186 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:39:53.928591 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:39:53.931105 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:39:53.935042 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:39:53.941507 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:39:53.950225 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:39:54.134354 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:39:54.144405 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:39:54.146412 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:39:54.148633 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:39:54.150757 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:39:54.156845 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:39:54.157756 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:39:54.159734 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:39:54.161838 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:39:54.165093 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:39:54.321804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106719fa0>]}
21:39:54.327926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e2c2b0>]}
21:39:54.328178 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 3 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:39:54.331097 [info ] [MainThread]: 
21:39:54.331955 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:39:54.333632 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:39:54.347129 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:39:54.347433 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:39:54.347628 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:39:55.120646 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.77 seconds
21:39:55.122833 [debug] [ThreadPool]: On list_analytics: Close
21:39:55.288025 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:39:55.295909 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:39:55.296145 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:39:55.296342 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:39:56.019519 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.72 seconds
21:39:56.021747 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:39:56.167067 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:39:56.167586 [info ] [MainThread]: 
21:39:56.171196 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:39:56.171577 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:39:56.172151 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:39:56.172374 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:39:56.172600 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:39:56.179914 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:39:56.181343 [debug] [Thread-1  ]: finished collecting timing info
21:39:56.181606 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:39:56.231504 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:39:56.231815 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:39:56.232016 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:39:56.816675 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a18013-0000-65ab-0000-00016cc23761
21:39:56.817031 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:39:56.817434 [debug] [Thread-1  ]: finished collecting timing info
21:39:56.817673 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:39:56.955955 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:39:56.956391 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10721e100>]}
21:39:56.956798 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.78s]
21:39:56.957205 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:39:56.957451 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:39:56.957873 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:39:56.958404 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:39:56.958611 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:39:56.958815 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:39:56.962491 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:39:56.963142 [debug] [Thread-1  ]: finished collecting timing info
21:39:56.963373 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:39:56.967476 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:56.967738 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:39:56.967944 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:39:58.654900 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.69 seconds
21:39:58.666442 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:58.666684 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:39:58.759834 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:39:58.764734 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:58.764963 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:39:58.854144 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:39:58.864079 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:58.864356 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:39:58.970180 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
21:39:59.004447 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:39:59.006359 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:59.006585 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:39:59.128029 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
21:39:59.128430 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:59.128636 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:39:59.776123 [debug] [Thread-1  ]: SQL status: SUCCESS 544 in 0.65 seconds
21:39:59.776441 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:39:59.776641 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:40:00.025733 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
21:40:00.038379 [debug] [Thread-1  ]: finished collecting timing info
21:40:00.038700 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:40:00.207930 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275220>]}
21:40:00.208632 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.25s]
21:40:00.209132 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:40:00.209433 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:40:00.209944 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:40:00.210534 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:40:00.210754 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:40:00.210973 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:40:00.214363 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:40:00.215022 [debug] [Thread-1  ]: finished collecting timing info
21:40:00.215261 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:40:00.226587 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:40:00.227842 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:40:00.228080 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:40:00.228277 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:01.575961 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.35 seconds
21:40:01.578161 [debug] [Thread-1  ]: finished collecting timing info
21:40:01.578499 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:40:01.856524 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275b20>]}
21:40:01.857093 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.65s]
21:40:01.857562 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:40:01.857846 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:40:01.858294 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:40:01.858960 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:40:01.859184 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:40:01.859397 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:40:01.860863 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:40:01.861609 [debug] [Thread-1  ]: finished collecting timing info
21:40:01.861848 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:40:01.864507 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:40:01.865462 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:40:01.865721 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:40:01.865927 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:19.124271 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.26 seconds
21:40:19.126771 [debug] [Thread-1  ]: finished collecting timing info
21:40:19.127059 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:40:19.507582 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275970>]}
21:40:19.508143 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 17.65s]
21:40:19.508616 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:40:19.508905 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.509359 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:40:19.509987 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.510239 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.510494 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.511949 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.513333 [debug] [Thread-1  ]: finished collecting timing info
21:40:19.513577 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:19.516102 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.517525 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:40:19.517766 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:40:19.517969 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:20.955187 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
21:40:20.957970 [debug] [Thread-1  ]: finished collecting timing info
21:40:20.958290 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:40:21.089095 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275910>]}
21:40:21.089657 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 1.58s]
21:40:21.090134 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:40:21.090425 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:40:21.090871 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:40:21.091477 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:40:21.091726 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:40:21.091985 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:40:21.093443 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:40:21.094036 [debug] [Thread-1  ]: finished collecting timing info
21:40:21.094261 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:40:21.096755 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:40:21.097963 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:40:21.098186 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:40:21.098386 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:23.314762 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.22 seconds
21:40:23.317257 [debug] [Thread-1  ]: finished collecting timing info
21:40:23.317548 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:40:23.507432 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275a60>]}
21:40:23.508016 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.42s]
21:40:23.508504 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:40:23.508810 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:40:23.509258 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:40:23.509851 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.510103 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:40:23.510349 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:40:23.511816 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.512394 [debug] [Thread-1  ]: finished collecting timing info
21:40:23.512618 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:40:23.515091 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.516240 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:40:23.516462 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:40:23.516666 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:26.210110 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.69 seconds
21:40:26.212643 [debug] [Thread-1  ]: finished collecting timing info
21:40:26.212933 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:40:26.359804 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275670>]}
21:40:26.360369 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 2.85s]
21:40:26.360837 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:40:26.361127 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:40:26.361571 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:40:26.362168 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:40:26.362417 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:40:26.362658 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:40:26.365078 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:40:26.365652 [debug] [Thread-1  ]: finished collecting timing info
21:40:26.365877 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:40:26.368708 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:40:26.369698 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:40:26.369925 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:40:26.370121 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:40:27.754345 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.38 seconds
21:40:27.756147 [debug] [Thread-1  ]: finished collecting timing info
21:40:27.756394 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:40:27.907140 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86818b4c-7252-4e3e-8b8d-539c3aeb2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107223ac0>]}
21:40:27.907712 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.55s]
21:40:27.908186 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:40:27.909388 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:40:27.909696 [info ] [MainThread]: 
21:40:27.910086 [info ] [MainThread]: Running 3 on-run-end hooks
21:40:27.910789 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
21:40:27.912347 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
21:40:27.914275 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
21:40:27.914866 [debug] [MainThread]: Using snowflake connection "master"
21:40:27.915081 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
21:40:27.915277 [debug] [MainThread]: Opening a new connection, currently in state init
21:40:28.871570 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.96 seconds
21:40:28.873029 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.96s]
21:40:28.873599 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
21:40:28.875100 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
21:40:28.876003 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
21:40:28.876697 [debug] [MainThread]: Using snowflake connection "master"
21:40:28.876953 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
21:40:29.331777 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.45 seconds
21:40:29.332894 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.46s]
21:40:29.333361 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
21:40:29.335223 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
21:40:29.336328 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
21:40:29.337609 [debug] [MainThread]: Using snowflake connection "master"
21:40:29.338094 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
21:40:29.467080 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
21:40:29.468077 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.13s]
21:40:29.468471 [info ] [MainThread]: 
21:40:29.468833 [debug] [MainThread]: On master: Close
21:40:29.723645 [info ] [MainThread]: 
21:40:29.724182 [info ] [MainThread]: Finished running 2 incremental models, 6 table models, 3 hooks in 35.39s.
21:40:29.724573 [debug] [MainThread]: Connection 'master' was properly closed.
21:40:29.724803 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:40:29.732698 [info ] [MainThread]: 
21:40:29.733116 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:40:29.733488 [info ] [MainThread]: 
21:40:29.733805 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:40:29.734122 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:40:29.734421 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:40:29.734773 [info ] [MainThread]: 
21:40:29.735147 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:40:29.735760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928bd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928b9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093f0700>]}


============================== 2022-01-08 21:46:47.705272 | af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7 ==============================
21:46:47.705272 [info ] [MainThread]: Running with dbt=1.0.1
21:46:47.706123 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:46:47.706358 [debug] [MainThread]: Tracking: tracking
21:46:47.706808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db40490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db404c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db406d0>]}
21:46:47.731644 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:46:47.732097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db3c130>]}
21:46:47.768231 [debug] [MainThread]: Parsing macros/catalog.sql
21:46:47.771371 [debug] [MainThread]: Parsing macros/adapters.sql
21:46:47.817062 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:46:47.820738 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:46:47.825697 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:46:47.826980 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:46:47.829888 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:46:47.837980 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:46:47.838976 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:46:47.842563 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:46:47.844787 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:46:47.846339 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:46:47.862316 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:46:47.873079 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:46:47.884206 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:46:47.888407 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:46:47.890118 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:46:47.891841 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:46:47.896030 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:46:47.906781 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:46:47.908231 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:46:47.917759 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:46:47.932042 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:46:47.938619 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:46:47.941163 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:46:47.947570 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:46:47.948793 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:46:47.951156 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:46:47.953188 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:46:47.959504 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:46:47.975053 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:46:47.976448 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:46:47.978657 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:46:47.980560 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:46:47.981411 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:46:47.981927 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:46:47.982567 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:46:47.983806 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:46:47.987764 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:46:47.997229 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:46:47.999369 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:46:48.002862 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:46:48.013275 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:46:48.016304 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:46:48.021484 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:46:48.030683 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:46:48.043228 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:46:48.294386 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:46:48.306405 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:46:48.309997 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:46:48.313545 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:46:48.317469 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:46:48.324263 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:46:48.325349 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:46:48.328786 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:46:48.332127 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:46:48.335158 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:46:48.486504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dbd1a60>]}
21:46:48.492643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc99100>]}
21:46:48.492925 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:46:48.494480 [info ] [MainThread]: 
21:46:48.494879 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:46:48.495938 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:46:48.508221 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:46:48.508474 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:46:48.508625 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:46:49.532805 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.02 seconds
21:46:49.534615 [debug] [ThreadPool]: On list_analytics: Close
21:46:49.676731 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:46:49.684246 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:46:49.684499 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:46:49.684697 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:46:50.465182 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.78 seconds
21:46:50.467312 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:46:50.605055 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:46:50.605591 [info ] [MainThread]: 
21:46:50.610038 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:46:50.610437 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:46:50.611000 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:46:50.611215 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:46:50.611442 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:46:50.617745 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:46:50.618421 [debug] [Thread-1  ]: finished collecting timing info
21:46:50.618663 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:46:50.668572 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:46:50.668878 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:46:50.669077 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:46:51.379268 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a1801a-0000-6584-0000-00016cc24715
21:46:51.379626 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:46:51.380051 [debug] [Thread-1  ]: finished collecting timing info
21:46:51.380291 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:46:51.521423 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:46:51.521920 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff67c40>]}
21:46:51.522392 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.91s]
21:46:51.522890 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:46:51.523194 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:46:51.523617 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:46:51.524159 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:46:51.524376 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:46:51.524586 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:46:51.528258 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:46:51.528924 [debug] [Thread-1  ]: finished collecting timing info
21:46:51.529169 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:46:51.533064 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:51.533312 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:46:51.533548 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:46:53.439469 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.91 seconds
21:46:53.450877 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.451118 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:46:53.553014 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:46:53.559042 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.559270 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:46:53.653039 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:46:53.663557 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.663789 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:46:53.786188 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
21:46:53.811834 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:46:53.813631 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.813843 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:46:53.921649 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:46:53.922204 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:53.922503 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:46:54.653062 [debug] [Thread-1  ]: SQL status: SUCCESS 415 in 0.73 seconds
21:46:54.653531 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:54.653855 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:46:54.922475 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
21:46:54.924953 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:46:54.925179 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

        grant select on analytics.dbt.incremental_dates to role analyst
21:46:55.036021 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:46:55.047729 [debug] [Thread-1  ]: finished collecting timing info
21:46:55.048024 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:46:55.204675 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dee9700>]}
21:46:55.205239 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.68s]
21:46:55.205722 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:46:55.206031 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:46:55.206518 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:46:55.207084 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:46:55.207301 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:46:55.207504 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:46:55.210033 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:46:55.210603 [debug] [Thread-1  ]: finished collecting timing info
21:46:55.210821 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:46:55.221347 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:46:55.222585 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:46:55.222802 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:46:55.222991 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:46:56.327096 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.1 seconds
21:46:56.330339 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:46:56.330600 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant select on analytics.dbt.first_model to role analyst
21:46:56.435430 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
21:46:56.437782 [debug] [Thread-1  ]: finished collecting timing info
21:46:56.438073 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:46:56.617387 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11007a880>]}
21:46:56.617951 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.41s]
21:46:56.618438 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:46:56.618725 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:46:56.619308 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:46:56.619917 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:46:56.620167 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:46:56.620423 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:46:56.621937 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:46:56.622530 [debug] [Thread-1  ]: finished collecting timing info
21:46:56.622753 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:46:56.625321 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:46:56.626151 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:46:56.626382 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:46:56.626579 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:14.476524 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.85 seconds
21:47:14.479194 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:47:14.479418 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        grant select on analytics.dbt.playing_with_tests to role analyst
21:47:14.616544 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
21:47:14.618213 [debug] [Thread-1  ]: finished collecting timing info
21:47:14.618468 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:47:14.760332 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff8e1c0>]}
21:47:14.760874 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 18.14s]
21:47:14.761349 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:47:14.761641 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.762116 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:47:14.762761 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.763024 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.763276 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.764728 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.765314 [debug] [Thread-1  ]: finished collecting timing info
21:47:14.765539 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:14.768818 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.769914 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:14.770132 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:47:14.770329 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:16.614357 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
21:47:16.617714 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:47:16.617983 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */

        grant select on analytics.dbt.snowflake_cumulative_orders_by_date to role analyst
21:47:16.716094 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
21:47:16.718449 [debug] [Thread-1  ]: finished collecting timing info
21:47:16.718742 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:47:16.862470 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110074f70>]}
21:47:16.862957 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 2.10s]
21:47:16.863358 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:47:16.863602 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:47:16.863994 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:47:16.864499 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:47:16.864706 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:47:16.864906 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:47:16.866281 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:47:16.866838 [debug] [Thread-1  ]: finished collecting timing info
21:47:16.867052 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:47:16.869461 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:47:16.870606 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:47:16.870813 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:47:16.871003 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:18.628120 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.76 seconds
21:47:18.631410 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:47:18.631666 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        grant select on analytics.dbt.snowflake_customer_purchases to role analyst
21:47:18.723771 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.09 seconds
21:47:18.725952 [debug] [Thread-1  ]: finished collecting timing info
21:47:18.726325 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:47:18.862278 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100742e0>]}
21:47:18.862776 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.00s]
21:47:18.863187 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:47:18.863440 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:47:18.863841 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:47:18.864396 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.864624 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:47:18.864835 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:47:18.866282 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.866925 [debug] [Thread-1  ]: finished collecting timing info
21:47:18.867145 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:47:18.870285 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.871539 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:47:18.871791 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:47:18.871992 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:20.166781 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
21:47:20.170060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:47:20.170312 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */

        grant select on analytics.dbt.snowflake_nation_customer_count to role analyst
21:47:20.285059 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:47:20.287064 [debug] [Thread-1  ]: finished collecting timing info
21:47:20.287361 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:47:20.425242 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e017dc0>]}
21:47:20.425820 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.56s]
21:47:20.426320 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:47:20.426611 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:47:20.427063 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:47:20.427678 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:47:20.427925 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:47:20.428168 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:47:20.431743 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:47:20.432347 [debug] [Thread-1  ]: finished collecting timing info
21:47:20.432588 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:47:20.434902 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:47:20.435790 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:47:20.436014 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:47:20.436225 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:47:21.510611 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.07 seconds
21:47:21.513886 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:47:21.514144 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        grant select on analytics.dbt.my_second_dbt_model to role analyst
21:47:21.625352 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:47:21.627713 [debug] [Thread-1  ]: finished collecting timing info
21:47:21.628007 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:47:21.907547 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af6f681c-11bd-4bf8-9d5e-af2bbbd7b1e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff5f8b0>]}
21:47:21.908058 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.48s]
21:47:21.908467 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:47:21.909778 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:47:21.910476 [info ] [MainThread]: 
21:47:21.910885 [info ] [MainThread]: Finished running 2 incremental models, 6 table models in 33.42s.
21:47:21.911314 [debug] [MainThread]: Connection 'master' was properly closed.
21:47:21.911522 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:47:21.918380 [info ] [MainThread]: 
21:47:21.918906 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:47:21.919304 [info ] [MainThread]: 
21:47:21.919735 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:47:21.920170 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:47:21.920645 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:47:21.921185 [info ] [MainThread]: 
21:47:21.921673 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:47:21.922168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dbd1cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc99430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110095430>]}


============================== 2022-01-08 21:49:27.432203 | 29d36611-2249-49ad-82bd-f8ff34c16dd6 ==============================
21:49:27.432203 [info ] [MainThread]: Running with dbt=1.0.1
21:49:27.432930 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:49:27.433166 [debug] [MainThread]: Tracking: tracking
21:49:27.433569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047d56a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047d51f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047d51c0>]}
21:49:27.457021 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:49:27.457465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047cbd00>]}
21:49:27.491924 [debug] [MainThread]: Parsing macros/catalog.sql
21:49:27.494631 [debug] [MainThread]: Parsing macros/adapters.sql
21:49:27.535837 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:49:27.539505 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:49:27.544377 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:49:27.545650 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:49:27.548544 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:49:27.556583 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:49:27.557490 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:49:27.561073 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:49:27.563244 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:49:27.564782 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:49:27.580506 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:49:27.591049 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:49:27.602051 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:49:27.606217 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:49:27.607859 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:49:27.609553 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:49:27.613671 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:49:27.623752 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:49:27.625065 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:49:27.634049 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:49:27.648014 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:49:27.654513 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:49:27.657190 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:49:27.663680 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:49:27.664827 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:49:27.667303 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:49:27.669357 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:49:27.674729 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:49:27.689949 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:49:27.691368 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:49:27.693511 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:49:27.694880 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:49:27.695654 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:49:27.696152 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:49:27.696773 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:49:27.698030 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:49:27.701845 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:49:27.709257 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:49:27.711238 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:49:27.713588 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:49:27.722520 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:49:27.743940 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:49:27.749907 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:49:27.758971 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:49:27.770372 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:49:27.953184 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
21:49:27.964772 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
21:49:27.965748 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:49:27.967821 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:49:27.970319 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:49:27.972293 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:49:27.978270 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:49:27.979133 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:49:27.981171 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:49:27.983086 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:49:27.986345 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:49:28.132903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048a16d0>]}
21:49:28.138515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048ab760>]}
21:49:28.138841 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:49:28.140582 [info ] [MainThread]: 
21:49:28.141046 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:49:28.142131 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:49:28.154469 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:49:28.154712 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:49:28.154862 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:49:28.992954 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.84 seconds
21:49:28.995098 [debug] [ThreadPool]: On list_analytics: Close
21:49:29.164757 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:49:29.172713 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:49:29.172958 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:49:29.173159 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:49:29.688585 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.52 seconds
21:49:29.690472 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:49:29.841618 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:49:29.842087 [info ] [MainThread]: 
21:49:29.845475 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:49:29.845852 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:49:29.846421 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:49:29.846644 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:49:29.846867 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:49:29.853263 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:49:29.853956 [debug] [Thread-1  ]: finished collecting timing info
21:49:29.854205 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:49:29.903122 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:49:29.903411 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:49:29.903595 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:30.533829 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a1801d-0000-65ab-0000-00016cc238e1
21:49:30.534180 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:49:30.534572 [debug] [Thread-1  ]: finished collecting timing info
21:49:30.534846 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:49:30.672210 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:49:30.672712 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b987f0>]}
21:49:30.673200 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.83s]
21:49:30.673694 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:49:30.673988 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:49:30.674511 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:49:30.675141 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:49:30.675401 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:49:30.675617 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:49:30.679375 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:49:30.680025 [debug] [Thread-1  ]: finished collecting timing info
21:49:30.680261 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:49:30.684029 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:30.684327 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:49:30.684539 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:32.675427 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.99 seconds
21:49:32.686918 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:32.687152 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:49:32.787518 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:49:32.792640 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:32.792895 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:49:32.911529 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
21:49:32.921868 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:32.922105 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:49:33.011520 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:49:33.038905 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:49:33.040682 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:33.040902 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:49:33.171562 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
21:49:33.172120 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:33.172423 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:49:33.813090 [debug] [Thread-1  ]: SQL status: SUCCESS 159 in 0.64 seconds
21:49:33.813556 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:49:33.813855 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:49:34.111341 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.3 seconds
21:49:34.123884 [debug] [Thread-1  ]: finished collecting timing info
21:49:34.124146 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:49:34.282710 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bda550>]}
21:49:34.283276 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.61s]
21:49:34.283776 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:49:34.284073 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:49:34.284535 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:49:34.285180 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:49:34.285435 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:49:34.285683 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:49:34.288668 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:49:34.289298 [debug] [Thread-1  ]: finished collecting timing info
21:49:34.289532 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:49:34.301095 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:49:34.302454 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:49:34.302731 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:49:34.302985 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:35.782411 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
21:49:35.785201 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:49:35.785435 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant select on analytics.dbt.first_model to role analyst
21:49:35.911434 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
21:49:35.913785 [debug] [Thread-1  ]: finished collecting timing info
21:49:35.914081 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:49:36.073553 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d3aa00>]}
21:49:36.074118 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.79s]
21:49:36.074593 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:49:36.074884 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:49:36.075457 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:49:36.076090 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:49:36.076404 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:49:36.076681 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:49:36.078134 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:49:36.078716 [debug] [Thread-1  ]: finished collecting timing info
21:49:36.078940 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:49:36.081448 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:49:36.082281 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:49:36.082500 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:49:36.082699 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:54.023100 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.94 seconds
21:49:54.025614 [debug] [Thread-1  ]: finished collecting timing info
21:49:54.025907 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:49:54.463888 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b234f0>]}
21:49:54.464445 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 18.39s]
21:49:54.464920 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:49:54.465227 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.465684 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:49:54.466306 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.466556 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.466798 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.468274 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.468851 [debug] [Thread-1  ]: finished collecting timing info
21:49:54.469082 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:54.471533 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.472560 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:49:54.472779 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:49:54.472975 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:56.161549 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.69 seconds
21:49:56.164033 [debug] [Thread-1  ]: finished collecting timing info
21:49:56.164326 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:49:56.329136 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bda640>]}
21:49:56.329702 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 1.86s]
21:49:56.330179 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:49:56.330475 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:49:56.331129 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:49:56.331756 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:49:56.332012 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:49:56.332246 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:49:56.333675 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:49:56.334238 [debug] [Thread-1  ]: finished collecting timing info
21:49:56.334464 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:49:56.336897 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:49:56.338089 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:49:56.338310 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:49:56.338510 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:58.090516 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
21:49:58.092422 [debug] [Thread-1  ]: finished collecting timing info
21:49:58.092698 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:49:58.263740 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bdaa30>]}
21:49:58.264304 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.93s]
21:49:58.264778 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:49:58.265070 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:49:58.265543 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:49:58.266138 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.266387 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:49:58.266638 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:49:58.268044 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.268606 [debug] [Thread-1  ]: finished collecting timing info
21:49:58.268830 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:49:58.271261 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.272398 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:49:58.272615 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:49:58.272813 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:49:59.614202 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
21:49:59.616710 [debug] [Thread-1  ]: finished collecting timing info
21:49:59.617015 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:49:59.766130 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bf11f0>]}
21:49:59.766693 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.50s]
21:49:59.767177 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:49:59.767447 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:49:59.767839 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:49:59.768371 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:49:59.768585 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:49:59.768792 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:49:59.771117 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:49:59.771683 [debug] [Thread-1  ]: finished collecting timing info
21:49:59.771907 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:49:59.774325 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:49:59.775191 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:49:59.775408 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:49:59.775605 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:50:01.117764 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
21:50:01.119905 [debug] [Thread-1  ]: finished collecting timing info
21:50:01.120204 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:50:01.263345 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29d36611-2249-49ad-82bd-f8ff34c16dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bf10a0>]}
21:50:01.263910 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.50s]
21:50:01.264380 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:50:01.265615 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:50:01.266064 [info ] [MainThread]: 
21:50:01.266418 [info ] [MainThread]: Finished running 2 incremental models, 6 table models in 33.13s.
21:50:01.266748 [debug] [MainThread]: Connection 'master' was properly closed.
21:50:01.266941 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:50:01.273754 [info ] [MainThread]: 
21:50:01.274128 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:50:01.274483 [info ] [MainThread]: 
21:50:01.274807 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:50:01.275105 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:50:01.275399 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:50:01.275701 [info ] [MainThread]: 
21:50:01.275994 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:50:01.276372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bea640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048abf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d37d90>]}


============================== 2022-01-08 21:52:28.283257 | 4874a80c-cec7-49f2-a4b2-55f78c0ecd63 ==============================
21:52:28.283257 [info ] [MainThread]: Running with dbt=1.0.1
21:52:28.284096 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:52:28.284549 [debug] [MainThread]: Tracking: tracking
21:52:28.285075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104928d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104928f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103c40850>]}
21:52:28.310642 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:52:28.311076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103c21eb0>]}
21:52:28.349208 [debug] [MainThread]: Parsing macros/catalog.sql
21:52:28.351787 [debug] [MainThread]: Parsing macros/adapters.sql
21:52:28.392703 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:52:28.396470 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:52:28.401326 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:52:28.402601 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:52:28.405483 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:52:28.413546 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:52:28.414458 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:52:28.418025 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:52:28.420199 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:52:28.421738 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:52:28.437799 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:52:28.448508 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:52:28.459506 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:52:28.463710 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:52:28.465377 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:52:28.467060 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:52:28.471170 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:52:28.481908 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:52:28.483482 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:52:28.493734 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:52:28.508554 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:52:28.515505 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:52:28.518176 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:52:28.524724 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:52:28.525918 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:52:28.528368 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:52:28.530475 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:52:28.536986 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:52:28.552680 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:52:28.554104 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:52:28.556433 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:52:28.557867 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:52:28.558681 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:52:28.559201 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:52:28.559848 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:52:28.561090 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:52:28.565151 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:52:28.572795 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:52:28.575050 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:52:28.577518 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:52:28.587157 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:52:28.589918 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:52:28.594030 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:52:28.600835 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:52:28.609752 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:52:28.808336 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:52:28.818866 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:52:28.820957 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:52:28.823158 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:52:28.825287 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:52:28.831693 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:52:28.832624 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:52:28.834705 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:52:28.836905 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:52:28.840443 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:52:29.004802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1038427f0>]}
21:52:29.011023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048f8190>]}
21:52:29.011332 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 3 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:52:29.013073 [info ] [MainThread]: 
21:52:29.013532 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:52:29.014599 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:52:29.027521 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:52:29.027785 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:52:29.027942 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:52:29.879087 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.85 seconds
21:52:29.881267 [debug] [ThreadPool]: On list_analytics: Close
21:52:30.066787 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:52:30.074871 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:52:30.075122 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:52:30.075336 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:52:30.737132 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.66 seconds
21:52:30.739601 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:52:31.366220 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:52:31.366729 [info ] [MainThread]: 
21:52:31.370389 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:52:31.370772 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:52:31.371334 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:52:31.371554 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:52:31.371781 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:52:31.378931 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:52:31.380499 [debug] [Thread-1  ]: finished collecting timing info
21:52:31.380769 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:52:31.431799 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:52:31.432114 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:52:31.432316 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:31.917637 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a18020-0000-65ab-0000-00016cc23915
21:52:31.917980 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:52:31.918374 [debug] [Thread-1  ]: finished collecting timing info
21:52:31.918652 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:52:32.124068 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:52:32.124568 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d2c580>]}
21:52:32.125042 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.75s]
21:52:32.125535 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:52:32.125827 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:52:32.126347 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:52:32.126950 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:52:32.127205 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:52:32.127418 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:52:32.131107 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:52:32.131747 [debug] [Thread-1  ]: finished collecting timing info
21:52:32.131975 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:52:32.135735 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:32.136040 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:52:32.136286 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:34.640678 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.5 seconds
21:52:34.652251 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:34.652504 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:52:34.771987 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
21:52:34.777037 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:34.777299 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:52:34.913553 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
21:52:34.924765 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:34.924998 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:52:35.016763 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
21:52:35.043620 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:52:35.046511 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:35.046733 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:52:35.176979 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
21:52:35.177439 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:35.177722 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:52:35.824036 [debug] [Thread-1  ]: SQL status: SUCCESS 182 in 0.65 seconds
21:52:35.824372 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:52:35.824572 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:52:36.113293 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.29 seconds
21:52:36.126160 [debug] [Thread-1  ]: finished collecting timing info
21:52:36.126473 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:52:36.273801 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d5b370>]}
21:52:36.274354 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 4.15s]
21:52:36.274822 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:52:36.275106 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:52:36.275552 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:52:36.276158 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:52:36.276404 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:52:36.276651 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:52:36.279312 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:52:36.279871 [debug] [Thread-1  ]: finished collecting timing info
21:52:36.280085 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:52:36.290632 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:52:36.292338 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:52:36.292802 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:52:36.293037 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:37.313343 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
21:52:37.315803 [debug] [Thread-1  ]: finished collecting timing info
21:52:37.316088 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:52:37.465779 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d5be80>]}
21:52:37.466325 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.19s]
21:52:37.466788 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:52:37.467071 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:52:37.467616 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:52:37.468231 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:52:37.468478 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:52:37.468714 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:52:37.470132 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:52:37.470696 [debug] [Thread-1  ]: finished collecting timing info
21:52:37.470915 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:52:37.473339 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:52:37.474203 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:52:37.474424 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:52:37.474618 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:54.362685 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 16.89 seconds
21:52:54.364345 [debug] [Thread-1  ]: finished collecting timing info
21:52:54.364562 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:52:54.515393 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fa0280>]}
21:52:54.515946 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 17.05s]
21:52:54.516409 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:52:54.516694 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:52:54.517173 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:52:54.517793 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:52:54.518051 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:52:54.518261 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:52:54.519659 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:52:54.520245 [debug] [Thread-1  ]: finished collecting timing info
21:52:54.520471 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:52:54.522900 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:52:54.523971 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:52:54.524195 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:52:54.524398 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:56.674349 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.15 seconds
21:52:56.676322 [debug] [Thread-1  ]: finished collecting timing info
21:52:56.676640 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:52:56.865298 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d58e20>]}
21:52:56.865791 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 2.35s]
21:52:56.866183 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:52:56.866426 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:52:56.866816 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:52:56.867324 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:52:56.867529 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:52:56.867733 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:52:56.869182 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:52:56.869784 [debug] [Thread-1  ]: finished collecting timing info
21:52:56.870013 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:52:56.872946 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:52:56.874364 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:52:56.874650 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:52:56.874852 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:52:59.529804 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.65 seconds
21:52:59.531944 [debug] [Thread-1  ]: finished collecting timing info
21:52:59.532238 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:53:00.092926 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d58370>]}
21:53:00.093416 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.23s]
21:53:00.093931 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:53:00.094497 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:53:00.095026 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:53:00.095616 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:53:00.095840 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:53:00.096053 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:53:00.097447 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:53:00.098852 [debug] [Thread-1  ]: finished collecting timing info
21:53:00.099083 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:53:00.101450 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:53:00.102839 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:53:00.103052 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:53:00.103245 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:53:01.565395 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.46 seconds
21:53:01.567651 [debug] [Thread-1  ]: finished collecting timing info
21:53:01.567994 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:53:01.716080 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d58610>]}
21:53:01.716645 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.62s]
21:53:01.717132 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:53:01.717426 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:53:01.717839 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:53:01.718366 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:53:01.718578 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:53:01.718786 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:53:01.721129 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:53:01.723023 [debug] [Thread-1  ]: finished collecting timing info
21:53:01.723374 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:53:01.726200 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:53:01.727178 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:53:01.727431 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:53:01.727695 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:53:03.313281 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
21:53:03.315558 [debug] [Thread-1  ]: finished collecting timing info
21:53:03.315863 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:53:03.475550 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4874a80c-cec7-49f2-a4b2-55f78c0ecd63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d58d00>]}
21:53:03.476109 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.76s]
21:53:03.476577 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:53:03.477763 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:53:03.478032 [info ] [MainThread]: 
21:53:03.478366 [info ] [MainThread]: Running 3 on-run-end hooks
21:53:03.478721 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
21:53:03.480040 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
21:53:03.481757 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
21:53:03.482357 [debug] [MainThread]: Using snowflake connection "master"
21:53:03.482639 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
21:53:03.482861 [debug] [MainThread]: Opening a new connection, currently in state init
21:53:03.980133 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.5 seconds
21:53:03.981325 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.50s]
21:53:03.981918 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
21:53:03.983493 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
21:53:03.985124 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
21:53:03.985764 [debug] [MainThread]: Using snowflake connection "master"
21:53:03.985983 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
21:53:04.165673 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.18 seconds
21:53:04.167106 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.18s]
21:53:04.167686 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
21:53:04.169438 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
21:53:04.171357 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
21:53:04.172047 [debug] [MainThread]: Using snowflake connection "master"
21:53:04.172316 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
21:53:04.264552 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
21:53:04.265870 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
21:53:04.266340 [info ] [MainThread]: 
21:53:04.266754 [debug] [MainThread]: On master: Close
21:53:04.414491 [info ] [MainThread]: 
21:53:04.414925 [info ] [MainThread]: Finished running 2 incremental models, 6 table models, 3 hooks in 35.40s.
21:53:04.415286 [debug] [MainThread]: Connection 'master' was properly closed.
21:53:04.415504 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:53:04.422669 [info ] [MainThread]: 
21:53:04.423078 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:53:04.423490 [info ] [MainThread]: 
21:53:04.424040 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:53:04.424683 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:53:04.425234 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:53:04.425814 [info ] [MainThread]: 
21:53:04.426276 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:53:04.426903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d043970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d5b580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d046f70>]}


============================== 2022-01-08 21:54:31.541137 | f4da1160-83d0-48ec-b141-ea6cdf1e46d8 ==============================
21:54:31.541137 [info ] [MainThread]: Running with dbt=1.0.1
21:54:31.541771 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:54:31.542008 [debug] [MainThread]: Tracking: tracking
21:54:31.542373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca30d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca32b0>]}
21:54:31.568723 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:54:31.569149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc91c10>]}
21:54:31.604543 [debug] [MainThread]: Parsing macros/catalog.sql
21:54:31.607367 [debug] [MainThread]: Parsing macros/adapters.sql
21:54:31.653646 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:54:31.657262 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:54:31.662343 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:54:31.663694 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:54:31.666570 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:54:31.674629 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:54:31.675555 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:54:31.679179 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:54:31.681361 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:54:31.682917 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:54:31.698771 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:54:31.709507 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:54:31.721313 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:54:31.725460 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:54:31.727074 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:54:31.728721 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:54:31.733343 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:54:31.743770 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:54:31.745153 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:54:31.755294 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:54:31.769737 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:54:31.776524 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:54:31.779173 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:54:31.785745 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:54:31.786946 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:54:31.789476 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:54:31.791575 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:54:31.797133 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:54:31.812231 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:54:31.813758 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:54:31.816170 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:54:31.817623 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:54:31.818436 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:54:31.818968 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:54:31.819630 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:54:31.820894 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:54:31.824921 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:54:31.832743 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:54:31.834754 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:54:31.837320 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:54:31.846275 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:54:31.849001 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:54:31.853398 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:54:31.861011 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:54:31.871062 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:54:32.076492 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:54:32.090208 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:54:32.093114 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:54:32.096163 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:54:32.099402 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:54:32.107561 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:54:32.108810 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:54:32.111611 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:54:32.114981 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:54:32.121151 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:54:32.356598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be10af0>]}
21:54:32.366867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd7b3d0>]}
21:54:32.367290 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:54:32.370158 [info ] [MainThread]: 
21:54:32.371116 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:54:32.372597 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:54:32.388746 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:54:32.389071 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:54:32.389273 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:54:33.986821 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.6 seconds
21:54:33.988931 [debug] [ThreadPool]: On list_analytics: Close
21:54:34.146059 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:54:34.154349 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:54:34.154637 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:54:34.154844 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:54:34.943183 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.79 seconds
21:54:34.955886 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:54:35.119592 [info ] [MainThread]: 
21:54:35.134375 [info ] [MainThread]: Running 1 on-run-start hook
21:54:35.135491 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
21:54:35.153565 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
21:54:35.155313 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
21:54:35.155998 [debug] [MainThread]: Using snowflake connection "master"
21:54:35.156364 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
21:54:35.156641 [debug] [MainThread]: Opening a new connection, currently in state init
21:54:35.764385 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.61 seconds
21:54:35.765198 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.61s]
21:54:35.765517 [info ] [MainThread]: 
21:54:35.765776 [debug] [MainThread]: On master: Close
21:54:35.916226 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:54:35.916667 [info ] [MainThread]: 
21:54:35.919709 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:54:35.920088 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:54:35.920938 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:54:35.921156 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:54:35.921369 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:54:35.927896 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:54:35.928598 [debug] [Thread-1  ]: finished collecting timing info
21:54:35.928847 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:54:35.978979 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:54:35.979289 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:54:35.979481 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:54:36.469723 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a18022-0000-65ab-0000-00016cc23955
21:54:36.470094 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:54:36.470487 [debug] [Thread-1  ]: finished collecting timing info
21:54:36.470747 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:54:36.617599 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:54:36.618106 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11411d700>]}
21:54:36.618585 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.70s]
21:54:36.619101 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:54:36.619411 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:54:36.619914 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:54:36.620527 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:54:36.620771 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:54:36.620978 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:54:36.624696 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:54:36.625282 [debug] [Thread-1  ]: finished collecting timing info
21:54:36.625509 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:54:36.629276 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:36.629546 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:54:36.629757 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:54:37.997327 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.37 seconds
21:54:38.008838 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:38.009070 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:54:38.115645 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
21:54:38.120751 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:38.121014 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:54:38.220721 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:54:38.230955 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:38.231185 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:54:38.369915 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
21:54:38.396316 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:54:38.398060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:38.398272 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:54:38.591125 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
21:54:38.591681 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:38.591983 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:54:39.564587 [debug] [Thread-1  ]: SQL status: SUCCESS 124 in 0.97 seconds
21:54:39.564934 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:54:39.565137 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:54:39.815458 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
21:54:39.827930 [debug] [Thread-1  ]: finished collecting timing info
21:54:39.828197 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:54:39.969632 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11209abe0>]}
21:54:39.970157 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 3.35s]
21:54:39.970571 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:54:39.970823 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:54:39.971237 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:54:39.971794 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:54:39.972013 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:54:39.972224 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:54:39.975200 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:54:39.975852 [debug] [Thread-1  ]: finished collecting timing info
21:54:39.976102 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:54:39.991581 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:54:39.993996 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:54:39.994528 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:54:39.994950 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:54:41.491164 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
21:54:41.493765 [debug] [Thread-1  ]: finished collecting timing info
21:54:41.494053 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:54:41.717403 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11209a370>]}
21:54:41.717983 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.75s]
21:54:41.718455 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:54:41.718909 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:54:41.719247 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:54:41.719979 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:54:41.720318 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:54:41.720541 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:54:41.721946 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:54:41.722520 [debug] [Thread-1  ]: finished collecting timing info
21:54:41.722744 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:54:41.725240 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:54:41.726068 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:54:41.726291 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:54:41.726504 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:54:58.465665 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 16.74 seconds
21:54:58.468136 [debug] [Thread-1  ]: finished collecting timing info
21:54:58.468427 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:54:58.868016 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120daf40>]}
21:54:58.868573 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 17.15s]
21:54:58.869038 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:54:58.869322 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:54:58.869755 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:54:58.870373 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:54:58.870623 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:54:58.870867 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:54:58.872335 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:54:58.872920 [debug] [Thread-1  ]: finished collecting timing info
21:54:58.873146 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:54:58.875671 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:54:58.876738 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:54:58.876960 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:54:58.877159 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:55:00.716151 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
21:55:00.718419 [debug] [Thread-1  ]: finished collecting timing info
21:55:00.718752 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:55:00.872415 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf9aa60>]}
21:55:00.872980 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 2.00s]
21:55:00.873445 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:55:00.873730 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:55:00.874170 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:55:00.874759 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:55:00.875008 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:55:00.875249 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:55:00.876823 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:55:00.877407 [debug] [Thread-1  ]: finished collecting timing info
21:55:00.877677 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:55:00.880338 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:55:00.881572 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:55:00.881796 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:55:00.881992 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:55:02.594821 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
21:55:02.596682 [debug] [Thread-1  ]: finished collecting timing info
21:55:02.596941 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:55:02.767241 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be9b130>]}
21:55:02.767946 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.89s]
21:55:02.768665 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:55:02.769123 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:55:02.769635 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:55:02.770242 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:55:02.770534 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:55:02.770768 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:55:02.772201 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:55:02.772794 [debug] [Thread-1  ]: finished collecting timing info
21:55:02.773027 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:55:02.775688 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:55:02.776928 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:55:02.777181 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:55:02.777465 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:55:04.226211 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
21:55:04.228749 [debug] [Thread-1  ]: finished collecting timing info
21:55:04.229045 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:55:04.396939 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be9b730>]}
21:55:04.397517 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 1.63s]
21:55:04.397988 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:55:04.398277 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:55:04.398720 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:55:04.399332 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:55:04.399578 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:55:04.399817 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:55:04.402257 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:55:04.402822 [debug] [Thread-1  ]: finished collecting timing info
21:55:04.403045 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:55:04.405509 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:55:04.406402 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:55:04.406635 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:55:04.406835 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:55:05.816402 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.41 seconds
21:55:05.818815 [debug] [Thread-1  ]: finished collecting timing info
21:55:05.819104 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:55:05.979225 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4da1160-83d0-48ec-b141-ea6cdf1e46d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be9b6d0>]}
21:55:05.979766 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.58s]
21:55:05.980235 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:55:05.981530 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:55:05.981875 [info ] [MainThread]: 
21:55:05.982206 [info ] [MainThread]: Running 3 on-run-end hooks
21:55:05.982650 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
21:55:05.984113 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
21:55:05.984927 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
21:55:05.985680 [debug] [MainThread]: Using snowflake connection "master"
21:55:05.985940 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
21:55:05.986138 [debug] [MainThread]: Opening a new connection, currently in state closed
21:55:06.788429 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.8 seconds
21:55:06.789444 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.80s]
21:55:06.789856 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
21:55:06.791151 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
21:55:06.791886 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
21:55:06.792464 [debug] [MainThread]: Using snowflake connection "master"
21:55:06.792665 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
21:55:06.965851 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.17 seconds
21:55:06.967271 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.17s]
21:55:06.967851 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
21:55:06.969594 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
21:55:06.970480 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
21:55:06.971184 [debug] [MainThread]: Using snowflake connection "master"
21:55:06.971396 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
21:55:07.067823 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
21:55:07.069238 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
21:55:07.069771 [info ] [MainThread]: 
21:55:07.070172 [debug] [MainThread]: On master: Close
21:55:07.218057 [info ] [MainThread]: 
21:55:07.218566 [info ] [MainThread]: Finished running 2 incremental models, 6 table models, 4 hooks in 34.85s.
21:55:07.218958 [debug] [MainThread]: Connection 'master' was properly closed.
21:55:07.219185 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:55:07.226463 [info ] [MainThread]: 
21:55:07.226866 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:55:07.227223 [info ] [MainThread]: 
21:55:07.227563 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:55:07.227868 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:55:07.228159 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:55:07.228480 [info ] [MainThread]: 
21:55:07.228822 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:55:07.229284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142987f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11420ce80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114295970>]}


============================== 2022-01-08 21:58:28.521563 | 28173d38-12d6-4ed8-a33b-a4d4a203618b ==============================
21:58:28.521563 [info ] [MainThread]: Running with dbt=1.0.1
21:58:28.522278 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
21:58:28.522539 [debug] [MainThread]: Tracking: tracking
21:58:28.522969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb00520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb00250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb002e0>]}
21:58:28.549572 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
21:58:28.550201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae15d30>]}
21:58:28.587660 [debug] [MainThread]: Parsing macros/catalog.sql
21:58:28.590485 [debug] [MainThread]: Parsing macros/adapters.sql
21:58:28.638174 [debug] [MainThread]: Parsing macros/materializations/merge.sql
21:58:28.641854 [debug] [MainThread]: Parsing macros/materializations/seed.sql
21:58:28.646919 [debug] [MainThread]: Parsing macros/materializations/view.sql
21:58:28.648230 [debug] [MainThread]: Parsing macros/materializations/table.sql
21:58:28.651142 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
21:58:28.659520 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
21:58:28.660436 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
21:58:28.664457 [debug] [MainThread]: Parsing macros/materializations/configs.sql
21:58:28.666707 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
21:58:28.668261 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
21:58:28.684592 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
21:58:28.696153 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
21:58:28.707715 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
21:58:28.712071 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
21:58:28.713728 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
21:58:28.715417 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
21:58:28.719642 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
21:58:28.731081 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
21:58:28.732657 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
21:58:28.742288 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
21:58:28.757295 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
21:58:28.765290 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
21:58:28.768206 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
21:58:28.775590 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
21:58:28.776861 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
21:58:28.779652 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
21:58:28.782007 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
21:58:28.788048 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
21:58:28.804131 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
21:58:28.805575 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
21:58:28.807945 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
21:58:28.809430 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
21:58:28.810248 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
21:58:28.810873 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
21:58:28.811536 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
21:58:28.812843 [debug] [MainThread]: Parsing macros/etc/statement.sql
21:58:28.816976 [debug] [MainThread]: Parsing macros/etc/datetime.sql
21:58:28.825175 [debug] [MainThread]: Parsing macros/adapters/schema.sql
21:58:28.827320 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
21:58:28.830250 [debug] [MainThread]: Parsing macros/adapters/relation.sql
21:58:28.839719 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
21:58:28.842499 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
21:58:28.846722 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
21:58:28.853708 [debug] [MainThread]: Parsing macros/adapters/columns.sql
21:58:28.863464 [debug] [MainThread]: Parsing tests/generic/builtin.sql
21:58:29.060809 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
21:58:29.073850 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
21:58:29.077579 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_orders_by_date.sql
21:58:29.081205 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
21:58:29.085223 [debug] [MainThread]: 1603: static parser failed on example/incremental_dates.sql
21:58:29.128976 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_dates.sql
21:58:29.130935 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_nation_customer_count.sql
21:58:29.136205 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
21:58:29.141039 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
21:58:29.145286 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
21:58:29.301187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b669640>]}
21:58:29.309693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10baecc40>]}
21:58:29.310071 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
21:58:29.312110 [info ] [MainThread]: 
21:58:29.312803 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:58:29.314152 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
21:58:29.329497 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
21:58:29.329812 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
21:58:29.330024 [debug] [ThreadPool]: Opening a new connection, currently in state init
21:58:30.377465 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.05 seconds
21:58:30.379554 [debug] [ThreadPool]: On list_analytics: Close
21:58:30.540740 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
21:58:30.548383 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
21:58:30.548637 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
21:58:30.548824 [debug] [ThreadPool]: Opening a new connection, currently in state closed
21:58:31.280427 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.73 seconds
21:58:31.282906 [debug] [ThreadPool]: On list_analytics_dbt: Close
21:58:31.422241 [info ] [MainThread]: 
21:58:31.422676 [info ] [MainThread]: Running 1 on-run-start hook
21:58:31.423044 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
21:58:31.424375 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
21:58:31.426089 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
21:58:31.426736 [debug] [MainThread]: Using snowflake connection "master"
21:58:31.426944 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
21:58:31.427133 [debug] [MainThread]: Opening a new connection, currently in state init
21:58:31.929033 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.5 seconds
21:58:31.930526 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.50s]
21:58:31.931145 [info ] [MainThread]: 
21:58:31.931712 [debug] [MainThread]: On master: Close
21:58:32.074269 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
21:58:32.074712 [info ] [MainThread]: 
21:58:32.077942 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
21:58:32.078334 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
21:58:32.079245 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
21:58:32.079600 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
21:58:32.079845 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
21:58:32.087279 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
21:58:32.087937 [debug] [Thread-1  ]: finished collecting timing info
21:58:32.088219 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
21:58:32.138775 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
21:58:32.139071 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
21:58:32.139270 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:58:32.628102 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a18026-0000-6584-0000-00016cc2486d
21:58:32.645972 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
21:58:32.647014 [debug] [Thread-1  ]: finished collecting timing info
21:58:32.647407 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
21:58:32.810994 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
21:58:32.811499 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c067850>]}
21:58:32.811963 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 0.73s]
21:58:32.812447 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
21:58:32.812750 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
21:58:32.813283 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
21:58:32.814060 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
21:58:32.814305 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
21:58:32.814672 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
21:58:32.818758 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
21:58:32.819404 [debug] [Thread-1  ]: finished collecting timing info
21:58:32.819638 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
21:58:32.824092 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:32.824369 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

        insert into dbt.audit (model, state, time) values ('incremental_dates', 'starting model deployment', current_timestamp)
21:58:32.824563 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:58:34.274815 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
21:58:34.277551 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:34.277817 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
21:58:35.368233 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
21:58:35.379439 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:35.379719 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
21:58:35.480395 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:58:35.484698 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:35.484961 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
21:58:35.569177 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
21:58:35.578371 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:35.578658 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
21:58:35.675883 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
21:58:35.702585 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
21:58:35.704444 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:35.704664 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
21:58:35.811441 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
21:58:35.811994 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:35.812291 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
21:58:36.519567 [debug] [Thread-1  ]: SQL status: SUCCESS 237 in 0.71 seconds
21:58:36.519901 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
21:58:36.520102 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
21:58:36.766933 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
21:58:36.778916 [debug] [Thread-1  ]: finished collecting timing info
21:58:36.779255 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
21:58:36.917071 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf6c790>]}
21:58:36.917648 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 4.10s]
21:58:36.918129 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
21:58:36.918428 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
21:58:36.918810 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
21:58:36.919344 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
21:58:36.919556 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
21:58:36.919763 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
21:58:36.922594 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
21:58:36.923128 [debug] [Thread-1  ]: finished collecting timing info
21:58:36.923353 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
21:58:36.935577 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:58:36.935854 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
21:58:36.936063 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:58:37.961905 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
21:58:37.964125 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
21:58:37.965480 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
21:58:37.965730 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
21:58:38.841017 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.88 seconds
21:58:38.843155 [debug] [Thread-1  ]: finished collecting timing info
21:58:38.843454 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
21:58:38.993817 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf6ceb0>]}
21:58:38.994429 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.07s]
21:58:38.994898 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
21:58:38.995185 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
21:58:38.995735 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
21:58:38.996291 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
21:58:38.996523 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
21:58:38.996738 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
21:58:38.998181 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
21:58:38.998730 [debug] [Thread-1  ]: finished collecting timing info
21:58:38.998952 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
21:58:39.002448 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:58:39.002680 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
21:58:39.002879 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:58:39.986905 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
21:58:39.989175 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
21:58:39.990174 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
21:58:39.990423 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
21:58:57.184566 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.19 seconds
21:58:57.186417 [debug] [Thread-1  ]: finished collecting timing info
21:58:57.186708 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
21:58:57.326537 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf72d30>]}
21:58:57.327102 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 18.33s]
21:58:57.327594 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
21:58:57.327900 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:58:57.328326 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
21:58:57.328936 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:58:57.329188 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
21:58:57.329434 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
21:58:57.330876 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:58:57.331493 [debug] [Thread-1  ]: finished collecting timing info
21:58:57.331767 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
21:58:57.336354 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:58:57.336623 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_orders_by_date', 'starting model deployment', current_timestamp)
21:58:57.336826 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:58:58.460954 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
21:58:58.463301 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:58:58.464598 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
21:58:58.464855 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
21:58:59.360305 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.9 seconds
21:58:59.362202 [debug] [Thread-1  ]: finished collecting timing info
21:58:59.362469 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
21:58:59.511403 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf6cfa0>]}
21:58:59.511955 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 2.18s]
21:58:59.512420 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
21:58:59.512708 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
21:58:59.513155 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
21:58:59.513767 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:58:59.514017 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
21:58:59.514265 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
21:58:59.515845 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:58:59.516481 [debug] [Thread-1  ]: finished collecting timing info
21:58:59.516714 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
21:58:59.520264 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:58:59.520488 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
21:58:59.520686 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:59:00.376900 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
21:59:00.379203 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
21:59:00.380660 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
21:59:00.380926 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
21:59:01.859017 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
21:59:01.861540 [debug] [Thread-1  ]: finished collecting timing info
21:59:01.861835 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
21:59:01.994458 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf6c0d0>]}
21:59:01.995041 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.48s]
21:59:01.995519 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
21:59:01.995811 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
21:59:01.996313 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
21:59:01.996937 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:59:01.997212 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
21:59:01.997427 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
21:59:01.998871 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:59:01.999449 [debug] [Thread-1  ]: finished collecting timing info
21:59:01.999677 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
21:59:02.003159 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:59:02.003390 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */

        insert into dbt.audit (model, state, time) values ('snowflake_nation_customer_count', 'starting model deployment', current_timestamp)
21:59:02.003592 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:59:02.845185 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
21:59:02.847405 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
21:59:02.848752 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
21:59:02.849007 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
21:59:03.780689 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
21:59:03.782986 [debug] [Thread-1  ]: finished collecting timing info
21:59:03.783307 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
21:59:04.161310 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf53b20>]}
21:59:04.161895 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 2.16s]
21:59:04.162370 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
21:59:04.162663 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
21:59:04.163140 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
21:59:04.163756 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
21:59:04.164007 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
21:59:04.164267 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
21:59:04.166723 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
21:59:04.167304 [debug] [Thread-1  ]: finished collecting timing info
21:59:04.167528 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
21:59:04.171134 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:59:04.171386 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
21:59:04.171576 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
21:59:05.176210 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
21:59:05.178076 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
21:59:05.179080 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
21:59:05.179298 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
21:59:06.208911 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
21:59:06.211382 [debug] [Thread-1  ]: finished collecting timing info
21:59:06.211674 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
21:59:06.574190 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28173d38-12d6-4ed8-a33b-a4d4a203618b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcccdf0>]}
21:59:06.574748 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.41s]
21:59:06.575154 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
21:59:06.576355 [debug] [MainThread]: Acquiring new snowflake connection "master"
21:59:06.576621 [info ] [MainThread]: 
21:59:06.576954 [info ] [MainThread]: Running 3 on-run-end hooks
21:59:06.577308 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
21:59:06.578628 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
21:59:06.579445 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
21:59:06.580013 [debug] [MainThread]: Using snowflake connection "master"
21:59:06.580218 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
21:59:06.580406 [debug] [MainThread]: Opening a new connection, currently in state closed
21:59:07.066713 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.49 seconds
21:59:07.068149 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.49s]
21:59:07.068750 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
21:59:07.070238 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
21:59:07.071113 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
21:59:07.071837 [debug] [MainThread]: Using snowflake connection "master"
21:59:07.072080 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
21:59:07.222000 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.15 seconds
21:59:07.223407 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.15s]
21:59:07.223969 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
21:59:07.225684 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
21:59:07.226530 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
21:59:07.227218 [debug] [MainThread]: Using snowflake connection "master"
21:59:07.227507 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
21:59:07.383763 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
21:59:07.385184 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.16s]
21:59:07.385718 [info ] [MainThread]: 
21:59:07.386126 [debug] [MainThread]: On master: Close
21:59:07.524008 [info ] [MainThread]: 
21:59:07.524517 [info ] [MainThread]: Finished running 2 incremental models, 6 table models, 4 hooks in 38.21s.
21:59:07.524912 [debug] [MainThread]: Connection 'master' was properly closed.
21:59:07.525146 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
21:59:07.532704 [info ] [MainThread]: 
21:59:07.533151 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
21:59:07.533558 [info ] [MainThread]: 
21:59:07.533886 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
21:59:07.534205 [error] [MainThread]:   001003 (42000): SQL compilation error:
21:59:07.534514 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
21:59:07.534840 [info ] [MainThread]: 
21:59:07.535159 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
21:59:07.535604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf72eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df90610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0f2790>]}


============================== 2022-01-08 22:03:43.061000 | c3e1ef77-7ef2-4074-b29f-1250702024d5 ==============================
22:03:43.061000 [info ] [MainThread]: Running with dbt=1.0.1
22:03:43.061853 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
22:03:43.062188 [debug] [MainThread]: Tracking: tracking
22:03:43.062659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8f5400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8f5f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8f5ac0>]}
22:03:43.117529 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
22:03:43.118267 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
22:03:43.133919 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
22:03:43.186215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c3e1ef77-7ef2-4074-b29f-1250702024d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11079a0d0>]}
22:03:43.196422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c3e1ef77-7ef2-4074-b29f-1250702024d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11065ccd0>]}
22:03:43.196825 [info ] [MainThread]: Found 8 models, 18 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
22:03:43.199302 [info ] [MainThread]: 
22:03:43.200070 [debug] [MainThread]: Acquiring new snowflake connection "master"
22:03:43.201577 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
22:03:43.218325 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
22:03:43.218662 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
22:03:43.218954 [debug] [ThreadPool]: Opening a new connection, currently in state init
22:03:44.163370 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.94 seconds
22:03:44.165486 [debug] [ThreadPool]: On list_analytics: Close
22:03:44.317889 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
22:03:44.326238 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
22:03:44.326546 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
22:03:44.326753 [debug] [ThreadPool]: Opening a new connection, currently in state closed
22:03:45.512369 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 1.19 seconds
22:03:45.514791 [debug] [ThreadPool]: On list_analytics_dbt: Close
22:03:45.696191 [info ] [MainThread]: 
22:03:45.696698 [info ] [MainThread]: Running 1 on-run-start hook
22:03:45.697144 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
22:03:45.698671 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
22:03:45.700583 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
22:03:45.701261 [debug] [MainThread]: Using snowflake connection "master"
22:03:45.701479 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
22:03:45.701675 [debug] [MainThread]: Opening a new connection, currently in state init
22:03:46.333766 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.63 seconds
22:03:46.335026 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.63s]
22:03:46.335497 [info ] [MainThread]: 
22:03:46.335930 [debug] [MainThread]: On master: Close
22:03:46.473008 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
22:03:46.473529 [info ] [MainThread]: 
22:03:46.476799 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
22:03:46.477177 [info ] [Thread-1  ]: 1 of 8 START incremental model dbt.dates........................................ [RUN]
22:03:46.478725 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
22:03:46.478957 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
22:03:46.479182 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
22:03:46.490043 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
22:03:46.490704 [debug] [Thread-1  ]: finished collecting timing info
22:03:46.490960 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
22:03:46.540632 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
22:03:46.540944 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <= current_date
order by d_date desc


    and d_date > (select max(d_date) from analytics.dbt.dates)

      );
22:03:46.541145 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
22:03:47.465510 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a1802b-0000-65ab-0000-00016cc23a29
22:03:47.465826 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 4 unexpected 'and'.
22:03:47.466176 [debug] [Thread-1  ]: finished collecting timing info
22:03:47.466417 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
22:03:47.892341 [debug] [Thread-1  ]: Database Error in model dates (models/new/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 4 unexpected 'and'.
22:03:47.892803 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3e1ef77-7ef2-4074-b29f-1250702024d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109c3850>]}
22:03:47.893219 [error] [Thread-1  ]: 1 of 8 ERROR creating incremental model dbt.dates............................... [[31mERROR[0m in 1.41s]
22:03:47.893633 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
22:03:47.893883 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_dates
22:03:47.894358 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_dates............................ [RUN]
22:03:47.895072 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_dates"
22:03:47.895451 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_dates
22:03:47.895857 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_dates
22:03:47.900967 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_dates"
22:03:47.902049 [debug] [Thread-1  ]: finished collecting timing info
22:03:47.902518 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_dates
22:03:47.908995 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
22:03:47.909372 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

        insert into dbt.audit (model, state, time) values ('incremental_dates', 'starting model deployment', current_timestamp)
22:03:47.909602 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
22:03:49.572243 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.66 seconds
22:03:49.574482 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
22:03:49.574715 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    

      create or replace temporary table analytics.dbt.incremental_dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


    and t_time > (select max(t_time) from analytics.dbt.incremental_dates)

      );
22:03:50.812199 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
22:03:50.823113 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
22:03:50.823584 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates__dbt_tmp
22:03:50.924533 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
22:03:50.930418 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
22:03:50.930706 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table analytics.dbt.incremental_dates
22:03:51.023868 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
22:03:51.033872 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
22:03:51.034181 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_DATES"
22:03:51.132908 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
22:03:51.160927 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_dates"
22:03:51.162796 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
22:03:51.163013 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_dates"} */
begin;
22:03:51.411891 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
22:03:51.412353 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
22:03:51.412587 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: merge into analytics.dbt.incremental_dates as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
22:03:52.138348 [debug] [Thread-1  ]: SQL status: SUCCESS 315 in 0.73 seconds
22:03:52.138772 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_dates"
22:03:52.139026 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: commit;
22:03:52.401619 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
22:03:52.413712 [debug] [Thread-1  ]: finished collecting timing info
22:03:52.414017 [debug] [Thread-1  ]: On model.learn_dbt.incremental_dates: Close
22:03:52.614462 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3e1ef77-7ef2-4074-b29f-1250702024d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11065c910>]}
22:03:52.615029 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_dates....................... [[32mSUCCESS 1[0m in 4.72s]
22:03:52.615505 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_dates
22:03:52.615824 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
22:03:52.616274 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
22:03:52.616802 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
22:03:52.617017 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
22:03:52.617225 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
22:03:52.620466 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
22:03:52.621151 [debug] [Thread-1  ]: finished collecting timing info
22:03:52.621407 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
22:03:52.633866 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
22:03:52.634152 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
22:03:52.634355 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
22:03:53.596249 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.96 seconds
22:03:53.598143 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
22:03:53.599777 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
22:03:53.600068 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'CA' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
22:03:54.312347 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.71 seconds
22:03:54.314471 [debug] [Thread-1  ]: finished collecting timing info
22:03:54.314769 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
22:03:54.488755 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3e1ef77-7ef2-4074-b29f-1250702024d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11071b0a0>]}
22:03:54.489255 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.87s]
22:03:54.489673 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
22:03:54.489925 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
22:03:54.490420 [info ] [Thread-1  ]: 4 of 8 START table model dbt.playing_with_tests................................. [RUN]
22:03:54.490960 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
22:03:54.491178 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
22:03:54.491390 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
22:03:54.492845 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
22:03:54.493543 [debug] [Thread-1  ]: finished collecting timing info
22:03:54.493777 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
22:03:54.497286 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
22:03:54.497534 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
22:03:54.497730 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
22:03:55.562670 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.06 seconds
22:03:55.564663 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
22:03:55.565698 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
22:03:55.565951 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"
      );
22:04:12.969579 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 17.4 seconds
22:04:12.971866 [debug] [Thread-1  ]: finished collecting timing info
22:04:12.972160 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
22:04:13.143631 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3e1ef77-7ef2-4074-b29f-1250702024d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c755b0>]}
22:04:13.144265 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 18.65s]
22:04:13.144749 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
22:04:13.145043 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_orders_by_date
22:04:13.145518 [info ] [Thread-1  ]: 5 of 8 START table model dbt.snowflake_cumulative_orders_by_date................ [RUN]
22:04:13.146067 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
22:04:13.146284 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_orders_by_date
22:04:13.146498 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_orders_by_date
22:04:13.147915 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
22:04:13.148517 [debug] [Thread-1  ]: finished collecting timing info
22:04:13.148748 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_orders_by_date
22:04:13.152283 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
22:04:13.152515 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_orders_by_date', 'starting model deployment', current_timestamp)
22:04:13.152714 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
22:04:14.189991 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
22:04:14.191683 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_orders_by_date"
22:04:14.192796 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_orders_by_date"
22:04:14.193025 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (SELECT
    o.o_orderdate,
    sum(o.o_totalprice) as cumulative_sales
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
GROUP BY o.o_orderdate
ORDER BY o.o_orderdate DESC
      );
22:04:15.130671 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.94 seconds
22:04:15.133067 [debug] [Thread-1  ]: finished collecting timing info
22:04:15.133540 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_orders_by_date: Close
22:04:15.276517 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3e1ef77-7ef2-4074-b29f-1250702024d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11071ba30>]}
22:04:15.277109 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.snowflake_cumulative_orders_by_date........... [[32mSUCCESS 1[0m in 2.13s]
22:04:15.277621 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_orders_by_date
22:04:15.277948 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
22:04:15.278532 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
22:04:15.279159 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
22:04:15.279380 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
22:04:15.279589 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
22:04:15.281854 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
22:04:15.282508 [debug] [Thread-1  ]: finished collecting timing info
22:04:15.282857 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
22:04:15.286564 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
22:04:15.286818 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
22:04:15.287017 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
22:04:16.171626 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.88 seconds
22:04:16.173488 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
22:04:16.174914 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
22:04:16.175133 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
22:04:17.524270 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.35 seconds
22:04:17.526411 [debug] [Thread-1  ]: finished collecting timing info
22:04:17.526718 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
22:04:17.663900 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3e1ef77-7ef2-4074-b29f-1250702024d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c41760>]}
22:04:17.664380 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.38s]
22:04:17.664787 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
22:04:17.665033 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_nation_customer_count
22:04:17.665427 [info ] [Thread-1  ]: 7 of 8 START table model dbt.snowflake_nation_customer_count.................... [RUN]
22:04:17.665945 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
22:04:17.666152 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_nation_customer_count
22:04:17.666354 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_nation_customer_count
22:04:17.667810 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_nation_customer_count"
22:04:17.668385 [debug] [Thread-1  ]: finished collecting timing info
22:04:17.668614 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_nation_customer_count
22:04:17.673000 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
22:04:17.673265 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */

        insert into dbt.audit (model, state, time) values ('snowflake_nation_customer_count', 'starting model deployment', current_timestamp)
22:04:17.673461 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
22:04:18.897017 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.22 seconds
22:04:18.899271 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_nation_customer_count"
22:04:18.900644 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_nation_customer_count"
22:04:18.900902 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_nation_customer_count"} */


      create or replace transient table analytics.dbt.snowflake_nation_customer_count  as
      (SELECT
    n.n_nationkey,
    n.n_name,
    count(*) as total_customers

FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."NATION" n
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
ON n.n_nationkey = c.c_nationkey

group by
    n.n_nationkey,
    n.n_name
      );
22:04:19.724568 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
22:04:19.726809 [debug] [Thread-1  ]: finished collecting timing info
22:04:19.727106 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_nation_customer_count: Close
22:04:19.883968 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3e1ef77-7ef2-4074-b29f-1250702024d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c92f40>]}
22:04:19.884551 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.snowflake_nation_customer_count............... [[32mSUCCESS 1[0m in 2.22s]
22:04:19.885020 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_nation_customer_count
22:04:19.885313 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
22:04:19.885769 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
22:04:19.886404 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
22:04:19.886657 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
22:04:19.886929 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
22:04:19.889385 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
22:04:19.889991 [debug] [Thread-1  ]: finished collecting timing info
22:04:19.890225 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
22:04:19.893860 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
22:04:19.894100 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
22:04:19.894324 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
22:04:21.017461 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
22:04:21.019754 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
22:04:21.020942 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
22:04:21.021245 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
22:04:21.797613 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.78 seconds
22:04:21.799627 [debug] [Thread-1  ]: finished collecting timing info
22:04:21.799883 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
22:04:21.937140 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3e1ef77-7ef2-4074-b29f-1250702024d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110918d00>]}
22:04:21.937702 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.05s]
22:04:21.938168 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
22:04:21.939729 [debug] [MainThread]: Acquiring new snowflake connection "master"
22:04:21.940216 [info ] [MainThread]: 
22:04:21.940617 [info ] [MainThread]: Running 3 on-run-end hooks
22:04:21.941031 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
22:04:21.942527 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
22:04:21.943411 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
22:04:21.943988 [debug] [MainThread]: Using snowflake connection "master"
22:04:21.944194 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
22:04:21.944384 [debug] [MainThread]: Opening a new connection, currently in state closed
22:04:22.428309 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.48 seconds
22:04:22.429767 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.49s]
22:04:22.430359 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
22:04:22.431835 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
22:04:22.433564 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
22:04:22.434279 [debug] [MainThread]: Using snowflake connection "master"
22:04:22.434518 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
22:04:22.612261 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.18 seconds
22:04:22.613232 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.18s]
22:04:22.613627 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
22:04:22.615091 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
22:04:22.615844 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
22:04:22.616415 [debug] [MainThread]: Using snowflake connection "master"
22:04:22.616615 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
22:04:22.712292 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
22:04:22.713284 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
22:04:22.713676 [info ] [MainThread]: 
22:04:22.714015 [debug] [MainThread]: On master: Close
22:04:22.894293 [info ] [MainThread]: 
22:04:22.894867 [info ] [MainThread]: Finished running 2 incremental models, 6 table models, 4 hooks in 39.69s.
22:04:22.895540 [debug] [MainThread]: Connection 'master' was properly closed.
22:04:22.895885 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
22:04:22.904188 [info ] [MainThread]: 
22:04:22.904672 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
22:04:22.905463 [info ] [MainThread]: 
22:04:22.906101 [error] [MainThread]: [33mDatabase Error in model dates (models/new/dates.sql)[0m
22:04:22.906879 [error] [MainThread]:   001003 (42000): SQL compilation error:
22:04:22.907533 [error] [MainThread]:   syntax error line 10 at position 4 unexpected 'and'.
22:04:22.908293 [info ] [MainThread]: 
22:04:22.908911 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
22:04:22.909731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11074dfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b50a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a90160>]}


============================== 2022-01-08 22:08:27.713318 | d811c571-e8e6-44e0-9944-b2ecf891d38c ==============================
22:08:27.713318 [info ] [MainThread]: Running with dbt=1.0.1
22:08:27.714066 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
22:08:27.714352 [debug] [MainThread]: Tracking: tracking
22:08:27.714793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fb4580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fb4730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fb4460>]}
22:08:27.769684 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
22:08:27.770326 [debug] [MainThread]: Partial parsing: added file: learn_dbt://snapshots/first_model_snapshot.sql
22:08:27.791242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10409c850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10411ae80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10413cf40>]}


============================== 2022-01-08 22:10:10.315931 | 5ca6a272-2a6a-44f0-a5f9-f4d0c4c611a9 ==============================
22:10:10.315931 [info ] [MainThread]: Running with dbt=1.0.1
22:10:10.316607 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
22:10:10.316864 [debug] [MainThread]: Tracking: tracking
22:10:10.317238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bb4490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bb46a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bb45b0>]}
22:10:10.356950 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
22:10:10.357417 [debug] [MainThread]: Partial parsing: added file: learn_dbt://snapshots/first_model_snapshot.sql
22:10:10.372583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c63490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d25ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d3be50>]}


============================== 2022-01-08 22:11:01.458596 | 766ba527-66b6-434a-a1d0-cf739451fc1e ==============================
22:11:01.458596 [info ] [MainThread]: Running with dbt=1.0.1
22:11:01.459264 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
22:11:01.459512 [debug] [MainThread]: Tracking: tracking
22:11:01.459878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106081e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106081d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106081be0>]}
22:11:01.498893 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
22:11:01.499377 [debug] [MainThread]: Partial parsing: added file: learn_dbt://snapshots/first_model_snapshot.sql
22:11:01.532395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '766ba527-66b6-434a-a1d0-cf739451fc1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061d30d0>]}
22:11:01.540616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '766ba527-66b6-434a-a1d0-cf739451fc1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10615cbe0>]}
22:11:01.541016 [info ] [MainThread]: Found 8 models, 18 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
22:11:01.542811 [info ] [MainThread]: 
22:11:01.543304 [debug] [MainThread]: Acquiring new snowflake connection "master"
22:11:01.544077 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
22:11:01.557621 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
22:11:01.557906 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
22:11:01.558079 [debug] [ThreadPool]: Opening a new connection, currently in state init
22:11:02.584456 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.03 seconds
22:11:02.586652 [debug] [ThreadPool]: On list_analytics: Close
22:11:02.730766 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_snapshots"
22:11:02.731297 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_snapshots"
22:11:02.731630 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='snapshots', identifier=None)"
22:11:02.737001 [debug] [ThreadPool]: Using snowflake connection "create_analytics_snapshots"
22:11:02.737224 [debug] [ThreadPool]: On create_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_snapshots"} */
create schema if not exists analytics.snapshots
22:11:02.737416 [debug] [ThreadPool]: Opening a new connection, currently in state closed
22:11:03.263165 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.53 seconds
22:11:03.264700 [debug] [ThreadPool]: On create_analytics_snapshots: Close
22:11:03.437779 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
22:11:03.445661 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
22:11:03.445899 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
22:11:03.446101 [debug] [ThreadPool]: Opening a new connection, currently in state closed
22:11:03.962317 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.52 seconds
22:11:03.964419 [debug] [ThreadPool]: On list_analytics_snapshots: Close
22:11:04.116309 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
22:11:04.118324 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
22:11:04.118549 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
22:11:04.118748 [debug] [ThreadPool]: Opening a new connection, currently in state closed
22:11:04.604924 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.49 seconds
22:11:04.607414 [debug] [ThreadPool]: On list_analytics_dbt: Close
22:11:04.763509 [info ] [MainThread]: 
22:11:04.763973 [info ] [MainThread]: Running 1 on-run-start hook
22:11:04.764362 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
22:11:04.765710 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
22:11:04.767400 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
22:11:04.768050 [debug] [MainThread]: Using snowflake connection "master"
22:11:04.768269 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
22:11:04.768469 [debug] [MainThread]: Opening a new connection, currently in state init
22:11:05.254846 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.49 seconds
22:11:05.256303 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.49s]
22:11:05.256863 [info ] [MainThread]: 
22:11:05.257270 [debug] [MainThread]: On master: Close
22:11:05.399077 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
22:11:05.399595 [info ] [MainThread]: 
22:11:05.402895 [debug] [Thread-1  ]: Began running node snapshot.learn_dbt.first_model_snapshot
22:11:05.403260 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.first_model_snapshot............................ [RUN]
22:11:05.404105 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:11:05.404496 [debug] [Thread-1  ]: Began compiling node snapshot.learn_dbt.first_model_snapshot
22:11:05.404775 [debug] [Thread-1  ]: Compiling snapshot.learn_dbt.first_model_snapshot
22:11:05.408619 [debug] [Thread-1  ]: finished collecting timing info
22:11:05.408954 [debug] [Thread-1  ]: Began executing node snapshot.learn_dbt.first_model_snapshot
22:11:05.445621 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:11:05.445899 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */
select count(*)
        from analytics.INFORMATION_SCHEMA.schemata
        where upper(schema_name) = upper('snapshots')
            and upper(catalog_name) = upper('analytics')
22:11:05.446097 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
22:11:06.962019 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
22:11:07.005489 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.learn_dbt.first_model_snapshot"
22:11:07.006938 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:11:07.007155 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

      

      create or replace transient table analytics.snapshots.first_model_snapshot  as
      (

    select *,
        md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        



select * from analytics.dbt.first_model

    ) sbq



      );
22:11:08.005264 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
22:11:08.022397 [debug] [Thread-1  ]: finished collecting timing info
22:11:08.022649 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: Close
22:11:08.294745 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '766ba527-66b6-434a-a1d0-cf739451fc1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10658e820>]}
22:11:08.295368 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.first_model_snapshot............................ [[32mSUCCESS 1[0m in 2.89s]
22:11:08.295864 [debug] [Thread-1  ]: Finished running node snapshot.learn_dbt.first_model_snapshot
22:11:08.297182 [debug] [MainThread]: Acquiring new snowflake connection "master"
22:11:08.297502 [info ] [MainThread]: 
22:11:08.297915 [info ] [MainThread]: Running 3 on-run-end hooks
22:11:08.298322 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
22:11:08.299614 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
22:11:08.300731 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
22:11:08.301308 [debug] [MainThread]: Using snowflake connection "master"
22:11:08.301519 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
22:11:08.301715 [debug] [MainThread]: Opening a new connection, currently in state closed
22:11:08.786130 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.48 seconds
22:11:08.787588 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.49s]
22:11:08.788156 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
22:11:08.789648 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
22:11:08.790498 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
22:11:08.791181 [debug] [MainThread]: Using snowflake connection "master"
22:11:08.791419 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
22:11:08.942781 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.15 seconds
22:11:08.944198 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.15s]
22:11:08.944772 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
22:11:08.946495 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
22:11:08.947329 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
22:11:08.948009 [debug] [MainThread]: Using snowflake connection "master"
22:11:08.948247 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
22:11:09.044052 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
22:11:09.045485 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
22:11:09.046003 [info ] [MainThread]: 
22:11:09.046413 [debug] [MainThread]: On master: Close
22:11:09.207589 [info ] [MainThread]: 
22:11:09.208097 [info ] [MainThread]: Finished running 1 snapshot, 4 hooks in 7.66s.
22:11:09.208487 [debug] [MainThread]: Connection 'master' was properly closed.
22:11:09.208719 [debug] [MainThread]: Connection 'snapshot.learn_dbt.first_model_snapshot' was properly closed.
22:11:09.215852 [info ] [MainThread]: 
22:11:09.216249 [info ] [MainThread]: [32mCompleted successfully[0m
22:11:09.216623 [info ] [MainThread]: 
22:11:09.216985 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
22:11:09.217531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10615c2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106597f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065e7190>]}


============================== 2022-01-08 22:12:48.763819 | ce25038c-271d-4f77-b55b-fb39356ef511 ==============================
22:12:48.763819 [info ] [MainThread]: Running with dbt=1.0.1
22:12:48.764752 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['example.my_first_dbt_model'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
22:12:48.765078 [debug] [MainThread]: Tracking: tracking
22:12:48.765537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2f4490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2f46a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2f45b0>]}
22:12:48.821175 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
22:12:48.822065 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
22:12:48.837659 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
22:12:48.889791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ce25038c-271d-4f77-b55b-fb39356ef511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5100d0>]}
22:12:48.900191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ce25038c-271d-4f77-b55b-fb39356ef511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3faaf0>]}
22:12:48.900631 [info ] [MainThread]: Found 8 models, 18 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
22:12:48.902749 [info ] [MainThread]: 
22:12:48.903391 [debug] [MainThread]: Acquiring new snowflake connection "master"
22:12:48.904396 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
22:12:48.920981 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
22:12:48.921306 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
22:12:48.921514 [debug] [ThreadPool]: Opening a new connection, currently in state init
22:12:49.763510 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.84 seconds
22:12:49.765416 [debug] [ThreadPool]: On list_analytics: Close
22:12:49.925217 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
22:12:49.932950 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
22:12:49.933236 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
22:12:49.933454 [debug] [ThreadPool]: Opening a new connection, currently in state closed
22:12:50.463485 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.53 seconds
22:12:50.465945 [debug] [ThreadPool]: On list_analytics_dbt: Close
22:12:50.837631 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
22:12:50.840039 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
22:12:50.840272 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
22:12:50.840469 [debug] [ThreadPool]: Opening a new connection, currently in state closed
22:12:51.568066 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.73 seconds
22:12:51.570382 [debug] [ThreadPool]: On list_analytics_snapshots: Close
22:12:51.745097 [info ] [MainThread]: 
22:12:51.745605 [info ] [MainThread]: Running 1 on-run-start hook
22:12:51.746105 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
22:12:51.747652 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
22:12:51.749350 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
22:12:51.750028 [debug] [MainThread]: Using snowflake connection "master"
22:12:51.750265 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
22:12:51.750468 [debug] [MainThread]: Opening a new connection, currently in state init
22:12:52.229203 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.48 seconds
22:12:52.230604 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.48s]
22:12:52.231105 [info ] [MainThread]: 
22:12:52.231543 [debug] [MainThread]: On master: Close
22:12:52.383548 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
22:12:52.384005 [info ] [MainThread]: 
22:12:52.387724 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
22:12:52.388257 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
22:12:52.389276 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
22:12:52.389615 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
22:12:52.390073 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
22:12:52.393847 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
22:12:52.395237 [debug] [Thread-1  ]: finished collecting timing info
22:12:52.395496 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
22:12:52.417426 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
22:12:52.417706 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
22:12:52.417918 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
22:12:53.916281 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
22:12:53.930040 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
22:12:53.931446 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
22:12:53.931669 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'NY' as state, '2020-02-01 00:01:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select *
from source_data
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
22:12:54.812259 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.88 seconds
22:12:54.825327 [debug] [Thread-1  ]: finished collecting timing info
22:12:54.825656 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
22:12:54.964584 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce25038c-271d-4f77-b55b-fb39356ef511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e438eb0>]}
22:12:54.965176 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.58s]
22:12:54.965690 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
22:12:54.966991 [debug] [MainThread]: Acquiring new snowflake connection "master"
22:12:54.967318 [info ] [MainThread]: 
22:12:54.967680 [info ] [MainThread]: Running 3 on-run-end hooks
22:12:54.968021 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
22:12:54.969688 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
22:12:54.970488 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
22:12:54.971054 [debug] [MainThread]: Using snowflake connection "master"
22:12:54.971259 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
22:12:54.971498 [debug] [MainThread]: Opening a new connection, currently in state closed
22:12:55.630037 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.66 seconds
22:12:55.631040 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.66s]
22:12:55.631451 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
22:12:55.632763 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
22:12:55.633537 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
22:12:55.634135 [debug] [MainThread]: Using snowflake connection "master"
22:12:55.634347 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
22:12:55.766729 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
22:12:55.768163 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
22:12:55.768738 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
22:12:55.770517 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
22:12:55.771535 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
22:12:55.772311 [debug] [MainThread]: Using snowflake connection "master"
22:12:55.772534 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
22:12:55.933650 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
22:12:55.935084 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.16s]
22:12:55.935617 [info ] [MainThread]: 
22:12:55.936028 [debug] [MainThread]: On master: Close
22:12:56.067493 [info ] [MainThread]: 
22:12:56.068020 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 7.16s.
22:12:56.068367 [debug] [MainThread]: Connection 'master' was properly closed.
22:12:56.068571 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
22:12:56.075593 [info ] [MainThread]: 
22:12:56.076033 [info ] [MainThread]: [32mCompleted successfully[0m
22:12:56.076523 [info ] [MainThread]: 
22:12:56.076904 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
22:12:56.077366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116733490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116733460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6f8af0>]}


============================== 2022-01-08 22:13:27.916347 | ae55480b-66b7-4925-891f-37d0518fc106 ==============================
22:13:27.916347 [info ] [MainThread]: Running with dbt=1.0.1
22:13:27.917126 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
22:13:27.917459 [debug] [MainThread]: Tracking: tracking
22:13:27.917922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f2cdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f2cf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f2c130>]}
22:13:27.970542 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
22:13:27.970828 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
22:13:27.978756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ae55480b-66b7-4925-891f-37d0518fc106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070aea90>]}
22:13:27.989402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ae55480b-66b7-4925-891f-37d0518fc106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f186d0>]}
22:13:27.989800 [info ] [MainThread]: Found 8 models, 18 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
22:13:27.992030 [info ] [MainThread]: 
22:13:27.992644 [debug] [MainThread]: Acquiring new snowflake connection "master"
22:13:27.993571 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
22:13:28.009332 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
22:13:28.009644 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
22:13:28.009860 [debug] [ThreadPool]: Opening a new connection, currently in state init
22:13:29.216481 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.21 seconds
22:13:29.218336 [debug] [ThreadPool]: On list_analytics: Close
22:13:29.368737 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
22:13:29.376931 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
22:13:29.377274 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
22:13:29.377507 [debug] [ThreadPool]: Opening a new connection, currently in state closed
22:13:30.066286 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.69 seconds
22:13:30.068534 [debug] [ThreadPool]: On list_analytics_dbt: Close
22:13:30.346650 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
22:13:30.348862 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
22:13:30.349077 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
22:13:30.349266 [debug] [ThreadPool]: Opening a new connection, currently in state closed
22:13:30.946124 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.6 seconds
22:13:30.948067 [debug] [ThreadPool]: On list_analytics_snapshots: Close
22:13:31.119044 [info ] [MainThread]: 
22:13:31.119552 [info ] [MainThread]: Running 1 on-run-start hook
22:13:31.120002 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
22:13:31.121563 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
22:13:31.123379 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
22:13:31.124006 [debug] [MainThread]: Using snowflake connection "master"
22:13:31.124216 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
22:13:31.124415 [debug] [MainThread]: Opening a new connection, currently in state init
22:13:31.679023 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.55 seconds
22:13:31.680443 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.56s]
22:13:31.680922 [info ] [MainThread]: 
22:13:31.681340 [debug] [MainThread]: On master: Close
22:13:31.846274 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
22:13:31.846853 [info ] [MainThread]: 
22:13:31.850459 [debug] [Thread-1  ]: Began running node snapshot.learn_dbt.first_model_snapshot
22:13:31.850845 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.first_model_snapshot............................ [RUN]
22:13:31.851434 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:31.851739 [debug] [Thread-1  ]: Began compiling node snapshot.learn_dbt.first_model_snapshot
22:13:31.852130 [debug] [Thread-1  ]: Compiling snapshot.learn_dbt.first_model_snapshot
22:13:31.856006 [debug] [Thread-1  ]: finished collecting timing info
22:13:31.856317 [debug] [Thread-1  ]: Began executing node snapshot.learn_dbt.first_model_snapshot
22:13:31.892465 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:31.892757 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */
select count(*)
        from analytics.INFORMATION_SCHEMA.schemata
        where upper(schema_name) = upper('snapshots')
            and upper(catalog_name) = upper('analytics')
22:13:31.892957 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
22:13:32.872923 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
22:13:32.910409 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:32.910704 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
22:13:33.069017 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.16 seconds
22:13:33.100358 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:33.100653 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

        

      create or replace temporary table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"  as
      (with snapshot_query as (

        



select * from analytics.dbt.first_model


    ),

    snapshotted_data as (

        select *,
            id as dbt_unique_key

        from "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    )

    select * from insertions
    union all
    select * from updates

      );
22:13:34.168961 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.07 seconds
22:13:34.171515 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:34.171717 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
22:13:34.269554 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.1 seconds
22:13:34.273905 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:34.274140 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
22:13:34.377490 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.1 seconds
22:13:34.382214 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:34.382490 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
22:13:34.469676 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.09 seconds
22:13:34.474763 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:34.475049 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
22:13:34.569511 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.09 seconds
22:13:34.578572 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:34.578839 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
22:13:34.691533 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.11 seconds
22:13:34.701878 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.learn_dbt.first_model_snapshot"
22:13:34.703476 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:34.703759 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

      begin;
22:13:34.919455 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.22 seconds
22:13:34.920007 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:34.920334 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: merge into "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT" as DBT_INTERNAL_DEST
    using "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp" as DBT_INTERNAL_SOURCE
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id

    when matched
     and DBT_INTERNAL_DEST.dbt_valid_to is null
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert ("ID", "STATE", "UPDATED_AT", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")
        values ("ID", "STATE", "UPDATED_AT", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")

;
22:13:35.478155 [debug] [Thread-1  ]: SQL status: SUCCESS 2 in 0.56 seconds
22:13:35.490899 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
22:13:35.491446 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: commit;
22:13:35.769279 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
22:13:35.784269 [debug] [Thread-1  ]: finished collecting timing info
22:13:35.784585 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: Close
22:13:35.933966 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ae55480b-66b7-4925-891f-37d0518fc106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073db160>]}
22:13:35.934557 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.first_model_snapshot............................ [[32mSUCCESS 1[0m in 4.08s]
22:13:35.935058 [debug] [Thread-1  ]: Finished running node snapshot.learn_dbt.first_model_snapshot
22:13:35.936323 [debug] [MainThread]: Acquiring new snowflake connection "master"
22:13:35.936652 [info ] [MainThread]: 
22:13:35.937021 [info ] [MainThread]: Running 3 on-run-end hooks
22:13:35.937436 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
22:13:35.938815 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
22:13:35.939692 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
22:13:35.940283 [debug] [MainThread]: Using snowflake connection "master"
22:13:35.940495 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
22:13:35.940690 [debug] [MainThread]: Opening a new connection, currently in state closed
22:13:36.469758 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.53 seconds
22:13:36.470809 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.53s]
22:13:36.471242 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
22:13:36.472669 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
22:13:36.473661 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
22:13:36.474512 [debug] [MainThread]: Using snowflake connection "master"
22:13:36.474795 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
22:13:36.598214 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
22:13:36.599200 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.12s]
22:13:36.599603 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
22:13:36.601081 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
22:13:36.601855 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
22:13:36.602491 [debug] [MainThread]: Using snowflake connection "master"
22:13:36.602708 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
22:13:36.719217 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
22:13:36.720381 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
22:13:36.720894 [info ] [MainThread]: 
22:13:36.721681 [debug] [MainThread]: On master: Close
22:13:36.871469 [info ] [MainThread]: 
22:13:36.872013 [info ] [MainThread]: Finished running 1 snapshot, 4 hooks in 8.88s.
22:13:36.872416 [debug] [MainThread]: Connection 'master' was properly closed.
22:13:36.872650 [debug] [MainThread]: Connection 'snapshot.learn_dbt.first_model_snapshot' was properly closed.
22:13:36.879644 [info ] [MainThread]: 
22:13:36.880065 [info ] [MainThread]: [32mCompleted successfully[0m
22:13:36.880516 [info ] [MainThread]: 
22:13:36.880875 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
22:13:36.881295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072fdc40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074dc0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074f0ac0>]}


============================== 2022-01-09 19:56:27.047981 | d1ea76b6-5706-4113-8ad2-c1d72bcb8665 ==============================
19:56:27.047981 [info ] [MainThread]: Running with dbt=1.0.1
19:56:27.049336 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['example.snowflake_customer_purchases'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:56:27.049696 [debug] [MainThread]: Tracking: tracking
19:56:27.050214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c1feb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c1fd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c1fb20>]}
19:56:27.128161 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
19:56:27.128924 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
19:56:27.129344 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
19:56:27.143435 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
19:56:27.216802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd1ea76b6-5706-4113-8ad2-c1d72bcb8665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113e3a0d0>]}
19:56:27.263711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd1ea76b6-5706-4113-8ad2-c1d72bcb8665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113bd66a0>]}
19:56:27.264116 [info ] [MainThread]: Found 8 models, 18 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
19:56:27.265911 [info ] [MainThread]: 
19:56:27.266481 [debug] [MainThread]: Acquiring new snowflake connection "master"
19:56:27.267367 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
19:56:27.283520 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
19:56:27.283855 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
19:56:27.284066 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:56:28.616232 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.33 seconds
19:56:28.618750 [debug] [ThreadPool]: On list_analytics: Close
19:56:28.780644 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
19:56:28.788412 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
19:56:28.788674 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
19:56:28.788861 [debug] [ThreadPool]: Opening a new connection, currently in state closed
19:56:29.616618 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.83 seconds
19:56:29.618697 [debug] [ThreadPool]: On list_analytics_dbt: Close
19:56:29.770255 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
19:56:29.773142 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
19:56:29.773397 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
19:56:29.773590 [debug] [ThreadPool]: Opening a new connection, currently in state closed
19:56:30.513154 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.74 seconds
19:56:30.514802 [debug] [ThreadPool]: On list_analytics_snapshots: Close
19:56:30.796202 [info ] [MainThread]: 
19:56:30.796623 [info ] [MainThread]: Running 1 on-run-start hook
19:56:30.796985 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
19:56:30.798276 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
19:56:30.800407 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
19:56:30.801090 [debug] [MainThread]: Using snowflake connection "master"
19:56:30.801387 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
19:56:30.801586 [debug] [MainThread]: Opening a new connection, currently in state init
19:56:31.406088 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.6 seconds
19:56:31.407082 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.61s]
19:56:31.407477 [info ] [MainThread]: 
19:56:31.407816 [debug] [MainThread]: On master: Close
19:56:31.559333 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
19:56:31.559811 [info ] [MainThread]: 
19:56:31.565293 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
19:56:31.565713 [info ] [Thread-1  ]: 1 of 1 START table model dbt.snowflake_customer_purchases....................... [RUN]
19:56:31.566297 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
19:56:31.566510 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
19:56:31.566722 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
19:56:31.570751 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
19:56:31.571955 [debug] [Thread-1  ]: finished collecting timing info
19:56:31.572298 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
19:56:31.594448 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
19:56:31.594703 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
19:56:31.594893 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
19:56:33.150372 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
19:56:33.163504 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
19:56:33.165682 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
19:56:33.165912 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM snowflake_sample_data.tpch_sf1.customer c
LEFT JOIN snowflake_sample_data.tpch_sf1.orders o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
19:56:34.793220 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.63 seconds
19:56:34.803255 [debug] [Thread-1  ]: finished collecting timing info
19:56:34.803504 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
19:56:34.946464 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1ea76b6-5706-4113-8ad2-c1d72bcb8665', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c177c40>]}
19:56:34.946902 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.38s]
19:56:34.947259 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
19:56:34.948182 [debug] [MainThread]: Acquiring new snowflake connection "master"
19:56:34.948415 [info ] [MainThread]: 
19:56:34.948700 [info ] [MainThread]: Running 3 on-run-end hooks
19:56:34.948999 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
19:56:34.950445 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
19:56:34.952501 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
19:56:34.953382 [debug] [MainThread]: Using snowflake connection "master"
19:56:34.953705 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
19:56:34.953895 [debug] [MainThread]: Opening a new connection, currently in state closed
19:56:35.573389 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.62 seconds
19:56:35.574574 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.62s]
19:56:35.575126 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
19:56:35.576602 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
19:56:35.577412 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
19:56:35.577988 [debug] [MainThread]: Using snowflake connection "master"
19:56:35.578180 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
19:56:35.710378 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
19:56:35.711628 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
19:56:35.712229 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
19:56:35.713964 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
19:56:35.715482 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
19:56:35.716061 [debug] [MainThread]: Using snowflake connection "master"
19:56:35.716259 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
19:56:35.834750 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
19:56:35.835919 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
19:56:35.836558 [info ] [MainThread]: 
19:56:35.837103 [debug] [MainThread]: On master: Close
19:56:36.004042 [info ] [MainThread]: 
19:56:36.004551 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 8.74s.
19:56:36.004936 [debug] [MainThread]: Connection 'master' was properly closed.
19:56:36.005165 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
19:56:36.013184 [info ] [MainThread]: 
19:56:36.013601 [info ] [MainThread]: [32mCompleted successfully[0m
19:56:36.014067 [info ] [MainThread]: 
19:56:36.014400 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
19:56:36.014815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c19d550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a187400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a187e50>]}


============================== 2022-01-09 20:00:07.430978 | fd201b94-ec71-4435-bad1-9681a44235a9 ==============================
20:00:07.430978 [info ] [MainThread]: Running with dbt=1.0.1
20:00:07.431961 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
20:00:07.432291 [debug] [MainThread]: Tracking: tracking
20:00:07.432728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111205250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112053d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111205160>]}
20:00:07.501159 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
20:00:07.502046 [debug] [MainThread]: Partial parsing: deleted source source.learn_dbt.sample.customer
20:00:07.502265 [debug] [MainThread]: Partial parsing: deleted source source.learn_dbt.sample.orders
20:00:07.502472 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
20:00:07.516064 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
20:00:07.631323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fd201b94-ec71-4435-bad1-9681a44235a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113d0c40>]}
20:00:07.641107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fd201b94-ec71-4435-bad1-9681a44235a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113239a0>]}
20:00:07.641493 [info ] [MainThread]: Found 8 models, 20 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
20:00:07.644505 [info ] [MainThread]: 
20:00:07.645126 [debug] [MainThread]: Acquiring new snowflake connection "master"
20:00:07.646735 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
20:00:07.663003 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
20:00:07.663304 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
20:00:07.663503 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:00:08.495666 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.83 seconds
20:00:08.497827 [debug] [ThreadPool]: On list_analytics_dbt: Close
20:00:08.820153 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
20:00:08.822945 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
20:00:08.823175 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
20:00:08.823370 [debug] [ThreadPool]: Opening a new connection, currently in state closed
20:00:09.743153 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.92 seconds
20:00:09.745145 [debug] [ThreadPool]: On list_analytics_snapshots: Close
20:00:10.139541 [info ] [MainThread]: 
20:00:10.140023 [info ] [MainThread]: Running 1 on-run-start hook
20:00:10.140394 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
20:00:10.141766 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
20:00:10.143575 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
20:00:10.144287 [debug] [MainThread]: Using snowflake connection "master"
20:00:10.144536 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
20:00:10.144750 [debug] [MainThread]: Opening a new connection, currently in state init
20:00:10.873318 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.73 seconds
20:00:10.874395 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.73s]
20:00:10.874800 [info ] [MainThread]: 
20:00:10.875153 [debug] [MainThread]: On master: Close
20:00:11.321377 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
20:00:11.321833 [info ] [MainThread]: 
20:00:11.325553 [debug] [Thread-1  ]: Began running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
20:00:11.325852 [info ] [Thread-1  ]: 1 of 20 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
20:00:11.326443 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
20:00:11.326815 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
20:00:11.327151 [debug] [Thread-1  ]: Compiling test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
20:00:11.344342 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
20:00:11.345773 [debug] [Thread-1  ]: finished collecting timing info
20:00:11.346018 [debug] [Thread-1  ]: Began executing node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
20:00:11.365747 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
20:00:11.367357 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
20:00:11.367618 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.playing_with_tests
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
20:00:11.367817 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:13.070089 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.7 seconds
20:00:13.073133 [debug] [Thread-1  ]: finished collecting timing info
20:00:13.073447 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
20:00:13.223394 [info ] [Thread-1  ]: 1 of 20 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 1.90s]
20:00:13.223902 [debug] [Thread-1  ]: Finished running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
20:00:13.224167 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_100m_acctbal
20:00:13.224499 [info ] [Thread-1  ]: 2 of 20 START test assert_under_100m_acctbal.................................... [RUN]
20:00:13.225025 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_100m_acctbal"
20:00:13.225244 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_100m_acctbal
20:00:13.225455 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_100m_acctbal
20:00:13.227828 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_100m_acctbal"
20:00:13.228529 [debug] [Thread-1  ]: finished collecting timing info
20:00:13.228808 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_100m_acctbal
20:00:13.231256 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_100m_acctbal"
20:00:13.232465 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_100m_acctbal"
20:00:13.232697 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_100m_acctbal: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_100m_acctbal"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select
    c_custkey,
    sum(c_acctbal) as total_acctbal
from analytics.dbt.playing_with_tests
group by
    c_custkey

having sum(c_acctbal) > 100000000
      
    ) dbt_internal_test
20:00:13.232964 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:14.926497 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.69 seconds
20:00:14.928606 [debug] [Thread-1  ]: finished collecting timing info
20:00:14.928905 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_100m_acctbal: Close
20:00:15.101709 [info ] [Thread-1  ]: 2 of 20 PASS assert_under_100m_acctbal.......................................... [[32mPASS[0m in 1.88s]
20:00:15.102280 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_100m_acctbal
20:00:15.102580 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
20:00:15.102963 [info ] [Thread-1  ]: 3 of 20 START test assert_under_10_percent_null................................. [RUN]
20:00:15.103585 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
20:00:15.103838 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
20:00:15.104082 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
20:00:15.106689 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
20:00:15.107492 [debug] [Thread-1  ]: finished collecting timing info
20:00:15.107934 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
20:00:15.110440 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
20:00:15.111691 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
20:00:15.111917 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select 
    sum(case when id is null then 1 else 0 end) / count(*) as total_nulls

from analytics.dbt.first_model

having sum(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
20:00:15.112120 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:15.903683 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.79 seconds
20:00:15.905842 [debug] [Thread-1  ]: finished collecting timing info
20:00:15.906133 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
20:00:16.067191 [info ] [Thread-1  ]: 3 of 20 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 0.96s]
20:00:16.067760 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
20:00:16.068060 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
20:00:16.068447 [info ] [Thread-1  ]: 4 of 20 START test not_null_playing_with_tests_c_custkey........................ [RUN]
20:00:16.069047 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
20:00:16.069294 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
20:00:16.069531 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
20:00:16.078061 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
20:00:16.078714 [debug] [Thread-1  ]: finished collecting timing info
20:00:16.078953 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
20:00:16.080869 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
20:00:16.081858 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
20:00:16.082068 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.playing_with_tests
where c_custkey is null



      
    ) dbt_internal_test
20:00:16.082268 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:16.937307 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
20:00:16.939478 [debug] [Thread-1  ]: finished collecting timing info
20:00:16.939770 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
20:00:17.090026 [info ] [Thread-1  ]: 4 of 20 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 1.02s]
20:00:17.090539 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
20:00:17.090808 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
20:00:17.091199 [info ] [Thread-1  ]: 5 of 20 START test not_null_snowflake_cumulative_orders_by_date_o_orderdate..... [RUN]
20:00:17.091769 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
20:00:17.092012 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
20:00:17.092217 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
20:00:17.096445 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
20:00:17.097372 [debug] [Thread-1  ]: finished collecting timing info
20:00:17.097798 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
20:00:17.100326 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
20:00:17.101453 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"
20:00:17.101679 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_orders_by_date
where o_orderdate is null



      
    ) dbt_internal_test
20:00:17.101875 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:18.042519 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.94 seconds
20:00:18.045084 [debug] [Thread-1  ]: finished collecting timing info
20:00:18.045396 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14: Close
20:00:18.198924 [info ] [Thread-1  ]: 5 of 20 PASS not_null_snowflake_cumulative_orders_by_date_o_orderdate........... [[32mPASS[0m in 1.11s]
20:00:18.199469 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_orders_by_date_o_orderdate.0679498c14
20:00:18.199760 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
20:00:18.200158 [info ] [Thread-1  ]: 6 of 20 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
20:00:18.200752 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
20:00:18.200968 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
20:00:18.201180 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
20:00:18.205287 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
20:00:18.206042 [debug] [Thread-1  ]: finished collecting timing info
20:00:18.206362 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
20:00:18.208798 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
20:00:18.209983 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
20:00:18.210214 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
20:00:18.210418 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:19.125335 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.91 seconds
20:00:19.127573 [debug] [Thread-1  ]: finished collecting timing info
20:00:19.127895 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
20:00:19.287296 [info ] [Thread-1  ]: 6 of 20 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.09s]
20:00:19.287796 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
20:00:19.288046 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
20:00:19.288362 [info ] [Thread-1  ]: 7 of 20 START test not_null_snowflake_customer_purchases_c_name................. [RUN]
20:00:19.288866 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
20:00:19.289074 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
20:00:19.289274 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
20:00:19.295767 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
20:00:19.296745 [debug] [Thread-1  ]: finished collecting timing info
20:00:19.297138 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
20:00:19.300080 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
20:00:19.302031 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"
20:00:19.302417 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_name is null



      
    ) dbt_internal_test
20:00:19.302790 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:20.005658 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
20:00:20.007728 [debug] [Thread-1  ]: finished collecting timing info
20:00:20.008025 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972: Close
20:00:20.159177 [info ] [Thread-1  ]: 7 of 20 PASS not_null_snowflake_customer_purchases_c_name....................... [[32mPASS[0m in 0.87s]
20:00:20.159662 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_name.c140ac3972
20:00:20.159909 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
20:00:20.160242 [info ] [Thread-1  ]: 8 of 20 START test not_null_snowflake_nation_customer_count_n_name.............. [RUN]
20:00:20.160757 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
20:00:20.160966 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
20:00:20.161168 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
20:00:20.165147 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
20:00:20.165804 [debug] [Thread-1  ]: finished collecting timing info
20:00:20.166050 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
20:00:20.168645 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
20:00:20.169849 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"
20:00:20.170098 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_nation_customer_count
where n_name is null



      
    ) dbt_internal_test
20:00:20.170306 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:21.027168 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
20:00:21.029562 [debug] [Thread-1  ]: finished collecting timing info
20:00:21.029861 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81: Close
20:00:21.182108 [info ] [Thread-1  ]: 8 of 20 PASS not_null_snowflake_nation_customer_count_n_name.................... [[32mPASS[0m in 1.02s]
20:00:21.182733 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_name.6520df1f81
20:00:21.183062 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
20:00:21.183434 [info ] [Thread-1  ]: 9 of 20 START test not_null_snowflake_nation_customer_count_n_nationkey......... [RUN]
20:00:21.184024 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
20:00:21.184272 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
20:00:21.184525 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
20:00:21.188951 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
20:00:21.189588 [debug] [Thread-1  ]: finished collecting timing info
20:00:21.189822 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
20:00:21.191986 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
20:00:21.192995 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"
20:00:21.193209 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_nation_customer_count
where n_nationkey is null



      
    ) dbt_internal_test
20:00:21.193406 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:22.477915 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.28 seconds
20:00:22.480112 [debug] [Thread-1  ]: finished collecting timing info
20:00:22.480414 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae: Close
20:00:22.624050 [info ] [Thread-1  ]: 9 of 20 PASS not_null_snowflake_nation_customer_count_n_nationkey............... [[32mPASS[0m in 1.44s]
20:00:22.624592 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_nation_customer_count_n_nationkey.6c98646eae
20:00:22.624848 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
20:00:22.625169 [info ] [Thread-1  ]: 10 of 20 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
20:00:22.625704 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
20:00:22.625917 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
20:00:22.626122 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
20:00:22.636522 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
20:00:22.637373 [debug] [Thread-1  ]: finished collecting timing info
20:00:22.637659 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
20:00:22.640334 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
20:00:22.641758 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
20:00:22.641974 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
20:00:22.642164 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:23.530588 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
20:00:23.532822 [debug] [Thread-1  ]: finished collecting timing info
20:00:23.533121 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
20:00:23.705096 [info ] [Thread-1  ]: 10 of 20 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[32mPASS[0m in 1.08s]
20:00:23.705672 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
20:00:23.705976 [debug] [Thread-1  ]: Began running node test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2
20:00:23.706398 [info ] [Thread-1  ]: 11 of 20 START test source_not_null_sample_customer_c_custkey................... [RUN]
20:00:23.707035 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2"
20:00:23.707285 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2
20:00:23.707535 [debug] [Thread-1  ]: Compiling test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2
20:00:23.712065 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2"
20:00:23.712718 [debug] [Thread-1  ]: finished collecting timing info
20:00:23.712957 [debug] [Thread-1  ]: Began executing node test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2
20:00:23.715259 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2"
20:00:23.716330 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2"
20:00:23.716560 [debug] [Thread-1  ]: On test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from snowflake_sample_data.tpch_sf1.customer
where c_custkey is null



      
    ) dbt_internal_test
20:00:23.716765 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:24.308337 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.59 seconds
20:00:24.310316 [debug] [Thread-1  ]: finished collecting timing info
20:00:24.310610 [debug] [Thread-1  ]: On test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2: Close
20:00:24.465711 [info ] [Thread-1  ]: 11 of 20 PASS source_not_null_sample_customer_c_custkey......................... [[32mPASS[0m in 0.76s]
20:00:24.466215 [debug] [Thread-1  ]: Finished running node test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2
20:00:24.466462 [debug] [Thread-1  ]: Began running node test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd
20:00:24.466780 [info ] [Thread-1  ]: 12 of 20 START test source_unique_sample_customer_c_custkey..................... [RUN]
20:00:24.467285 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd"
20:00:24.467493 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd
20:00:24.467696 [debug] [Thread-1  ]: Compiling test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd
20:00:24.476144 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd"
20:00:24.476763 [debug] [Thread-1  ]: finished collecting timing info
20:00:24.476992 [debug] [Thread-1  ]: Began executing node test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd
20:00:24.478860 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd"
20:00:24.480037 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd"
20:00:24.480262 [debug] [Thread-1  ]: On test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from snowflake_sample_data.tpch_sf1.customer
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
20:00:24.480459 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:25.446570 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.97 seconds
20:00:25.448675 [debug] [Thread-1  ]: finished collecting timing info
20:00:25.448983 [debug] [Thread-1  ]: On test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd: Close
20:00:25.599188 [info ] [Thread-1  ]: 12 of 20 PASS source_unique_sample_customer_c_custkey........................... [[32mPASS[0m in 1.13s]
20:00:25.599754 [debug] [Thread-1  ]: Finished running node test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd
20:00:25.600048 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
20:00:25.600454 [info ] [Thread-1  ]: 13 of 20 START test unique_my_first_dbt_model_id................................ [RUN]
20:00:25.601061 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
20:00:25.601310 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
20:00:25.601554 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
20:00:25.606477 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
20:00:25.607231 [debug] [Thread-1  ]: finished collecting timing info
20:00:25.607483 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
20:00:25.609876 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
20:00:25.611060 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
20:00:25.611279 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
20:00:25.611474 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:26.347315 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
20:00:26.349560 [debug] [Thread-1  ]: finished collecting timing info
20:00:26.349975 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
20:00:26.647412 [info ] [Thread-1  ]: 13 of 20 PASS unique_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.05s]
20:00:26.647991 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
20:00:26.648291 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
20:00:26.648681 [info ] [Thread-1  ]: 14 of 20 START test unique_my_second_dbt_model_id............................... [RUN]
20:00:26.649515 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
20:00:26.649834 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
20:00:26.650089 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
20:00:26.654517 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
20:00:26.655184 [debug] [Thread-1  ]: finished collecting timing info
20:00:26.655424 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
20:00:26.657753 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
20:00:26.659005 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
20:00:26.659267 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
20:00:26.659477 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:28.127091 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.47 seconds
20:00:28.129308 [debug] [Thread-1  ]: finished collecting timing info
20:00:28.129604 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
20:00:28.277733 [info ] [Thread-1  ]: 14 of 20 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 1.63s]
20:00:28.278323 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
20:00:28.278622 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
20:00:28.279000 [info ] [Thread-1  ]: 15 of 20 START test unique_playing_with_tests_c_custkey......................... [RUN]
20:00:28.279623 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
20:00:28.279874 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
20:00:28.280117 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
20:00:28.284673 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
20:00:28.285344 [debug] [Thread-1  ]: finished collecting timing info
20:00:28.285592 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
20:00:28.287888 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
20:00:28.289045 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
20:00:28.289264 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.playing_with_tests
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
20:00:28.289463 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:29.478531 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.19 seconds
20:00:29.480925 [debug] [Thread-1  ]: finished collecting timing info
20:00:29.481219 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: Close
20:00:29.647477 [info ] [Thread-1  ]: 15 of 20 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.37s]
20:00:29.648058 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
20:00:29.648362 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
20:00:29.648755 [info ] [Thread-1  ]: 16 of 20 START test unique_snowflake_cumulative_orders_by_date_o_orderdate...... [RUN]
20:00:29.649446 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
20:00:29.649721 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
20:00:29.650072 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
20:00:29.654617 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
20:00:29.655303 [debug] [Thread-1  ]: finished collecting timing info
20:00:29.655541 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
20:00:29.657794 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
20:00:29.658958 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"
20:00:29.659171 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_orders_by_date
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
20:00:29.659363 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:30.677573 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
20:00:30.679681 [debug] [Thread-1  ]: finished collecting timing info
20:00:30.679970 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88: Close
20:00:30.895862 [info ] [Thread-1  ]: 16 of 20 PASS unique_snowflake_cumulative_orders_by_date_o_orderdate............ [[32mPASS[0m in 1.25s]
20:00:30.896351 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_orders_by_date_o_orderdate.86a671ca88
20:00:30.896600 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
20:00:30.896976 [info ] [Thread-1  ]: 17 of 20 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
20:00:30.897502 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
20:00:30.897712 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
20:00:30.897915 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
20:00:30.901897 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
20:00:30.902585 [debug] [Thread-1  ]: finished collecting timing info
20:00:30.902955 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
20:00:30.905448 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
20:00:30.906681 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
20:00:30.906896 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
20:00:30.907092 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:31.559765 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.65 seconds
20:00:31.561640 [debug] [Thread-1  ]: finished collecting timing info
20:00:31.561902 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
20:00:31.938035 [info ] [Thread-1  ]: 17 of 20 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.04s]
20:00:31.938616 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
20:00:31.938918 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
20:00:31.939309 [info ] [Thread-1  ]: 18 of 20 START test unique_snowflake_customer_purchases_c_name.................. [RUN]
20:00:31.939921 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
20:00:31.940174 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
20:00:31.940404 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
20:00:31.944716 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
20:00:31.945380 [debug] [Thread-1  ]: finished collecting timing info
20:00:31.945620 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
20:00:31.947922 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
20:00:31.949130 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"
20:00:31.949360 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_name as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_name is not null
group by c_name
having count(*) > 1



      
    ) dbt_internal_test
20:00:31.949569 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:32.948987 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
20:00:32.951436 [debug] [Thread-1  ]: finished collecting timing info
20:00:32.951745 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297: Close
20:00:33.130716 [info ] [Thread-1  ]: 18 of 20 PASS unique_snowflake_customer_purchases_c_name........................ [[32mPASS[0m in 1.19s]
20:00:33.131304 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_name.13933c5297
20:00:33.131597 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
20:00:33.131934 [info ] [Thread-1  ]: 19 of 20 START test unique_snowflake_nation_customer_count_n_name............... [RUN]
20:00:33.132784 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
20:00:33.133034 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
20:00:33.133254 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
20:00:33.138078 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
20:00:33.138823 [debug] [Thread-1  ]: finished collecting timing info
20:00:33.139102 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
20:00:33.141408 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
20:00:33.143306 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"
20:00:33.143570 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    n_name as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_nation_customer_count
where n_name is not null
group by n_name
having count(*) > 1



      
    ) dbt_internal_test
20:00:33.143807 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:33.937995 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.79 seconds
20:00:33.940150 [debug] [Thread-1  ]: finished collecting timing info
20:00:33.940461 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034: Close
20:00:34.222569 [info ] [Thread-1  ]: 19 of 20 PASS unique_snowflake_nation_customer_count_n_name..................... [[32mPASS[0m in 1.09s]
20:00:34.223143 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_nation_customer_count_n_name.0db6643034
20:00:34.223443 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
20:00:34.223841 [info ] [Thread-1  ]: 20 of 20 START test unique_snowflake_nation_customer_count_n_nationkey.......... [RUN]
20:00:34.224417 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
20:00:34.224632 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
20:00:34.224838 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
20:00:34.229071 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
20:00:34.229724 [debug] [Thread-1  ]: finished collecting timing info
20:00:34.229992 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
20:00:34.232317 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
20:00:34.233885 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"
20:00:34.234215 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    n_nationkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_nation_customer_count
where n_nationkey is not null
group by n_nationkey
having count(*) > 1



      
    ) dbt_internal_test
20:00:34.234435 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:00:34.966668 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.73 seconds
20:00:34.968817 [debug] [Thread-1  ]: finished collecting timing info
20:00:34.969123 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5: Close
20:00:35.109786 [info ] [Thread-1  ]: 20 of 20 PASS unique_snowflake_nation_customer_count_n_nationkey................ [[32mPASS[0m in 0.89s]
20:00:35.110284 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5
20:00:35.111502 [debug] [MainThread]: Acquiring new snowflake connection "master"
20:00:35.111771 [info ] [MainThread]: 
20:00:35.112100 [info ] [MainThread]: Running 3 on-run-end hooks
20:00:35.112465 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
20:00:35.113808 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
20:00:35.114726 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
20:00:35.115418 [debug] [MainThread]: Using snowflake connection "master"
20:00:35.115687 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
20:00:35.115896 [debug] [MainThread]: Opening a new connection, currently in state closed
20:00:35.621261 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.51 seconds
20:00:35.622501 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.51s]
20:00:35.622994 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
20:00:35.624396 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
20:00:35.625154 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
20:00:35.625746 [debug] [MainThread]: Using snowflake connection "master"
20:00:35.625949 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
20:00:35.787267 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
20:00:35.788419 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
20:00:35.788886 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
20:00:35.790735 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
20:00:35.791549 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
20:00:35.792154 [debug] [MainThread]: Using snowflake connection "master"
20:00:35.792362 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
20:00:35.902798 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
20:00:35.904086 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
20:00:35.904533 [info ] [MainThread]: 
20:00:35.904925 [debug] [MainThread]: On master: Close
20:00:36.201212 [info ] [MainThread]: 
20:00:36.201709 [info ] [MainThread]: Finished running 20 tests, 4 hooks in 28.56s.
20:00:36.202096 [debug] [MainThread]: Connection 'master' was properly closed.
20:00:36.202321 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_nation_customer_count_n_nationkey.c8d51524e5' was properly closed.
20:00:36.211472 [info ] [MainThread]: 
20:00:36.211877 [info ] [MainThread]: [32mCompleted successfully[0m
20:00:36.212272 [info ] [MainThread]: 
20:00:36.212580 [info ] [MainThread]: Done. PASS=20 WARN=0 ERROR=0 SKIP=0 TOTAL=20
20:00:36.212973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117bdf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115c6790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117da250>]}


============================== 2022-01-09 20:01:33.130544 | a7d80032-6fec-4cc0-9110-06c3c7b0cf9d ==============================
20:01:33.130544 [info ] [MainThread]: Running with dbt=1.0.1
20:01:33.131215 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/ajaydavid/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['source:sample+'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
20:01:33.131469 [debug] [MainThread]: Tracking: tracking
20:01:33.131870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106822550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106822e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068222b0>]}
20:01:33.187971 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
20:01:33.188189 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
20:01:33.194390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a7d80032-6fec-4cc0-9110-06c3c7b0cf9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069a60d0>]}
20:01:33.202243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a7d80032-6fec-4cc0-9110-06c3c7b0cf9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068f8370>]}
20:01:33.202526 [info ] [MainThread]: Found 8 models, 20 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
20:01:33.204059 [info ] [MainThread]: 
20:01:33.204491 [debug] [MainThread]: Acquiring new snowflake connection "master"
20:01:33.205395 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
20:01:33.218597 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
20:01:33.218888 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
20:01:33.219083 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:01:34.094805 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.88 seconds
20:01:34.097061 [debug] [ThreadPool]: On list_analytics: Close
20:01:34.246384 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
20:01:34.254298 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
20:01:34.254533 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
20:01:34.254729 [debug] [ThreadPool]: Opening a new connection, currently in state closed
20:01:35.052816 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.8 seconds
20:01:35.055390 [debug] [ThreadPool]: On list_analytics_dbt: Close
20:01:35.202070 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
20:01:35.204702 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
20:01:35.204958 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
20:01:35.205157 [debug] [ThreadPool]: Opening a new connection, currently in state closed
20:01:35.695684 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.49 seconds
20:01:35.697880 [debug] [ThreadPool]: On list_analytics_snapshots: Close
20:01:35.854915 [info ] [MainThread]: 
20:01:35.855377 [info ] [MainThread]: Running 1 on-run-start hook
20:01:35.855750 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
20:01:35.857089 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
20:01:35.858909 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
20:01:35.859571 [debug] [MainThread]: Using snowflake connection "master"
20:01:35.859803 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
20:01:35.860005 [debug] [MainThread]: Opening a new connection, currently in state init
20:01:37.561576 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.7 seconds
20:01:37.563034 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.70s]
20:01:37.563593 [info ] [MainThread]: 
20:01:37.564001 [debug] [MainThread]: On master: Close
20:01:37.717240 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
20:01:37.717756 [info ] [MainThread]: 
20:01:37.721097 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
20:01:37.721522 [info ] [Thread-1  ]: 1 of 1 START table model dbt.snowflake_customer_purchases....................... [RUN]
20:01:37.722109 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
20:01:37.722325 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
20:01:37.722548 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
20:01:37.726080 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
20:01:37.726701 [debug] [Thread-1  ]: finished collecting timing info
20:01:37.726945 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
20:01:37.747895 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
20:01:37.748175 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
20:01:37.748370 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
20:01:39.029784 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.28 seconds
20:01:39.043241 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
20:01:39.044575 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
20:01:39.044796 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
    c.c_custkey,
    c.c_name,
    c.c_nationkey as nation,
    sum(o.o_totalprice) as total_order_price
FROM snowflake_sample_data.tpch_sf1.customer c
LEFT JOIN snowflake_sample_data.tpch_sf1.orders o
ON c.c_custkey = o.o_custkey

group by
    c.c_custkey,
    c.c_name,
    c.c_nationkey
      );
20:01:40.410368 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.37 seconds
20:01:40.422941 [debug] [Thread-1  ]: finished collecting timing info
20:01:40.423215 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
20:01:40.561425 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7d80032-6fec-4cc0-9110-06c3c7b0cf9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069b2130>]}
20:01:40.561992 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.84s]
20:01:40.562478 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
20:01:40.563731 [debug] [MainThread]: Acquiring new snowflake connection "master"
20:01:40.564042 [info ] [MainThread]: 
20:01:40.564446 [info ] [MainThread]: Running 3 on-run-end hooks
20:01:40.564824 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
20:01:40.566846 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
20:01:40.567741 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
20:01:40.568349 [debug] [MainThread]: Using snowflake connection "master"
20:01:40.568634 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
20:01:40.568856 [debug] [MainThread]: Opening a new connection, currently in state closed
20:01:41.042826 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.47 seconds
20:01:41.044265 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.48s]
20:01:41.044849 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
20:01:41.046339 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
20:01:41.047289 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
20:01:41.048075 [debug] [MainThread]: Using snowflake connection "master"
20:01:41.048337 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
20:01:41.235088 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.19 seconds
20:01:41.236496 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.19s]
20:01:41.237084 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
20:01:41.238839 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
20:01:41.239748 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
20:01:41.240444 [debug] [MainThread]: Using snowflake connection "master"
20:01:41.240691 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
20:01:41.346961 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
20:01:41.347944 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
20:01:41.348336 [info ] [MainThread]: 
20:01:41.348680 [debug] [MainThread]: On master: Close
20:01:41.525255 [info ] [MainThread]: 
20:01:41.525744 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 8.32s.
20:01:41.526087 [debug] [MainThread]: Connection 'master' was properly closed.
20:01:41.526285 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
20:01:41.534338 [info ] [MainThread]: 
20:01:41.534799 [info ] [MainThread]: [32mCompleted successfully[0m
20:01:41.535213 [info ] [MainThread]: 
20:01:41.535544 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
20:01:41.535965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c0b7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c0b7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bef220>]}
